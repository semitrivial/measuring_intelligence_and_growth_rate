\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{mathdots}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{informallemma}[theorem]{Informal Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{openquestion}[theorem]{Open Question}

\title{Extending Hibbard's intelligence measure by delegating hard choices to the agent}
\author{Samuel Alexander\thanks{The U.S.\ Securities and Exchange Commission}}
\date{2020}

\begin{document}

\maketitle

\begin{abstract}
When studying the theory of agents with Artificial General Intelligence
(the theory of AGIs), one can sometimes avoid arbitrary decisions by
delegating those decisions to the AGIs under investigation.
In 2011, Hibbard suggested an intelligence measure for AGIs acting as
predictors in adversarial sequence prediction games. Hibbard's measure
depends arbitrarily on a function-sequence
imported from a paper by Liu. We argue that Hibbard's measure is trivial:
any genuine AGI should have Hibbard intelligence $\infty$,
because the functions in Liu's paper are
trivial to a genuine AGI. Our key insight is this: rather than
arbitrarily choosing a function-sequence, we can delegate that choice to an AGI.
In this way, we propose
non-trivial variations of Hibbard's original measure, which we call
relative Hibbard measures.
However, relative Hibbard measures are still flawed. To repair their flaws,
we further propose what we call transfinite Hibbard measures,
which depend on an AGI choosing a slow-growing hierarchy (from mathematical
logic) rather than a function-sequence.
\end{abstract}

\section{Introduction}

\begin{quote}
    Todo:
    \begin{enumerate}
        \item Formal theorem suggesting THM/IOI connection.
        \item More background about fast- and slow-growing hierarchies.
        \item In Example bruteforcenottotallyoptimalexample, we choose a function which
            the AGI does not know. Add a lemma showing that such functions must exist.
        \item A lemma to the effect that if X knows M is a Turing machine which computes
            f at all but finitely many points, then there exists a TM M' which computes
            f everywhere and such that X knows M' is total.
    \end{enumerate}
\end{quote}

At a high-level, this paper is about a meta-technique in theoretical research
on agents with Artificial General Intelligence (that is, on AGIs), namely:
avoiding difficult and arbitrary decisions by delegating those decisions to the
very AGIs we are studying. To speak metaphorically, suppose we were fighting about
what clothes the Oracle of Delphi should wear: such fighting could be avoided
by asking the oracle herself what clothes an Oracle of Delphi should wear. At
a low-level, this paper is about a certain specific intelligence measure, and
improvements thereon: these serve as a kind of proving ground for the
higher-level meta-technique.

In his insightful paper \cite{hibbard}, Bill Hibbard introduces a novel
intelligence measure (which we will here refer to as the \emph{original Hibbard measure})
for AGIs.
Hibbard's measure is based on a game of adversarial sequence
prediction \cite{hibbard2008adversarial}
``against a hierarchy of increasingly difficult sets of'' evaders (environments that attempt
to emit $1$s and $0$s in such a way as to evade prediction).
The levels of Hibbard's hierarchy are labelled by natural numbers\footnote{Technically,
Hibbard's hierarchy begins at level $1$ and he separately defines what it means for
an agent to have intelligence $0$, but that definition is equivalent to what would result
by declaring that the $0$th level of the hierarchy consists of the empty set of evaders.}, and
an agent's original Hibbard measure is the maximum $n\in\mathbb N$ such that
said agent learns to predict all the evaders in the $n$th level of the hierarchy,
or implicitly\footnote{Hibbard does not explicitly include the $\infty$ case in his
definition, but in his Proposition 3 he refers to agents having ``finite intelligence'', and
it is clear from context that by this he means agents who fail to predict some evader
somewhere in the hierarchy.} an agent's original Hibbard measure is $\infty$
if said agent learns to predict all the evaders in all levels of Hibbard's hierarchy.

In this paper, we will argue that the original Hibbard measure is
trivial: we will argue that \emph{all} suitably idealized AGIs should have
original Hibbard intelligence $\infty$. This is because Hibbard's hierarchy
depends on a function-sequence which is (we would argue) arbitrarily chosen,
and which happens to consist of functions which should be trivial to a genuine AGI.

We will suggest two different methods to repair Hibbard's intelligence measure.
\begin{itemize}
    \item
    The first method we describe will be elementary, in that it will
    essentially involve
    no mathematics more advanced than the mathematics used in Hibbard's original approach.
    This will yield a non-trivial family of intelligence measures,
    which we will call \emph{relative Hibbard measures}, but these will still suffer a flaw.
    \item
    The second method we describe will make use of \emph{slow-growing hierarchies}
    \cite{weiermann2002slow} (an advanced notion from mathematical logic) and will
    produce a family of ordinal-number-valued intelligence measures, which we will
    call \emph{transfinite Hibbard measures}, to avoid the above-mentioned flaw.
\end{itemize}
Both of these methods will, rather than producing a single intelligence measure,
rather, produce a family of intelligence measures indexed by a parameter $X$ where
$X$ is an AGI.
Every AGI $X$ will have a corresponding relative Hibbard measure $|\bullet|_X$
(for any AGI $Y$, $|Y|_X$ will be a natural-number-valued measurement of $Y$'s intelligence
``according to $X$'').
Every AGI $X$ will also have a corresponding transfinite Hibbard measure
$\|\bullet\|_X$
(for any AGI $Y$, $\|Y\|_X$ will be a computable-ordinal-valued measurement of $Y$'s
intelligence ``according to $X$'').

The structure of the paper is as follows.
\begin{itemize}
    \item
    In Section \ref{agiperspectivesection}, we present an idealized viewpoint of AGIs.
    \item
    In Section \ref{originalmeasuresection}, we review the original Hibbard measure.
    \item
    In Section \ref{trivialitysection}, argue that
    under certain idealizing assumptions, \emph{every} AGI probably has
    original Hibbard intelligence $\infty$.
    \item
    In Section \ref{simplemeasuresection}, we delegate an arbitrary choice
    (which Hibbard originally made by importing from a paper by Liu) to an AGI,
    thereby obtaining what we call \emph{relative Hibbard measures}.
    \item
    In Section \ref{slowgrowinghierarchysection}, we review the \emph{slow-growing hierarchy}.
    \item
    In Section \ref{transfinitehibbardsection}, we use
    slow-growing hierarchies to define what we call \emph{transfinite Hibbard measures}
    (delegating the choice of a slow-growing hierarchy to an AGI).
    \item
    In Section \ref{conclusionsection}, we summarize and make concluding remarks.
\end{itemize}

\section{An idealized viewpoint of AGIs}
\label{agiperspectivesection}

\begin{quote}
    ``Thus it is a property of man[-like intelligence] to be capable of learning
    grammar; for if he is a man[-like intelligence], then he is capable of learning
    grammar, and if he is capable of learning grammar, then he is
    a man[-like intelligence].'' ---Aristotle \cite{aristotle} (modified)
\end{quote}

As yet, we are unaware of any formal mathematical definition of what an AGI
actually is. We take the stance that an AGI should be thought of like a faithful
employee which can understand
practical conversation in a common human language (such as
English) and capable of (and faithfully willing to) obey commands
expressed by its employer in said language\footnote{Yampolskiy \cite{yampolskiy2013turing}
nicely captures this idea when he talks about reducing the Turing Test to the
problem of Programming, saying: `Having access to an Oracle capable of solving Programming
allows us to solve TT via a simple reduction. For any statement $S$ presented during
TT transform said statement into a programming assignment of the form: ``Write a
program which would respond to $S$ with a statement indistinguishable from a statement
provided by an average human{''}'.}.
So if the AGI's employer said, ``Recite the digits of pi until I tell you to
stop,'' then the AGI would begin computing and reciting digits of pi, until the
employer told it to stop (if ever). Unlike a human employee, who would eventually
get fed up with such a task, an AGI should have no fear of tedium, and should
never grow tired of performing whatever task it has been assigned (we assume
the AGI never runs out of memory and can indeed run forever, just like a Turing
machine is routinely assumed to be able to run forever and have infinite tape).

We think assumptions similar to the above are implicit in many attempts to study AGIs.
Many authors who set out to study
AGIs actually study not the full AGI, but rather the AGI's persona when it is
performing some general type of task. For example:
\begin{itemize}
    \item
    In the Turing Test, the AGI is reduced to a conversation partner pretending to
    be human.
    An AGI is more than a pretend human conversation partner;
    but an AGI would act as a pretend human conversation partner
    if commanded to do so.
    \item
    In Hibbard's paper \cite{hibbard}, the AGI is reduced to a predictor in an
    adversarial sequence prediction game.
    An AGI is more than a predictor; but an AGI would
    act as such a predictor if commanded to do so.
    \item
    Some authors \cite{legg} \cite{hernandez}
    reduce the AGI to a reinforcement learning agent.
    An AGI is more than a reinforcement
    learning agent; but an AGI would
    act as a reinforcement learning agent if commanded to do so.
    \item
    Some philosophers
    reduce the AGI to a mere \emph{knower} who performs
    no actions but simply knows things in some formal language, or, equivalently,
    to a formal theory (namely the list of all the things it knows).
    An AGI is more than a mere knower
    or theory \cite{wang2007three};
    but an AGI would act as a mere knower (and give rise to a resulting theory)
    if commanded to do so.
    \item
    In the Non-Axiomatic Reasoning System research program (NARS) \cite{nars},
    it is hoped that an AGI can be realized via the implementation of what is,
    essentially, a special type of database capable of being bombarded by
    many (possibly conflicting) assertions in a certain formal language
    and of outputting probabilistic answers to realtime queries about said
    assertions. An AGI is more
    than a mere database; but
    an AGI would act as such a database if commanded to do so.
\end{itemize}
In the same way that IQ tests are intended to measure human intelligence despite
the fact that humans are more than professional IQ-test-takers,
likewise, the above cross-sections of AGI serve to illuminate AGI
even though none of them capture the full AGI. Many of these kind of
cross-sections\footnote{Or rather, the task of doing \emph{good} at these
cross sections---whatever
that means---for anyone can easily program a Turing Test participant that just
repeats the same phrase over and over again, but that is not an example of
doing the Turing Test well. Anyone can program a reinforcement learning agent that
acts pseudo-randomly, but that is not an example of doing reinforcement learning well.}
are probably examples of so-called \emph{AI-Complete} problems
\cite{yampolskiy2012ai} \cite{yampolskiy2013turing}.

\begin{remark}
\label{temporalremark}
    Throughout this paper, whenever we speak of an AGI, we really mean the
    state of a general-artificially intelligent agent's mind at an instant in time.
    To illustrate this, imagine a robot which possesses artificial general intelligence.
    Suppose at time $t$ the robot observes something which updates its knowledge.
    Then we consider the same robot to define at least two distinct AGIs, one AGI
    immediately before time $t$, and another
    immediately after time $t$.
    Whenever we speak of the outputs which an AGI would make in response to some
    command, we implicitly mean the hypothetical outputs which the AGI would make
    if, immediately upon receiving the command, the AGI were isolated from all
    external stimulus.
\end{remark}

Remark \ref{temporalremark} is illustrated by the following
informal lemma.

\begin{informallemma}
\label{teachinglemma}
    If $X$ is an AGI and $\phi$ is a true sentence in the language of Peano arithmetic
    such that $X$ does not know $\phi$, then there exists an AGI $Y$ such that:
    \begin{enumerate}
        \item
        $Y$ knows $\phi$.
        \item
        For every sentence $\psi$ in the language of Peano arithmetic,
        if $X$ knows $\psi$, then $Y$ knows $\psi$.
    \end{enumerate}
    In fact, $Y$ can be obtained from $(X,\phi)$ in an effective way, by which we mean
    that there is a computable function $F$ which takes two inputs $(x,y)$ such that
    if $x$ encodes AGI $X$ and $y$ encodes true sentence $\phi$ of Peano arithmetic
    then $F(x,y)$ encodes AGI $Y$ as above.
\end{informallemma}

\begin{proof}[Informal proof]
    Let $Y$ be the AGI which would result immediately after $X$ were given the command:
    ``Know $\phi$; in other words, henceforward, operate under the assumption
    that $\phi$ is true.'' Then $Y$ knows $\phi$ by construction, and $Y$ knows
    every sentence $\psi$ in the language of Peano arithmetic that $X$ knows
    (because the indicated command should not cause $X$ to suddenly doubt any
    previously known arithmetical facts---note that since $\phi$ is true, $X$
    did not previously know $\neg\phi$, or anything else inconsistent with $\phi$,
    since knowledge is truthful). This process is clearly effective, so the second
    part of the Informal Lemma follows by Church's Thesis.
\end{proof}

Note that part (2) of Informal Lemma \ref{teachinglemma} might fail if
$\psi$ were not restricted to purely arithmetical formulas.
For example, assume $P\neq NP$ and let $\phi$ express $P\neq NP$.
It could very well be that $X$ knows that ``I do not know $\phi$''---i.e., that
$X$ knows ``$\neg K(\phi)$'' (a formula in the language of Epistemic Arithmetic
\cite{shapiro})---but that $Y$, having been taught that $\phi$ is true,
no longer knows ``I do not know $\phi$''.

\begin{assumption}
\label{idealizingassumption}
    We make the following idealizing assumptions about every AGI $X$.
    \begin{itemize}
        \item
        (Basic mathematical exposure) $X$ knows the axioms of ZFC (the axiomatic
        system underlying mainstream mathematics).
        \item
        (Mathematical truthfulness) If $X$ knows some statement in the language
        of ZFC, then that statement is true.
        \item
        (Mathematical reasoning ability) If $X$ knows some set $S$ of mathematical
        axioms then, given sufficient time to think about it, $X$ would eventually
        become aware of all the consequences of $S$.
        \item
        (Caution) $X$ avoids getting stuck: If $X$ is commanded to carry out any
        task which involves outputting things
        forever, and if the task is not impossible
        (e.g., does not require solving the Halting Problem or doing other
        non-computable or nonsensical things),
        then $X$ will continue outputting things (perhaps
        after long intervals of time between outputs) indefinitely.
        \item
        (Mechanicalness) If $X$ is commanded to carry out a task
        which involves outputting things forever, and if those outputs depend only on
        $X$'s own decisions (not on any external stimulus),
        then the resulting outputs will
        be computably enumerable (in other words, some Turing machine could
        generate said outputs).
    \end{itemize}
\end{assumption}

Concerning the \emph{mechanicalness} part of Assumption \ref{idealizingassumption},
it is important to keep in mind that although the assumption guarantees that if $C$
is any such command, there exists a Turing machine $M$ which computes enumerates
$X$'s outputs in response to command $C$, nevertheless:
\begin{enumerate}
    \item
    It is not necessarily the case that $X$ knows that $M$
    enumerates an infinite list.
    \item
    Even if $X$ does know that $M$ enumerates an infinite list, it is not necessarily
    the case that $X$ knows that the list enumerated by $M$ is the list of things
    $X$ would output in response to command $C$.
\end{enumerate}
We will give two examples to illustrate the above two caveats.

\begin{definition}
\label{functionsuccdefn}
For any $f,g:\mathbb N\to\mathbb N$, write $f\succ g$ as shorthand for the statement
that there is some $i\in\mathbb N$ such that for all $x\geq i$, $f(x)>g(x)$.
\end{definition}

\begin{example}
\label{counterintuitiveexample1}
    Suppose $X$ is commanded: ``Output Turing machines $M_0,M_1,\ldots$
    such that each $M_i$ computes a total function $f_i:\mathbb N\to\mathbb N$,
    and such that each $f_{i+1}\succ f_i$, and such that for every Turing machine $M$
    such that you know $M$ computes a total function $f:\mathbb N\to\mathbb N$,
    there exists some $i$ such that $f_i>f$.'' By \emph{mechanicalness}, there
    exists a Turing machine $T$ which enumerates $M_0,M_1,\ldots$.
    But $X$ does not know that $T$ enumerates an infinite list.
\end{example}

\begin{proof}
    Assume (for sake of contradiction) that $X$ knows that $T$ enumerates an
    infinite list. Since $X$ is capable of basic mathematical reasoning, it follows
    that $X$ knows that Turing machine $M$ defines a total function $f:\mathbb N\to\mathbb N$,
    there $M$ is the Turing machine which takes input $n\in\mathbb N$ and proceeds as
    follows:
    \begin{enumerate}
        \item
        Run $T$ until it has outputted Turing machines $M_0,\ldots,M_n$. (If $T$
        ever outputs something that is not a Turing machine, halt and output $0$.)
        \item
        For each $i\leq n$, run $M_i$ on input $n$ until it outputs a natural
        number $m_{n,i}$.
        \item
        Output $\max\{m_{n,0},\ldots,m_{n,n}\}+1$.
    \end{enumerate}
    Above, since each $M_i$ computes $f_i$, it follows that each $m_{n,i}=f_i(n)$.
    Thus, for each $i$, $f\succ f_i$, because for all $x\geq i$,
    $f(x)=\max\{m_{x,0},\ldots,m_{x,x}\}+1\geq m_{x,i}+1=f_i(x)+1$.
    But by assumption, since $X$ knows that $M$ computes a total function from
    $\mathbb N$ to $\mathbb N$, there is some $i$ such that
    $f_i\succ f$. So $f\succ f_i$ and $f_i\succ f$, a contradiction.
\end{proof}

\begin{example}
\label{counterintuitiveexample2}
    (G\"odel's incompleteness theorem)
    Assume $X$ knows that its own knowledge is truthful.
    Suppose $X$ is commanded by command $C$:
    ``Output all the true statements (in the language of
    Peano arithmetic) that you know are true.'' Let the resulting statements be
    $\phi_0,\phi_1,\ldots$. By \emph{mechanicalness}, there is a Turing machine $M$
    such that $M$ enumerates $\phi_0,\phi_1,\ldots$. Then $X$ does not know
    ``$M$ enumerates the list of things I would output in response to $C$''.
\end{example}

\begin{proof}
    Assume (for sake of contradiction) that $X$ knows ``$M$ enumerates the
    list of things I would output in response to $C$''.
    Then, since $X$ knows that its own knowledge is truthful,
    $X$ knows that $M$ enumerates a list of true statements of Peano arithmetic
    (because $X$ knows that it knows all statements output in response to $C$).
    Of course, this fact $\Phi$---that $M$ enumerates a list of true statements of Peano
    arithmetic---is not itself expressible in Peano arithmetic, by Tarski's
    undefinability theorem \cite{tarski1936wahrheitsbegriff},
    and therefore this fact need not be one of the $\phi_i$'s.
    However, $\Phi$ implies (and hence $X$ should know)
    a weaker fact $\Phi'$, namely, that $M$ enumerates a consistent
    list of statements of Peano Arithmetic. This consistency statement $\Phi'$ \emph{is}
    expressible in Peano arithmetic, and thus since $X$ knows it,
    there is some $i$ such that $\Phi'=\phi_i$. Thus, $T=\{\phi_0,\phi_1,\ldots\}$
    is a computably enumerable
    theory (in the language of Peano arithmetic) which is true, and which
    includes the axioms of Peano arithmetic (since $X$ knows those), and which
    includes a statement $\Phi'$ stating its own consistency. This is a contradiction
    because it violates G\"odel's second incompleteness theorem.
\end{proof}

\section{Hibbard's original measure}
\label{originalmeasuresection}

Hibbard's intelligence measure is based on the AGI's performance against
many opponents in a game of adversarial sequence prediction (we define this
formally below). The AGI acts as
a predictor $p$ which competes against evaders $e$. In each step of the game,
both predictor and evader simultaneoulsy choose a binary digit, $1$ or $0$.
Only after both of them have made their choice do they see which choice the other
one made, and then the game proceeds to the next step. The predictor's goal in
each step of the game is to choose the same digit that the evader will choose;
the evader's goal is to choose a different digit than the predictor. The predictor
wins the game (and is said to \emph{learn to predict $e$}) if, after finitely many
initial steps, eventually the predictor always chooses the same digit as the
evader.

\begin{definition}
By $B$, we mean the binary alphabet $\{0,1\}$. By $B^*$, we mean the set of all
finite binary sequences. By $\langle\rangle$ we mean the empty binary sequence.
\end{definition}

\begin{definition}
\label{evaderpredictordefn}
    (Predictors and evaders)
    \begin{enumerate}
        \item
        By a \emph{predictor}, we mean a Turing machine $p$
        which takes as input a finite (possibly empty) binary sequence
        $(x_1,\ldots,x_n)\in B^*$
        (thought of as a sequence of \emph{evasions})
        and outputs $0$ or $1$ (thought of as a \emph{prediction}), which output
        we write as $p(x_1,\ldots,x_n)$.
        \item
        By an \emph{evader}, we mean a Turing machine $e$
        which takes as input a finite (possibly empty) binary sequence
        $(y_1,\ldots,y_n)\in B^*$
        (thought of as a sequence of \emph{predictions})
        and outputs $0$ or $1$ (thought of as an \emph{evasion}), which output
        we write as $e(y_1,\ldots,y_n)$.
        \item
        For any predictor $p$ and evader $e$, the \emph{result of $p$ playing the
        game of adversarial prediction against $e$} (or more simply, the \emph{result of
        $p$ playing against $e$}) is the infinite binary sequence
        $(x_1,y_1,x_2,y_2,\ldots)$
        defined as follows:
        \begin{enumerate}
            \item
            The first evasion
            $x_1=e(\langle\rangle)$ is
            the output of $e$ when run on the empty prediction-sequence.
            \item
            The first prediction
            $y_1=p(\langle\rangle)$ is
            the result of applying $p$ to the empty evasion-sequence.
            \item
            For all $n>0$, the $(n+1)$th evasion
            $x_{n+1}=e(y_1,\ldots,y_n)$ is
            the output of $e$ on the sequence of the first $n$ predictions.
            \item
            For all $n>0$, the $(n+1)$th prediction
            $y_{n+1}=p(x_1,\ldots,x_n)$ is
            the result of applying $p$ to the first $n$ evasions.
        \end{enumerate}
        \item
        Suppose $r=(x_1,y_1,x_2,y_2,\ldots)$ is the result of a predictor $p$ playing
        against an evader $e$. For every $n\geq 1$,
        we say \emph{the predictor wins round $n$ in $r$}
        if $x_n=y_n$; otherwise,
        \emph{the evader wins round $n$ in $r$}.
        We say that \emph{$p$ learns to predict $e$}
        (or simply that \emph{$p$ learns $e$}) if there is some $N\in\mathbb N$
        such that for all $n>N$, $p$ is the winner of round $n$ in $r$.
    \end{enumerate}
\end{definition}

Note that if $e$ simply ignores its inputs $(y_1,\ldots,y_n)$ and instead
computes $e(y_1,\ldots,y_n)$ based only on $n$, then $e$ is essentially a sequence.
Thus Definition \ref{evaderpredictordefn} is a generalization of sequence prediction,
which many authors have written about (such as \cite{legg2006there}, who gives many
references).

The following definition makes explicit a subtlety which is implicit in Hibbard's
original paper.

\begin{definition}
\label{Xspredictordefn}
    Suppose $X$ is an AGI. By \emph{$X$'s predictor}, we mean the predictor which
    $X$ would act as if $X$ were commanded to act as a predictor as in
    Definition \ref{evaderpredictordefn}.
\end{definition}

In the following definition, we differ from Hibbard's original paper
because of a minor (and fortunately, easy-to-fix) error there.

\begin{definition}
\label{tsubedefinition}
    Suppose $M$ is any Turing machine which computes a total function from $B^*$ to $B$.
    For any $n\in\mathbb N$, let $T_M(e)$ be the maximum number of steps that $M$ takes
    to run on any length-$n$ sequence of binary digits.
    In other words, $t_M(0)$ is the number of steps $M$ takes to run on $\langle\rangle$,
    and for all $n>0$,
    \[
        t_M(n) = \max_{b_1,\ldots,b_n\in \{0,1\}}
        (\text{number of steps $M$ takes to run on $(b_1,\ldots,b_n)$}).
    \]
\end{definition}

\begin{example}
    Let $e$ be an evader. Then
    $t_e(2)$ is equal to the number of steps $e$ takes to run on input
    $(0,0)$, or to run on input $(0,1)$, or to run on input $(1,0)$, or to run on input
    $(1,1)$---whichever of these four possibilities is largest.
\end{example}

\begin{definition}
\label{evadersetdefinition}
    (The evader-set bounded by a function)
    Suppose $f:\mathbb N\to\mathbb N$. We define the \emph{evader-set bounded by $f$},
    written $E_f$, to be the set of all evaders $e$ such that
    there is some $k\in\mathbb N$ such that $\forall n>k$,
    $t_e(n)<f(n)$.
\end{definition}

In the following broad definition, for every function-sequence of functions
from $\mathbb N$ to $\mathbb N$, we define a corresponding intelligence measure
for AGIs.
The original Hibbard measure is a special case for one specific
such function-sequence.

\begin{definition}
\label{generalintelligencemeasuredefn}
    (The general Hibbard measure given by a function-sequence)
    Suppose $(g_1,g_2,\ldots)$ is a function-sequence,
    each $g_i:\mathbb N\to\mathbb N$.
    For each $m\in\mathbb N$, define $f_m:\mathbb N\to\mathbb N$ by
    \[f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g_i(j).\]
    For any AGI $X$, we define the \emph{Hibbard intelligence of $X$
    given by $(g_1,g_2,\ldots)$}, written $|X|_{(g_1,g_2,\ldots)}$, as follows.
    Let $p$ be $X$'s predictor (Definition \ref{Xspredictordefn}).
    We define $|X|_{(g_1,g_2,\ldots)}$ to be the maximum $m>0$
    such that $p$ learns to predict $e$ for every $e\in E_{f_m}$
    (or $0$ if there is no such $m$, or $\infty$ if $p$ learns to predict $e$
    for every $e\in E_{f_m}$ for every $m$).
\end{definition}

\begin{definition}
\label{classichibbardmeasuredefn}
    The \emph{original Hibbard measure} is defined to be the Hibbard intelligence
    measure given by one specific family $(g_1,g_2,\ldots)$ of functions, namely:
    Liu's \cite{liu1960enumeration} enumeration of the primitive recursive
    functions.
\end{definition}


\section{Do all AGIs have original Hibbard intelligence $\infty$?}
\label{trivialitysection}

In this section, we will argue that under certain idealizing
assumptions, every AGI should have original Hibbard intelligence $\infty$.
Thus, we would suggest that Definition \ref{classichibbardmeasuredefn} is really
only appropriate for certain weak AIs who are strong enough that they can be
induced to participate in adversarial sequence prediction games, but who are
too weak to qualify as genuine AGIs.


\subsection{A semi-optimal predictor}
\label{semioptimalpredictorsubsection}

The most obvious way to try to predict an evader would be to
enumerate some list $M_1,M_2,\ldots$ of Turing machines and
sequentially try to predict $e$ by assuming $e$ computes the same
function as $M_1$, and if that ever fails, then predict $e$ by
assuming $e$ computes the same function as $M_2$, and if that ever
fails, then predict $e$ by assuming $e$ computes the same function
as $M_3$, and so on. In doing so, we should limit ourselves
to Turing machines $M_i$ which define total functions, lest
we end up waiting forever for a non-terminating computation
and never getting around to making our next
prediction. Unfortunately, the set of total Turing machines is
not computably enumerable, so the best we can hope for is to enumerate
some subset of the total Turing machines. But which subset? This is
a tricky and arbitrary decision---thankfully, we do not need to
decide it ourselves, we can let the AGI decide for us.

\begin{definition}
\label{bruteforcepredictordefn}
    (Brute-Force Predictors)
    Suppose $X$ is an AGI. Let $M_1,M_2,\ldots$ be the list of Turing machines
    which $X$ would enumerate if $X$ were commanded: ``Enumerate all the Turing
    machines which you know define total functions from $B^*$ to $B$''.
    By \emph{$X$'s brute-force predictor}, we mean the predictor $p$ defined
    as follows.
    \begin{enumerate}
        \item
        Initially, $p$ shall attempt to predict the evader $e$ by assuming that $e$
        defines the same function as $M_1$. When (if ever) this fails,
        say that \emph{$M_1$ is ruled out from being the evader}.
        \item
        Once $M_1$ has been ruled out from being the evader (if ever),
        $p$ shall attempt to predict $e$ by assuming that $e$ defines the same
        function as $M_2$. When (if ever) this fails,
        say that \emph{$M_2$ is ruled out from being the evader}.
        \item
        Once $M_2$ has been ruled out from being the evader (if ever),
        $p$ shall attempt to predict $e$ by assuming that $e$ defines the same
        function as $M_3$. When (if ever) this fails,
        say that \emph{$M_3$ is ruled out from being the evader}.
        \item
        And so on forever...
    \end{enumerate}
\end{definition}

Note that $X$'s brute-force predictor
is total precisely because of the mathematical truthfulness assumption
(from Definition \ref{idealizingassumption}): whenever $X$ knows that
$M_i$ defines a total function from $B^*$ to $B$, $M_i$ really \emph{does}
define a total function from $B^*$ to $B$ (hereafter, we will suppress
remarks like this and routinely use the mathematical truthfulness assumption
without explicit mention).

\begin{lemma}
\label{knowingimplieslearninglemma}
    Let $X$ be an AGI and let $e$ be an evader (so $e$ is a Turing machine which
    computes a function from $B^*$ to $B$).
    Let $M$ be any Turing machine which computes the same function from $B^*$ to $B$
    as $e$ computes.
    If $X$ knows that $M$ defines a total function from $B^*$ to $B$,
    then $X$'s brute-force predictor learns to predict $e$.
\end{lemma}

\begin{proof}
    Let $p$ be $X$'s brute-force predictor.
    Let $M_1,M_2,\ldots$ be as in Definition \ref{bruteforcepredictordefn}.
    Since $X$ knows that $M$ defines a total
    function from $B^*$ to $B$,
    it follows that $M=M_k$ for some $k$.
    When $p$ plays against $e$, it cannot occur that $M_k$ is ruled out
    from being the evader, because in order for that to occur, $p$ would have
    to fail at predicting $e$ when $p$ assumes that $e$ computes the same
    function as $M_k$, but that cannot fail because that assumption is true.
    Since $M_k$ cannot be ruled out from being the evader, it follows that
    step $k+1$ of Definition \ref{bruteforcepredictordefn} will never be
    reached, which in turn implies that $p$ stops failing at predicting $e$
    after finitely many initial failures, in other words, $p$ learns to
    predict $e$.
\end{proof}

For any AGI $X$, we would like to claim that $X$'s brute-force predictor is
optimal among all predictors $X$ could act as; unfortunately this
is not true in the strongest sense it possibly could be true, as the following
example shows.

\begin{example}
\label{bruteforcenottotallyoptimalexample}
    Let $X$ be an AGI. Let $f:\mathbb N\to B$ be a total computable function
    which is not computed\footnote{Such an $f$ must exist because
    otherwise, $X$ could enumerate all the total
    computable functions from $\mathbb N$ to $B$, which is absurd because those functions
    are not computably enumerable.} by any Turing machine $M$ such that $X$ knows $X$ computes
    a total function from $\mathbb N$ to $B$.
    For each $i\in\{0,1\}$, let $e_i$ be an evader such that:
    \begin{align*}
        e_i(\langle\rangle) &= i,\\
        e_i(y_1,\ldots,y_n) &=
        \begin{cases}
            i &\mbox{if $y_1=\cdots=y_n=i$,}\\
            f(n) &\mbox{otherwise.}
        \end{cases}
    \end{align*}
    For each $i\in\{0,1\}$, let $p_i$ be a
    constantly-$i$ predictor, $p_i(x_1,\ldots,x_n)=i$.
    Then $p_0$ learns to predict $e_0$ and $p_1$ learns to predict $e_1$,
    but $X$'s brute-force predictor learns to predict at most one of $e_0$ or $e_1$.
\end{example}

\begin{proof}
    Clearly the result of $p_0$ playing against $e_0$ is
    $(x_0,y_0,x_1,y_1,\ldots)=(0,0,0,0,\ldots)$, so $p_0$ learns to predict $e_0$.
    Likewise, the result of $p_1$ playing against $e_1$ is
    $(x_0,y_0,x_1,y_1,\ldots)=(1,1,1,1,\ldots)$, so $p_1$ learns to predict $e_1$.
    It remains to show that $X$'s brute-force predictor $p$ cannot learn to predict
    both $e_0$ and $e_1$.

    Let $M_1,M_2,\ldots$ be as in Definition \ref{bruteforcepredictordefn}.
    Let $g:B^*\to B$ be the function computed by $M_1$.

    Case 1: $g(\langle\rangle)=1$. Then when $p$ plays against $e_0$,
    after the first step, it will never be the case that
    $y_1=\cdots=y_n=0$ (because $y_1=g(\langle\rangle)=1$).
    Thus, for all $n>0$, $e_0(y_1,\ldots,y_n)=f(n)$.
    I claim that $p$ does not learn $e_0$.
    To see this, assume (for the sake of contradiction)
    that $p$ learns $e_0$. It follows that there is some $k$ (which we may take
    as small as possible) such that $M_k$ never gets ruled out from being the
    evader (Definition \ref{bruteforcepredictordefn}). Let $h:B^*\to B$ be the
    function defined by $M_k$.
    Let $(x_0,y_0,x_1,y_1,\ldots)$ be the result of $p$ playing against $e_0$.
    It follows that there is some $j$ such that for all $i>j$,
    $h(y_1,\ldots,y_{i-1})=x_i=y_i=f(i)$.
    This shows that for all but finitely many $i\in\mathbb N$,
    $f(i)=h(y_1,\ldots,y_{i-1})$. Since $X$ knows that $M_k$ defines a total
    function from $B^*$ to $B$, it follows that
    there is a Turing machine $M$ such that $M$ computes $f$ and $X$ knows
    $M$ computes a total function from $\mathbb N$ to $B$. Absurd, this
    contradicts our choice of $f$.

    Case 2: $g(\langle\rangle)=0$. Then by similar reasoning as in Case 1,
    it can be shown that $p$ does not learn $e_1$.
\end{proof}

Example \ref{bruteforcenottotallyoptimalexample} shows that we cannot
hope for the brute-force to be totally optimal in the most extreme possible sense:
there will always be evaders that the AGI's brute-force predictor
fails to learn, but which other
predictors (which the AGI is capable of acting as)
do nevertheless learn. Example \ref{bruteforcenottotallyoptimalexample} involves
highly contrived evaders which are custom-made to act stupidly in one specific case
(allowing them to be learned by stupid predictors), while being
highly sophisticated in other cases. In the following definition, we rule out
situations where a less sophisticated predictor manages to learn a
more sophisticated evader due to the evader concealing its true sophistication from
the predictor.

\begin{definition}
\label{notwithoutafightdefn}
    Suppose $p$ is a predictor and $e$ is an evader.
    We say that \emph{$p$ learns $e$ but-not-without-a-fight}
    if the following conditions hold:
    \begin{enumerate}
        \item $p$ learns $e$.
        \item For each $i$, $t_p(i)\geq t_e(i)$.
    \end{enumerate}
\end{definition}

Armed with Definition \ref{notwithoutafightdefn}, we can now state a theorem
which shows the semi-optimality of the brute-force predictor.

\begin{theorem}
\label{semioptimalitytheorem}
    (Semi-optimality of brute force)
    Let $X$ be an AGI and let $p$ be any predictor.
    If $X$ knows that $p$ computes a total function from $B^*$ to $B$,
    and if $p$ learns an evader $e$ but-not-without-a-fight,
    then $X$'s brute-force predictor learns $e$.
\end{theorem}

\begin{proof}
    Since $X$ knows $p$ computes a total
    function from $B^*$ to $B$, $X$ knows that $e'$ is a total
    computable function from $B^*$ to $B$, where $e'$ is the Turing machine which
    takes an input $b\in B^*$ and operates as follows:
    \begin{enumerate}
        \item
        Calculate $t_p(i)$ (by running $p$ on all length-$i$ binary sequences).
        \item
        Run $e$ on $b$ for up to $t_p(i)$ steps. If $e$ outputs a result $x$ within that
        time, then output $x$. Otherwise, output $0$.
    \end{enumerate}
    Since $p$ learns $e$ but-not-without-a-fight, each $t_p(i)\geq t_e(i)$,
    so in fact $e'$ computes the same function as $e$.
    By Lemma \ref{knowingimplieslearninglemma}, $X$'s brute-force predictor
    learns $e'$. Since $e'$ and $e$ compute the same function, this implies
    $X$'s brute-force predictor learns $e$.
\end{proof}

\subsection{Triviality of the original Hibbard measure}
\label{trivialitysubsection}

Although Example \ref{bruteforcenottotallyoptimalexample} showed that
an AGI $X$'s brute-force predictor
is not optimal in the strongest possible sense, Theorem \ref{semioptimalitytheorem}
shows that $X$'s brute-force predictor is still semi-optimal. In some sense,
$X$'s brute-force predictor learns every evader which any other predictor $p$ (that $X$
knows is a predictor) would learn, except possibly for cases where $p$ only learns
an evader $e$ because $e$ conceals its full sophistication from $p$.

Since we only used basic mathematics to prove Theorem \ref{semioptimalitytheorem},
any genuine AGI should also eventually figure out Theorem \ref{semioptimalitytheorem}.
Thus, when an AGI is commanded to compete as a predictor in the adversarial
sequence prediction game, the resulting predictor which the AGI acts as should be
at least as good as the brute-force predictor, because why would the AGI act as
a worse predictor if it can figure out that brute-force is semi-optimal?
We formalize this in the following assumption.

\begin{assumption}
\label{bruteforceassumption}
    For every AGI $X$, $X$'s predictor is at least as good as
    $X$'s brute-force predictor, by which we mean that for every evader $e$,
    if $X$'s brute-force predictor learns $e$, then $X$'s predictor
    learns $e$.
\end{assumption}

Based on Assumption \ref{bruteforceassumption},
we are now ready to argue that the original Hibbard measure is
trivial: that it assigns intelligence level $\infty$ to every AGI.

\begin{theorem}
    Every AGI $X$ has original Hibbard intelligence $\infty$.
\end{theorem}

\begin{proof}
    Let $p$ be $X$'s brute-force predictor, and let $q$ be $X$'s predictor.
    By Definition \ref{generalintelligencemeasuredefn}, in order
    to show $X$ has original Hibbard intelligence $\infty$, we must
    show that $q$ learns to predict $e$ for every $e$ in $E_{f_m}$ for
    every $m\in\mathbb N$,
    where each $f_m:\mathbb N\to\mathbb N$ is defined by
    $f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g_i(j)$,
    where $g_i$ is the $i$th primitive recursive function
    in Liu's enumeration
    (Definition \ref{classichibbardmeasuredefn}).
    By Assumption \ref{bruteforceassumption}, it suffices to show that
    $q$ learns all such $e$, for then Assumption \ref{bruteforceassumption}
    says that $p$ learns all such $e$ as well.

    Let $m\in\mathbb N$ be arbitrary and let $e\in E_{f_m}$ be arbitrary.
    By Definition \ref{evadersetdefinition},
    for all but finitely many $n\in\mathbb N$, $t_e(n)<f_m(n)$.
    We will show that $p$ learns to predict $e$.

    Let $M$ be a Turing machine which takes an input
    $(y_1,\ldots,y_n)\in B^*$ and
    operates as follows:
    \begin{itemize}
        \item
        Spend up to $f_m(n)$ steps computing $e(y_1,\ldots,y_n)$.
        If $e$ halts (with output $x$) during that time, then output $x$.
        Otherwise, output $0$.
    \end{itemize}
    Since, for all but finitely many $n\in\mathbb N$, $t_e(n)<f_m(n)$,
    it follows that $M$ computes the same function as $e$ except for finitely
    many exceptions.

    It is well-known that for every primitive recursive function $g$, Peano
    arithmetic proves that $g$ is total. Thus, by the \emph{basic mathematical
    exposure} and \emph{mathematical reasoning ability} assumptions from
    Assumption \ref{idealizingassumption}, it follows that $X$ knows that
    $M$ is total. Since $M$ computes the same function as $e$ except for
    finitely many exceptions, it follows that there is a Turing machine $M'$
    which computes the same function as $e$, and such that $X$
    knows that $M'$ is total. By Lemma \ref{knowingimplieslearninglemma},
    $p$ learns to predict $e$.
\end{proof}

We will finish this section by stating one other important, possibly
counterintuitive consequence of Assumption \ref{bruteforceassumption}.

\begin{theorem}
\label{counterintuitivetheorem}
    If $X$ is an AGI and $p$ is $X$'s predictor, then $X$ does not know that
    $p$ defines a total function from $B^*$ to $B$.
\end{theorem}

\begin{proof}
    Let $e$ be the evader which attempts to evade the predictor by assuming that
    the predictor is $p$ and always playing the opposite digit which $p$ is
    about to play. Clearly $p$ does not learn $e$.

    The fact that $e$ defines a total function from $B^*$ to $B$ follows
    by basic mathematical reasoning from the fact that $p$ defines a total
    function from $B^*$ to $B$. Thus, if $X$ knows that $p$ defines a total
    function from $B^*$ to $B$, then $X$ should know that $e$ defines a total
    function from $B^*$ to $B$. If so, then $X$'s brute-force predictor learns
    $e$ by Lemma \ref{knowingimplieslearninglemma}. But then
    Assumption \ref{bruteforceassumption} would imply that $p$ learns $e$,
    a contradiction.
\end{proof}

Theorem \ref{counterintuitivetheorem} is reminiscent of
Examples \ref{counterintuitiveexample1} and \ref{counterintuitiveexample2}.


\section{Relative Hibbard measures}
\label{simplemeasuresection}

In Subsection \ref{trivialitysubsection}, we argued that every AGI has
intelligence $\infty$ according to the original Hibbard measure.
In this section, we will present a family of variations of the original Hibbard measure
which do not assign intelligence $\infty$ to every AGI.
This family will contain
one intelligence measure for each AGI $X$, which measure one might think of informally as
a measure of ``intelligence as judged by $X$''.

The original Hibbard measure depends on a particular function-sequence. Hibbard chose
one specific function-sequence, namely the enumeration from Liu \cite{liu1960enumeration}.
Our method here is not to choose a function-sequence by ourselves, but instead to
delegate that choice to an AGI.

\begin{definition}
\label{functionlistdefinition}
    If $X$ is an AGI, let $(C^X_1, C^X_2, \ldots)$ be the sequence of
    Turing machines which would result if $X$ were commanded:
    \begin{quote}
        ``Until further notice, list Turing machines which compute total
        functions $g_1,g_2,\ldots$ from $\mathbb N$ to $\mathbb N$, such that
        each $g_{i+1}\succ g_i$ (Definition \ref{functionsuccdefn}),
        and such that for every Turing machine $C$ that you know computes
        a total function $f:\mathbb N\to\mathbb N$,
        there is some $i$ such that $g_i\succ f$.''
    \end{quote}
    For each $i>0$, let $g^X_i:\mathbb N\to\mathbb N$ be the function computed by
    $C^X_i$.
\end{definition}

For example, if $X$ is an AGI, then in response to the command in Definition
\ref{functionlistdefinition}, $X$ might think for a while, figure out a Turing
machine $C^X_1$ which computes the identity function $g^X_1(n)=n$. Then $X$
might think some more and figure out a Turing machine $C^X_2$ which computes
the function $g^X_2(n)=2n$. Then $X$ might think some more and figure
out a Turing machine $C^X_3$ which computes the function $g^X_3(n)=3n$.
Now, $X$ might feel lazy and want to continue that pattern forever, so that
the next functions would be $4n$, $5n$, etc., but the latter part of the command in
Definition \ref{functionlistdefinition} rules this sort of laziness out, so $X$
eventually has to move on to bigger functions like $n^2$, $n^n$,
$n^{n^{n^{n}}}$,
and so on ($X$ must know about these because we assumed $X$ has basic mathematical
knowledge and reasoning ability).

\begin{definition}
    For any AGI $X$, the \emph{relative Hibbard measure given by $X$}
    is defined to be the Hibbard measure
    $|\bullet|_{(g^X_1,g^X_2,\ldots)}$
    given by
    $(g^X_1,g^X_2,\ldots$) (see Definition \ref{generalintelligencemeasuredefn}).
    For any AGI $Y$, we will write $|Y|_X$ for $|Y|_{(g^X_1,g^X_2,\ldots)}$.
\end{definition}

\subsection{Non-triviality of the relative Hibbard measures}

We will now argue that at least for certain AGIs $X$,
the relative Hibbard measure given by $X$ does not assign intelligence $\infty$
to every AGI: but that, at least for certain AGIs $X$, there exist AGIs $Y$
such that $|Y|_X<\infty$.

\begin{theorem}
\label{simplehibbardnontrivialtheorem}
    (Non-triviality of relative Hibbard measures)
    Suppose $X$ and $Y$ are AGIs. Let $p$ be $Y$'s predictor.
    If $X$ knows that $p$ defines a total function from $B^*$ to $B$,
    then $|Y|_X<\infty$.
\end{theorem}

\begin{proof}
    Let $e$ be the evader which attempts to evade the predictor by assuming
    that the predictor is $p$ and always outputting the opposite of what
    the predictor will output based on that assumption. Clearly, $p$ does
    not learn to predict $e$.

    Since $X$ knows that $p$ defines a total function from $B^*$ to $B$,
    it follows that there is a Turing machine $C$ such that:
    \begin{enumerate}
        \item
        $C$ computes the function $g:\mathbb N\to \mathbb N$ defined by
        $g(n)=t_e(n)$, where $t_e$ is as in Definition \ref{tsubedefinition}.
        \item
        $X$ knows that $C$ computes a total function from $\mathbb N$ to $\mathbb N$.
    \end{enumerate}
    By (2), there is some $m$ such that $g^X_m\succ g$
    (by the second part of the command in Definition \ref{functionlistdefinition}).
    So if $f_m:\mathbb N\to\mathbb N$ is defined
    (as in Definition \ref{generalintelligencemeasuredefn})
    as $f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g^X_i(j)$,
    then for all but finitely many $k$, $f_m(k)\geq g^X_m(k)>g(k)=t_e(k)$.
    This shows that $e\in E_{f_m}$ (from Definition \ref{evadersetdefinition}).
    Since $p$ does not learn to predict $e$,
    it is not the case that $p$ learns to predict every evader in $E_{f_m}$.
    Therefore, $|Y|_X<m$.
\end{proof}

In particular, if $X$ knew that $X$'s own predictor computed a total function
from $B^*$ to $B$, then we would have $|X|_X<\infty$.
But we saw in Theorem \ref{counterintuitivetheorem} that $X$ cannot know
$X$'s own predictor computes a total function. Is it possible that $|X|_X$ could
be $<\infty$ anyway? The following theorem answers this question negatively.

\begin{theorem}
\label{Xjudgesitselfinfinitelysmarttheorem}
    For every AGI $X$, $|X|_X=\infty$.
\end{theorem}

\begin{proof}
    In other words, we must show that $X$'s predictor learns every
    evader $e\in E_{f_m}$ for every $m>0$, where
    $f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g^X_i(j)$.
    So, fix $m\in\mathbb N$ and let $e\in E_{f_m}$.

    Let $M$ be the Turing machine which takes input $(x_1,\ldots,x_n)\in B^*$
    and proceeds as follows:
    \begin{enumerate}
        \item
        Run $C^X_m$ on input $n$ until it gives output $k$.
        \item
        Run $e$ for up to $k$ steps. If it halts with output $y\in\{0,1\}$ during that
        time, then halt and output $y$. Otherwise, halt and output $0$.
    \end{enumerate}
    Since $X$ knows that $C^X_m$ computes a total function from $\mathbb N$ to $\mathbb N$,
    it follows that $X$ knows that $M$ computes a total function from $B^*$ to $B$.
    Since $C^X_m$ computes $f_m$,
    in line (2) in the definition of $M$, when $e$ is run for
    up to $k$ steps, that means $e$ is run for up to $f_m(n)$ steps.
    Since $e\in E_{f_m}$, this means that, except for finitely many exceptions,
    for every input $(x_1,\ldots,x_n)\in B^*$, $M$ halts with output
    $e(x_1,\ldots,x_n)$. Thus, it follows that there is a Turing machine $M'$
    such that $M'$ computes $e$ and such that $X$ knows that $M'$ computes a total
    function from $B^*$ to $B$. By Lemma \ref{knowingimplieslearninglemma},
    $X$'s brute-force predictor learns $e$. By Assumption \ref{bruteforceassumption},
    $X$'s predictor learns $e$.
\end{proof}

\subsection{The problem with relative Hibbard measures}
\label{problemwithsimplehibbardsection}

Based on Theorems \ref{simplehibbardnontrivialtheorem}
and \ref{Xjudgesitselfinfinitelysmarttheorem},
we see that in a certain sense, for all AGIs $X$ and $Y$,
if $X$ knows that $Y$'s predictor computes a total function from $B^*$ to $B$,
then $X$ is more intelligent than $Y$: $X$ is more intelligent
than $Y$ in the sense that $|X|_X=\infty>|Y|_X$).

Based on the above, we might expect that for all AGIs $X,Y,Z$, if $X$ knows
$Y$'s predictor computes a total function from $B^*$ to $B$, and if $Y$
knows $Z$'s predictor computes a total function from $B^*$ to $B$,
then $|X|_X=\infty>|Y|_X>|Z|_X$. But this does \emph{not} hold in general
(as we show in the next theorem),
and the reason has almost nothing to do with intelligence or with adversarial
sequence prediction, and almost entirely to do with the structure of the natural
numbers: relative Hibbard measures assign natural-number-valued intelligence
measures to AGIs, and those values therefore suffer the same limitations as the
natural numbers.

\begin{theorem}
\label{nonarchimedeantheorem}
    If any AGI exists, then
    there exist AGIs $X,Y,Z$ such that:
    \begin{enumerate}
        \item $X$ knows that $Y$'s predictor computes a total function from $B^*$ to $B$.
        \item $Y$ knows that $Z$'s predictor computes a total function from $B^*$ to $B$.
        \item It is \emph{not} the case that $|X|_X>|Y|_X>|Z|_X$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    By assumption, some AGI exists, so we may let $Y_0$ be some initial AGI.

    Let $F$ be the function from the second part of Informal Lemma \ref{teachinglemma}.
    Define true sentences $\phi_0,\phi_1\ldots$ of Peano arithmetic and
    AGIs $Y_1,Y_2,\ldots$ by simultaneous recursion as follows:
    \begin{enumerate}
        \item
        Assuming $Y_i$ has been defined,
        let $\phi_i$ be the statement that $Y_i$'s predictor defines a computable
        function from $B^*$ to $B$.
        \item
        Assuming $Y_{i}$ and $\phi_{i}$ have been defined,
        let $Y_{i+1}=F(Y_{i},\phi_{i})$.
    \end{enumerate}
    By construction, each $Y_{i+1}$ is an AGI which
    knows that $Y_i$'s predictor computes a total function from $B^*$ to $B$.

    Let $\phi$ be the statement that $\forall i$, $Y_i$'s predictor computes a total
    function from $B^*$ to $B$.
    Let $Y=F(Y_0,\phi)$.
    Thus, $Y$ is an AGI such that for each $i$, $Y$ knows that $Y_i$'s predictor
    computers a total function from $B^*$ to $B$.

    Let $\phi'$ be the statement that $Y$'s predictor computes a total function
    from $B^*$ to $B$ and that for each $i$, $Y_i$'s predictor computes a total
    function from $B^*$ to $B$.
    Let $X=F(Y,\phi')$.
    Thus, $X$ is an AGI which knows that $Y$'s predictor computes a total function from
    $B^*$ to $B$, and also knows (for each $i$) that $Y_i$'s predictor computes a total
    function from $B^*$ to $B$.

    Assume (for sake of contradiction) that the Theorem we are proving is false.
    Then:
    \begin{itemize}
        \item
        For each $i\geq 0$, we have:
        \begin{itemize}
            \item
            $X$ knows $Y_{i+1}$'s predictor defines a total function from $B^*$ to $B$.
            \item
            $Y_{i+1}$ knows $Y_i$'s predictor defines a total function from $B^*$ to $B$.
            \item
            Thus, $|X|_X=\infty>|Y_{i+1}|_X>|Y_i|_X$ (lest the triple $(X,Y_{i+1},Y_i)$
            would witness the Theorem).
        \end{itemize}
        \item
        Also, for each $i\geq 0$, we have:
        \begin{itemize}
            \item
            $X$ knows $Y$'s predictor defines a total function from $B^*$ to $B$.
            \item
            $Y$ knows $Y_i$'s predictor defines a total function from $B^*$ to $B$.
            \item
            Thus, $|X|_X=\infty>|Y|_X>|Y_i|_X$ (lest the triple $(X,Y,Y_i)$
            would witness the Theorem).
        \end{itemize}
    \end{itemize}
    Since $|Y|_X$ and each $|Y_i|_X$ are natural numbers, it follows that
    $\{|Y_0|_X, |Y_1|_X, \ldots\}$
    is an infinite set of distinct natural numbers, all of them $<|Y|_X$.
    This is absurd, because there are only $|Y|_X$ distinct natural numbers
    $<|Y|_X$.
\end{proof}

The proof of Theorem \ref{nonarchimedeantheorem} works because if $n_0,n_1,n_2,\ldots$
is any sequence of naturals with each $n_{i+1}\geq n_i+1$, then for every natural number
$m$ (such as $m=|Y|_X$),
there is some $i$ such that $n_i>m$. This property is a generalization of a
basic property of $\mathbb R$ called the \emph{Archimedean property}. This generalized
version of the Archimedean property debuted in \cite{alexander2020archimedean},
where we argue that it is hopeless to try to measure non-Archimedean structures
using natural numbers---in fact, that it is even hopeless to measure non-Archimedean
structures using \emph{real} numbers. If AGI intelligence is non-Archimedean (as the
proof of Theorem \ref{nonarchimedeantheorem} suggests), then in order to
accurately measure it, we need to use a non-Archimedean number system.
In Section \ref{transfinitehibbardsection}
we will do exactly that. But first, we need some machinery from mathematical logic.

\begin{remark}
    At a low level, the proof of Theorem \ref{nonarchimedeantheorem} involves a
    lot of tedious work. But at a high-level, what we are doing in that proof is
    that we are constructing a sequence of AGIs $Y_0,Y_1,\ldots,Y,X$
    ordered like the ordinals $0,1,\ldots,\omega,\omega+1$
    (where $\omega$ is the smallest infinite ordinal).
    Each $Y_i$ corresponds to the finite ordinal number $i$; $Y$ corresponds to $\omega$;
    and $X$ corresponds to $\omega+1$, the next
    ordinal after $\omega$. More generally, given any ordinal notation, one could
    use the same technique from the proof of Theorem \ref{nonarchimedeantheorem} to
    construct a set of AGIs isomorphic that ordinal\footnote{This
    resembles the technique suggested in \cite{good1969godel}.}.
    This is a general theoretical
    recipe\footnote{Unfortunately,
    the recipe requires an initial AGI $Y_0$ to kick the process off, so it will not be
    of much use pre-singularity.} for transforming any ordinal notation into a very intelligent
    AGI---``and the larger the ordinal, the fitter the organism'',
    to quote Chaitin \cite{chaitin}.
    We would submit this as evidence of our thesis
    \cite{ioi1} \cite{ioi2} that more intelligent AGIs should know larger ordinal numbers.
\end{remark}

\section{Transfinite Hibbard measures}

The original Hibbard measure
(Definition \ref{classichibbardmeasuredefn}) depends on a specific list of
quickly-growing computable functions from $\mathbb N$ to $\mathbb N$, imported from
\cite{liu1960enumeration}. In Section \ref{trivialitysection}, we argued
that the original Hibbard measure is trivial for AGIs because the functions thus imported
are too slow-growing.
In Section \ref{simplemeasuresection} we generalized
the original Hibbard measure
by delegating the choice of a list of quickly-growing computable functions to an AGI rather
than to a single external paper. The resulting family of relative Hibbard measures is
non-trivial (Theorem \ref{simplehibbardnontrivialtheorem}), but in
Subsection \ref{problemwithsimplehibbardsection} we argued that these
measures still have a crucial flaw: they are constrained by the structure of
$\mathbb N$, which is inappropriate because, as Theorem \ref{nonarchimedeantheorem}
suggests, AGI intelligence should have a more sophisticated structure than $\mathbb N$.
In this section, we will rectify this flaw by introducing what we call \emph{transfinite
Hibbard measures}, which assign computable-ordinal-valued intelligence levels rather than
natural-number-valued intelligence levels. First we need some infrastructure.

\subsection{Majorization hierarchies and Kleene's $\mathcal O$}

We are going to be delegating the task of notating computable
ordinals to an AGI, so we need to fix a formal, systematic way of speaking about these things.
The following notation system is due to Kleene \cite{kleene1938notation}.

\begin{definition}
(Kleene's $\mathcal O$)
We define a subset $\mathcal O\subseteq \mathbb N$ and a function $|\bullet|$ which maps
members of $\mathcal O$ to computable ordinals as follows (whenever $n\in\mathcal O$ and
$|n|=\alpha$, we say that $n$ \emph{notates} the ordinal $\alpha$):
\begin{enumerate}
    \item
        $0\in\mathcal O$ and $|0|=0$ (in other words, the natural number $0$ notates
        the ordinal $0$).
    \item
        For each $n\in\mathcal O$, $2^n\in\mathcal O$ and $|2^n|=|n|+1$ (in other words,
        if the natural number $n$ notates $\alpha$, then the natural number $2^n$
        notates $\alpha+1$).
    \item
        If the $e$th Turing machine defines a total function $f:\mathbb N\to\mathbb N$
        such that each $f(n)\in\mathcal O$ and such that each $|f(n)|<|f(n+1)|$,
        then $3\cdot 5^e\in\mathcal O$ and $|3\cdot 5^e|=\lim_{n\in\mathbb N}|f(n)|$.
    \item
        $\mathcal O$ is as small as possible such that the above properties hold.
\end{enumerate}
\end{definition}

\begin{example}
\label{kleeneexamples}
    (Examples of Kleene's $\mathcal O$)
    \begin{enumerate}
        \item
        Let $e_1$ be such that the $e_1$th Turing machine computes the
        function $f_1:\mathbb N\to\mathbb N$ such that
        $f_1(0)=0$, $f_1(1)=2^0$, $f_1(2)=2^{2^0}$, $f_1(3)=2^{2^{2^0}}$, and so on.
        Then:
        \begin{enumerate}
            \item
            Each $f_1(n)\in\mathcal O$.
            \item
            Each $|f_1(n)|=n$.
            \item
            $3\cdot 5^{e_1}\in \mathcal O$.
            \item
            $|3\cdot 5^{e_1}|=\lim_{n\in\mathbb N}|f_1(n)|=\lim_{n\in\mathbb N}n=\omega$,
            where $\omega$ is the smallest infinite ordinal.
        \end{enumerate}
        \item
        Let $e_2$ be such that the $e$th Turing machine computes the
        function $f_2:\mathbb N\to\mathbb N$ such that
        $f_2(0)=3\cdot 5^{e_1}$, $f_2(1)=2^{3\cdot 5^{e_1}}$,
        $f_2(2)=2^{2^{3\cdot 5^{e_1}}}$, and so on.
        Then:
        \begin{enumerate}
            \item
            Each $f_2(n)\in \mathcal O$.
            \item
            Each $|f_2(n)|=\omega+n$.
            \item
            $3\cdot 5^{e_2}\in\mathcal O$.
            \item
            $|3\cdot 5^{e_2}|=\lim_{n\in\mathbb N}|f_2(n)|=\lim_{n\in\mathbb N}\omega+n
            =\omega+\omega=\omega\cdot 2$.
        \end{enumerate}
        \item
        Similarly, we could define $e_3$ such that $|3\cdot 5^{e_3}|=\omega\cdot 3$,
        and $e_4$ such that $|3\cdot 5^{e_4}|=\omega\cdot 4$, and so on.
        But with sufficient creativity, the reader can short-circuit this whole process,
        and find a single number $e$ such that the $e$th Turing machine computes
        a function $f:\mathbb N\to\mathbb N$ such that
        $f(0)=e_0=0$, $f(1)=e_1$, $f(2)=e_2$,
        and in general each $f(n)=e_n$ for some such $e_1,e_2,\ldots$ as just described.
        Then:
        \begin{enumerate}
            \item
            Each $f(n)\in\mathcal O$.
            \item
            Each $|f(n)|=\omega\cdot n$.
            \item
            $3\cdot 5^e\in\mathcal O$.
            \item
            $|3\cdot 5^e|=\lim_{n\in\mathbb N}|f(n)|
            =\lim_{n\in\mathbb N}\omega\cdot n
            =\omega\cdot\omega=\omega^2$.
        \end{enumerate}
    \end{enumerate}
\end{example}

The following result is well-known and we state it without proof.

\begin{lemma}
    An ordinal $\alpha$ is computable if and only if $\alpha=|k|$ for some $k\in\mathcal O$.
\end{lemma}

\begin{definition}
\label{notationsbelowkdefn}
    For each $k\in\mathcal O$, we define the \emph{notations below $k$},
    written $B(k)$, inductively as follows.
    \begin{enumerate}
        \item
        If $k=0$, then $B(n)=\emptyset$, the empty set.
        \item
        If $k=2^m$, then $B(n)=B(m)\cup\{m\}$.
        \item
        If $k=3\cdot 5^e$ where the $e$th Turing machine computes the
        function $f:\mathbb N\to\mathbb N$, then
        $B(k)=\{f(0),f(1),\ldots\} \cup B(f(0)) \cup B(f(1)) \cup \cdots$.
    \end{enumerate}
\end{definition}

\begin{definition}
    For any $k\in\mathcal O$ and any ordinal $\beta\leq |k|$, we define
    \emph{the canonical code of $\beta$ according to $k$}, written $c(\beta,k)$,
    by induction as follows.
    \begin{enumerate}
        \item
        If $\beta=|k|$, then $c(\beta,k)=k$.
        \item
        If $\beta<|k|$ and $k=2^{k_0}$, then $c(\beta,k)=c(\beta,k_0)$.
        \item
        If $\beta<|k|$ and $k=3\cdot 5^e$, where the $e$th Turing machine computes
        a total function $f:\mathbb N\to \mathcal O$, then we define
        $c(\beta,k)$ to be $c(\beta,f(i))$ where $i$ is minimal such that
        $\beta\leq |f(i)|$.
    \end{enumerate}
\end{definition}

\begin{definition}
By $INC$, we mean the set of all $n\in\mathbb N$ such that the $n$th
Turing machine defines a total computable increasing function from $\mathbb N$
to $\mathbb N$.
\end{definition}

\begin{definition}
    By a \emph{syntactic majorization hierarchy}, we mean a pair $(k,F)$
    where $k\in\mathbb O$ and $F$ is a computable function from $B(k)$ to $INC$,
    satisfying the following property:
    \begin{itemize}
        \item
        For any $k_0,k_1\in B(k)$, if $|k_1|>|k_0|$, then
        $F(k_1)\succ F(k_0)$ (Definition \ref{functionsuccdefn}).
    \end{itemize}
\end{definition}

\begin{definition}
    If $(k,F)$ is a syntactic majorization hierarchy, we define the
    \emph{semantic majorization hierarchy defined by $(k,F)$},
    written $\mathscr S(k,F)$,
    to be the function $F:|k|\to INC$
    defined as follows: for any $\alpha<|k|$,
    $\mathscr F(\alpha)=F(c(\alpha, k))$.
\end{definition}

\begin{definition}
\label{majorizationhierarchyofanagidefn}
    For each AGI $X$, let $(k^X_1,F^X_1),(k^X_2,F^X_2),\ldots$ be the sequence
    of syntactic majorization hierarchies which would result if $X$ were commanded:
    \begin{quote}
        ``Until further notice, list syntactic majorization hierarchies
        $(k_1,F_1),(k_2,F_2),\ldots$ in such a way that the following requirements
        hold:
        \begin{enumerate}
            \item
            Each $k_i=3\cdot 5^e$ for some $e$.
            \item
            Each $|k_{i+1}|>|k_i|$.
            \item
            Each $\mathscr S(k_{i+1},F_{i+1})$ extends $S(k_i,F_i)$.
            \item
            For every $k$ such that you know $k\in\mathcal O$, there is some $i$
            such that $|k_i|>|k|$.
            \item
            For every Turing machine $M$ such that you know $M$ computes a total
            computable function $f:\mathbb N\to\mathbb N$, there is some
            $i$ and some $\ell \in B(k_i)$ such that $F(\ell)\succ f$.''
        \end{enumerate}
    \end{quote}
\end{definition}

\begin{lemma}
    Let $X$ be an AGI. It is possible for $X$ to carry out the command in
    Definition \ref{majorizationhierarchyofanagidefn}.
\end{lemma}

\begin{proof}
    Let $\ell_1,\ell_2,\ldots$ be the sequence of naturals which would result if
    $X$ were commanded:
    \begin{quote}
        ``Until further notice, list all the $\ell\in\mathbb N$ such that you know
        $\ell\in\mathcal O$.''
    \end{quote}
    Let $M_1,M_2,\ldots$ be the sequence of Turing machines which would result if
    $X$ were commanded:
    \begin{quote}
        ``Until further notice, list all the Turing machines $M$ such that you know
        $M$ computes a total computable increasing function $f:\mathbb N\to\mathbb N$''
    \end{quote}
    (and let $f_1,f_2,\ldots$ be the total computable increasing functions
    computed by $M_1,M_2,\ldots$).

    Let $k_0=3\cdot 5^{e_1}$ where $e_1$ is as in Example
    \ref{kleeneexamples} (so $|k_0|=\omega$).
    Let $F_0:B(k_0)\to INC$ be defined so that $F_0(0)(x)=0$,
    $F_0(2^0)(x)=1$, $F_0(2^{2^0})(x)=2$, and so on (in other words,
    $F(k)=|k|$ for all $k\in B(k_0)$).

    Now inductively, for any $i$, suppose we have defined $(k_j,F_j)$ for all $j\leq i$,
    satisfying conditions 1--3 of the command in
    Definition \ref{majorizationhierarchyofanagidefn}.
    We will define $(k_{i+1},F_{i+1})$.

    Let $k_{i+1}=k_i\oplus \ell_{i+1}$. Define $F_{i+1}(k)=F_i(k)$ for all $k\in B(k_i)$.
    As for $k\in B(k_{i+1})\backslash B(k_i)$, all of these are of the form
    $k_i\oplus k'$ where $k'\in B(\ell_{i+1})$. We define $F_{i+1}$ on these numbers
    by induction as follows:
    \begin{enumerate}
        \item
        If $k'=0$, then let $e$ be such that $k_i=3\cdot 5^e$, and let
        $f:\mathbb N\to B(k')$ be the total computable function computed by the $e$th
        Turing machine. Define
        \[
            F_{i+1}(k_i\oplus k')(x) = F_i(f(x))(x) + f_{i+1}(x)
        \]
        (the $F_i(f(x))(x)$ summand ensures that
        $F_{i+1}(k_i\oplus k')\succ F_i(k'')$ for all $k''\in B(k')$;
        the $f_{i+1}(x)$ summand ensures that $F_{i+1}(k_i\oplus k')\succ f_{i+1}$).
        \item
        If $k'=2^{k''}$, we define
        \[
            F_{i+1}(k_i\oplus k')(x)=F_{i+1}(k_i\oplus k'')(x)+1
        \]
        (ensuring that $F_{i+1}(k_i\oplus k')\succ F_{i+1}(k_i\oplus k'')$).
        \item
        If $k'=3\cdot 5^e$ where the $e$th Turing machine defines a total computable
        function $f:\mathbb N\to\mathcal O$,
        then define
        \[
            F_{i+1}(k_i\oplus k')(x) = F_{i+1}(k_i\oplus f(x))(x)
        \]
        (ensuring that $F_{i+1}(k_i\oplus k')\succ F_{i+1}(k_i\oplus f(x))$
        for every $x$).
    \end{enumerate}
    It is easy to check that $k_1,\ldots,k_{i+1}$ and $F_1,\ldots,F_{i+1}$
    still satisfy conditions 1--3 of the command in
    Definition \ref{majorizationhierarchyofanagidefn}.

    In this way, we inductively have defined infinite sequences
    $k_1,k_2,\ldots\in\mathcal O$ and $F_1,F_2,\ldots$ (each $F_i:B(k_i)\to INC$)
    satisfying conditions 1--3 of the command in
    Definition \ref{majorizationhierarchyofanagidefn}. 
    
    Because we chose each $k_{i+1}=k_i\oplus \ell_{i+1}$,
    it follows (by choice of $\ell_1,\ell_2,\ldots$) that condition 4 of the command from
    Definition \ref{majorizationhierarchyofanagidefn} is satisfied.
    
    Because we ensured that each $F_{i+1}(k_i\oplus 0)\succ f_{i+1}$,
    it follows (by choice of $M_1,M_2,\ldots$ and definition of $f_1,f_2,\ldots$)
    that condition 5 of the command from
    Definition \ref{majorizationhierarchyofanagidefn} is satisfied.

    So $(k_1,F_1),(k_2,F_2),\ldots$, as defined above, satisfy all the requirements
    of the command from Definition \ref{majorizationhierarchyofanagidefn}.
    Now, in the above argument, we never used any mathematics which should not be
    known by $X$. Therefore, $X$ would be perfectly capable of using the above
    strategy to obey the command in question. Whether $X$ uses the above strategy
    or some other strategy to obey the command, we do not know, but we have shown that
    it is possible for $X$ to obey the command.
\end{proof}


\section{The slow-growing hierarchy}
\label{slowgrowinghierarchysection}

The original Hibbard measure
(Definition \ref{classichibbardmeasuredefn}) depends on a specific list of
quickly-growing computable functions from $\mathbb N$ to $\mathbb N$, imported from
\cite{liu1960enumeration}. In Section \ref{trivialitysection}, we argued
that the original Hibbard measure is trivial for AGIs because the functions thus imported
are too slow-growing.
In Section \ref{simplemeasuresection} we generalized
the original Hibbard measure
by delegating the choice of a list of quickly-growing computable functions to an AGI rather
than to a single external paper. The resulting family of relative Hibbard measures is
non-trivial (Theorem \ref{simplehibbardnontrivialtheorem}), but in
Subsection \ref{problemwithsimplehibbardsection} we argued that these
measures still have a crucial flaw: they depend too heavily on the order in which
the AGI supplies its list of computable functions.

In order to solve the problem of dependence on computable functions, we will take
a different strategy.
\begin{itemize}
    \item
    In mathematical logic, there is a general recipe for obtaining
    quickly-growing computable
    functions, through the usage of so-called \emph{slow-growing hierarchies}.
    \item
    The recipe takes as input a computable
    ordinal number $\alpha$ along with some so-called \emph{fundamental
    sequences} for certain ordinals $\lambda<\alpha$ (called \emph{limit ordinals}),
    and outputs a family of functions: one function $G_{\beta}:\mathbb N\to\mathbb N$
    for every ordinal
    $\beta<\alpha$, and for large values of $\beta$, $G_{\beta}$ grows very quickly.
    \item
    Thus, instead of
    commanding our AGI to directly produce a list of quickly-growing computable functions,
    we can instead command our AGI to produce computable ordinal numbers and
    fundamental sequences, and then obtain a list of quickly-growing
    computable functions indirectly, via the resulting slow-growing hierarchy.
\end{itemize}
This solves the problem of order-dependence: we can completely ignore the order
in which the AGI outputs the computable ordinals, because computable ordinals are
\emph{themselves} ordered. In other words, if the AGI outputs a small computable ordinal
and a large computable ordinal, we can consider the small computable ordinal to precede
the large computable ordinal, regardless of in which order the AGI outputs them.

\begin{definition}
    (Classification of ordinal numbers)
    Let $\alpha$ be an ordinal number.
    \begin{enumerate}
        \item
        If $\alpha=\beta+1$ for some ordinal number $\beta$, then $\alpha$ is called
        a \emph{successor ordinal}.
        \item
        If $\alpha$ is not a successor ordinal and $\alpha\neq 0$, then $\alpha$ is
        called a \emph{limit ordinal}.
    \end{enumerate}
\end{definition}

\begin{definition}
\label{fundamentalsequencedefn}
    (Fundamental sequences)
    If $\lambda$ is a limit ordinal, a \emph{fundamental sequence} for $\lambda$
    is a sequence $(\lambda[0],\lambda[1],\lambda[2],\ldots)$
    of ordinals, such that the following requirements hold:
    \begin{enumerate}
        \item
        Each $\lambda[i]<\lambda[i+1]<\lambda$.
        \item
        The supremum of the $\lambda[i]$s is $\lambda$. Or equivalently:
        for each ordinal $\alpha<\lambda$, there is some $N\in\mathbb N$ such that
        for all $i>N$, $\lambda[i]>\alpha$.
    \end{enumerate}
\end{definition}

\begin{definition}
\label{slowgrowinghierarchiesdefn}
    (Slow-Growing Hierarchies)
    Suppose $\alpha$ is an ordinal and suppose $\mathcal F$ is a function which
    takes as input a limit ordinal $\lambda<\alpha$ and outputs a fundamental
    sequence $\mathcal F(\lambda)=(\lambda[0],\lambda[1],\lambda[2],\ldots)$
    for $\lambda$. The \emph{slow-growing hierarchy given by $\alpha$ and $\mathcal F$}
    is the family $\{G_\beta\}_{\beta<\alpha}$ of functions consisting of a function
    $G_\beta:\mathbb N\to\mathbb N$ for every
    ordinal $\beta<\alpha$, defined by transfinite induction according to following cases:
    \begin{enumerate}
        \item
        $G_0(x)=0$.
        \item
        $G_{\beta+1}(x) = G_\beta(x) + 1$.
        \item
        $G_{\lambda}(x) = G_{\lambda[x]}(x)$ (for every limit ordinal $\lambda<\alpha$),
        where $(\lambda[0],\lambda[1],\lambda[2],\ldots)$ is the fundamental sequence
        $\mathcal F(\lambda)$ of $\lambda$.
    \end{enumerate}
\end{definition}

\begin{lemma}
    Suppose $\{G_\beta\}_{\beta<\alpha}$ is the slow-growing hierarchy given by
    an ordinal $\alpha$ and function $\mathcal F$.
    If $\alpha$ is computable and $\mathcal F$ is computable,
    then each $G_\beta$ is computable.
\end{lemma}

\begin{proof}
By Church's thesis.
\end{proof}

\begin{example}
    Consider the ordinal $\alpha=\omega^2$ (where $\omega$ is the smallest infinite
    ordinal).
    The limit ordinals $\lambda<\omega^2$ are exactly the ordinals
    $\{\omega\cdot (n+1)\,:\,n\in\mathbb N,\}$.
    A natural way to assign fundamental sequences to these limit ordinals is to define,
    for all $n,m\in\mathbb N$,
    \[
        \mathcal F(\omega\cdot(n+1))(m) = (\omega\cdot(n+1))[m] = (\omega\cdot n)+m.
    \]
    Let us compute some of the functions $\{G_{\beta}\,:\,\beta<\alpha\}$
    given by $\alpha$ and $\mathcal F$. Below, $x$ and $n$
    denote arbitrary natural numbers.
    \begin{enumerate}
        \item
        By the base case, $G_0(x)=0$ for all $x\in\mathbb N$.
        \item
        By the successor case, $G_1(x)=G_0(x)+1=0+1=1$.
        \item
        By the successor case, $G_2(x)=G_1(x)+1=1+1=2$.
        \item
        Generalizing the above pattern, $G_n(x)=n$.
        \item
        By the limit case,
        $G_\omega(x)=G_{\omega\cdot(0+1)}(x)
        =G_{(\omega\cdot(0+1))[x]}(x)=G_{(\omega\cdot 0)+x}(x)
        =G_x(x)=x$.
        \item
        By the successor case, $G_{\omega+1}(x)=G_{\omega}(x)+1=x+1$.
        \item
        By the successor case, $G_{\omega+2}(x)=G_{\omega+1}(x)+1=x+2$.
        \item
        Generalizing the above pattern, $G_{\omega+n}(x)=x+n$.
        \item
        By the limit case,
        $G_{\omega\cdot 2}(x)=G_{\omega\cdot(1+1)}(x)
        =G_{(\omega\cdot(1+1))[x]}(x)=G_{(\omega\cdot 1)+x}(x)
        =x+x$.
        \item
        Similarly, the reader can check that $G_{\omega\cdot 3}(x)=x+x+x$.
        \item
        Generalizing the above pattern, $G_{\omega\cdot n}(x)=x\cdot n$.
    \end{enumerate}
\end{example}

\begin{example}
\label{epsilon0example}
    The ordinal $\epsilon_0$
    (pronounced ``epsilon-nought'') is the smallest ordinal larger than
    the ordinals $\omega, \omega^\omega, \omega^{\omega^\omega}, \ldots$.
    It satisfies the equation $\epsilon_0=\omega^{\epsilon_0}$, and can be
    intuitively thought of as
    \[
        \epsilon_0 = \omega^{\omega^{\omega^{\iddots}}}.
    \]
    Examples of ordinals below $\epsilon_0$ include such ordinals as
    $\omega^\omega$, $\omega^{\omega^\omega+\omega}$,
    \[
        \omega^{\omega^{\omega^{\omega^\omega+\omega^3+5}+\omega^{\omega^2}+\omega^\omega}+1}
        +\omega^{\omega^{\omega^2+\omega+1}+\omega^{800}}
        +\omega^{\omega^5\cdot 12 + \omega^4\cdot 9 + 1000}
        +1,
    \]
    and so on. There is a natural way to assign fundamental sequences to limit ordinals
    $<\epsilon_0$, yielding a corresponding slow-growing hierarchy where, for example,
    \begin{align*}
        G_{\omega^\omega}(x) &= x^x,\\
        G_{\omega^{\omega^\omega}+5}(x) &= x^{x^x}+5,\\
        G_{\omega^{\omega^{\omega^{\omega^\omega}}}}(x) &= x^{x^{x^{x^{x}}}},
    \end{align*}
    and so on. Likewise, $(\omega,\omega^\omega,\omega^{\omega^\omega},\ldots)$ is itself a
    fundamental sequence for $\epsilon_0$. What could $G_{\epsilon_0}(x)$ be?
    Thinking of $\epsilon_0$ as $\omega^{\omega^{\iddots}}$, one might initially think
    $G_{\epsilon_0}(x)=x^{x^{\iddots}}$, but such an infinite tower of natural numbers
    makes no sense for $x>1$. Instead, the answer defies familiar mathematical notation:
    \begin{align*}
        G_{\epsilon_0}(0) &= 0\\
        G_{\epsilon_0}(1) &= 1^1\\
        G_{\epsilon_0}(2) &= 2^{2^2}\\
        G_{\epsilon_0}(3) &= 3^{3^{3^3}},
    \end{align*}
    and so on.
\end{example}

Example \ref{epsilon0example} illustrates how slow-growing hierarchies reduce
the open-ended problem
\[\mbox{``Invent a quickly-growing computable function''}\]
to a slightly less open-ended and more manageable problem:
\[\mbox{``Invent fundamental sequences up to a large computable ordinal.''}\]

Slow-growing hierarchies provide an elegant means of obtaining quickly-growing
computable functions from $\mathbb N$ to $\mathbb N$.
The larger the computable ordinal, the larger the resulting computable function.
However, inventing large computable ordinals is a non-trivial task---in
\cite{ioi2} we argue that it might be a task that exhausts the full range
of intelligence (i.e., that for any possible intelligence level, there is a corresponding
computable ordinal whose invention requires at least that much intelligence).
Even having invented a large computable ordinal, the task of assigning fundamental
sequences to the limit ordinals below it is another difficult task in general\footnote{The
choice of fundamental sequences can dramatically change the growth rate of the
resulting slow-growing hierarchy---see \cite{weiermann1997sometimes}.}.
Fortunately, this is a theoretical paper about AGI, so we can avoid all these decisions
by delegating them to an AGI. In order to do so in a sensible way, we need a certain
technical lemma which will allow us to command the AGI to give us a slow-growing hierarchy
piece-by-piece.

\begin{definition}
\label{fundamentalsequenceextensiondef}
    Suppose $\mathcal H_1$ is the slow-growing hierarchy given by
    ordinal $\alpha_1$ and function $\mathcal F_1$, and suppose
    $\mathcal H_2$ is the slow-growing hierarchy given by
    ordinal $\alpha_2$ and function $\mathcal F_2$.
    We say \emph{$\mathcal H_2$ extends $\mathcal H_1$},
    written $\mathcal H_1\prec \mathcal H_2$, if the following
    requirements hold:
    \begin{enumerate}
        \item
        $\alpha_1<\alpha_2$.
        \item
        For every limit ordinal $\lambda<\alpha_1$,
        $\mathcal F_1(\lambda)=\mathcal F_2(\lambda)$.
    \end{enumerate}
\end{definition}

In the following lemma and its proof, we will be dealing with unions of functions
and with unions of ordinals,
so it is important to recall the following:
\begin{itemize}
    \item A \emph{relation} is a set $R$ of pairs $(x,y)$.
    \item A \emph{function} is a relation $f$ which satisfies the requirement
    (sometimes called the ``vertical line test'') that whenever $(x,y_1)\in f$
    and $(x,y_2)\in f$, then $y_1=y_2$. Whenever $(x,y)\in f$, we write $f(x)$
    to denote $y$.
    \item Every ordinal $\alpha$ is equal to the set of all ordinals $\beta<\alpha$.
\end{itemize}

\begin{lemma}
\label{slowgrowingtechnicallemma}
    Suppose for every $i\in\mathbb N$,
    $\mathcal H_i$ is the slow-growing hierarchy given by an ordinal
    $\alpha_i$ and function $\mathcal F_i$.
    If $\mathcal H_0\prec \mathcal H_1\prec \mathcal H_2\prec\cdots$,
    then
    $\mathcal F=\cup_i\mathcal F_i$ is a function which assigns
    fundamental sequences
    to all limit ordinals $\lambda<\alpha=\cup_i\alpha_i$
    (so that together, $\alpha$ and $\mathcal F$
    give a slow-growing hierarchy).
\end{lemma}

\begin{proof}
    To show that $\mathcal F$ is a function, which must show that for any two pairs
    $(\lambda,y_1)\in\mathcal F$ and $(\lambda,y_2)\in\mathcal F$,
    $y_1=y_2$ (i.e., that
    $\mathcal F$ ``passes the vertical line test'').
    Assume $(\lambda,y_1)\in\mathcal F$ and $(\lambda,y_2)\in\mathcal F$.
    This means there are some $i_1,i_2\in\mathbb N$ such that
    $\mathcal F_{i_1}(\lambda)=y_1$ and $\mathcal F_{i_2}(\lambda)=y_2$.
    If $i_1=i_2$ then $y_1=y_2$ because $\mathcal F_{i_1}=\mathcal F_{i_2}$ is a function,
    but assume $i_1\neq i_2$. Without loss of generality we may
    assume $i_1<i_2$ (the other case is similar).
    Since $\mathcal H_{i_1}\prec \cdots \prec \mathcal H_{i_2}$,
    it follows by a simple inductive argument that $\mathcal H_{i_1}\prec \mathcal H_{i_2}$.
    Thus by condition 2 of Definition \ref{fundamentalsequenceextensiondef},
    $y_1=y_2$, as desired.

    It remains to let $\lambda<\alpha$ be a limit ordinal and show
    that conditions 1 and 2 of Definition \ref{fundamentalsequencedefn}
    hold for $\mathcal F(\lambda)$.
    Since $\lambda<\alpha$, that means $\lambda<\alpha_i$ for some $i\in\mathbb N$.
    Let $(\lambda[0],\lambda[1],\ldots)=\mathcal F(\lambda)$.
    Then $(\lambda[0],\lambda[1],\ldots)=\mathcal F_i(\lambda)$, so
    conditions 1 and 2 of Definition \ref{fundamentalsequencedefn} hold because
    $\mathcal F_i$ is a function which assigns fundamental sequences to all limit
    ordinals $<\alpha_i$.
\end{proof}

\section{The Transfinite Hibbard measures}
\label{transfinitehibbardsection}

We would like to delegate the problem of inventing large computable ordinals and
fundamental sequences to an AGI. In order to do so, we need a systematic
way for the AGI to encode those things. Since we do not care about the specific
details of the encoding, we can get away with the following high-level definition.
A more concrete definition would be possible by using, say, the ordinal notation
system known as Kleene's $\mathcal O$ \cite{kleene1938notation}, but the details
would be long and tedious.

\begin{definition}
    By a \emph{slow-growing hierarchy notation}, we mean a
    definition (in the language of ZFC) of a pair $(\alpha,\mathcal F)$
    such that $\alpha$ is a computable ordinal and $\mathcal F$ is a computable
    function that assigns fundamental sequences to limit ordinals $\lambda<\alpha$.
\end{definition}

\begin{definition}
\label{slowgrowinghierarchyofanagidefn}
    Let $X$ be an AGI.
    Let $d_0,d_1,\ldots$ be the slow-growing hierarchy notations which would result
    if $X$ were commanded as follows:
    \begin{quote}
    ``Until further notice, output slow-growing hierarchy
    notations of pairs $(\alpha_i,\mathcal F_i)$, such that
    the corresponding slow-growing hierarchies $\mathcal H_i$ satisfy
    the hypotheses of Lemma \ref{slowgrowingtechnicallemma}. Do this in such a way
    that the $\alpha_i$s include computable ordinals as large as possible.''
    \end{quote}
    For each $i\in\mathbb N$, let $\alpha_i$ and $\mathcal F_i$ be the
    computable ordinal and computable function defined by $d_i$.
    The \emph{slow-growing hierarchy of $X$} is defined to be
    the slow-growing hierarchy given by $\alpha=\cup_i\alpha_i$
    and $\mathcal F=\cup_i\mathcal F_i$ (see Lemma \ref{slowgrowingtechnicallemma}).
\end{definition}

\begin{definition}
\label{transfinitehibbardmeasuredefn}
    Suppose that $X$ is an AGI, and that
    $\alpha$ and $\mathcal F$ are as in
    Definition \ref{slowgrowinghierarchyofanagidefn}, and that
    $\{G_\beta\}_{\beta<\alpha_\infty}$ is the slow-growing hierarchy
    given by $\alpha$ and $\mathcal F$
    (Definition \ref{slowgrowinghierarchiesdefn}).
    The \emph{transfinite Hibbard measure given by $X$} is
    the function which assigns to each AGI $Y$ a computable ordinal (or $\infty$)
    $\|Y\|_X$
    defined as follows.
    We define $\|Y\|_X$ to be the smallest ordinal $\beta<\alpha$ such that
    there is some evader $e\in E_{G_\beta}$ such that $Y$'s predictor does not
    learn to predict $e$ (where $E_{G_\beta}$ is as in Definition \ref{evadersetdefinition}),
    or we define $\|Y\|_X=\infty$ if there is no such $\beta<\alpha$.
\end{definition}

Definition \ref{transfinitehibbardmeasuredefn} avoids the order-dependency problem which
we saw in Subsection \ref{problemwithsimplehibbardsection}, because the functions
$G_{\alpha}$ which are used to define evader-sets come with their own intrinsic ordering
($G_{\alpha}$ comes before $G_{\beta}$ if and only if $\alpha<\beta$) rather than
depending on the order in which the AGI thinks of things.

If $X$ is an AGI, consider the set $S$ of all AGIs $Y$ such that $\|Y\|_X<\infty$.
The transfinite Hibbard measure given by $X$ is a computable-ordinal-valued intelligence
measure defined on $S$. This should be contrasted with intelligence measures that
are real-number-valued. In \cite{alexander2020archimedean} we point out that because
the real numbers are constrained by a certain generalized Archimedean property,
real numbers are inappropriate for measuring things which are non-Archimedean in a certain
technical sense. Arguably, if $X$ itself is sufficiently intelligent, then
the intelligences of the AGIs in $S$ are probably non-Archimedean, and so the usage of
computable ordinals to measure their intelligence is more appropriate than using real numbers.

If AGI $Y$ plays the adversarial sequence prediction game using $Y$'s brute-force
predictor, $Y$ enumerates all the Turing machines $M_1,M_2,\ldots$ such that $Y$ knows that
$M_i$ computes a total function from $B^*$ to $B$, and $Y$ systematically tries to
predict the evader $e$ by first assuming that $e$ computes the same function as
$M_1$, and if that fails, then assuming that $e$ computes the same function as
$M_2$, and so on. In particular, suppose $Y$ knows that a certain computable ordinal
$\alpha_i$ and function $\mathcal F_i$ give a slow-growing hierarchy
$\{G_\beta\}_{\beta<\alpha_i}$. For any $\beta<\alpha_i$,
since $Y$ is capable of mathematical reasoning, for every Turing machine $M$
which computes a total function from $B^*$ to $B$ and which has runtime bounded by
$G_\beta$, there should be a Turing machine $M'$ such that $M$ computes the same
function as $M'$ and such that $Y$ knows that $M'$ computes a total function from $B^*$
to $B$. Thus, $M_1,M_2,\ldots$ should include Turing machines that compute all the
functions from $B^*$ to $B$ that can be so computed with runtime bounded by any such
$G_\beta$. Thus, by Assumption \ref{bruteforceassumption}, if
$\|Y\|_X<\infty$, then it seems that $\|Y\|_X$ should in some sense measure the size
of the supremum of the ordinals $\alpha$ such that $Y$ knows a fundamental sequence up
to $\alpha$. This suggests a close relation between the transfinite Hibbard measure and
our Intuitive Ordinal Intelligence measure (an AGI $Y$'s Intuitive Ordinal Intelligence is
defined as the supremum of the ordinals $\alpha$ such that $\alpha$ has any code
$c$ such that $Y$ knows that $c$ is the code of a computable ordinal)
\cite{ioi1} \cite{ioi2}.

\section{Summary and Conclusion}
\label{conclusionsection}

To summarize:
\begin{itemize}
    \item
    Hibbard proposed \cite{hibbard} an intelligence measure for predictors (and, implicitly,
    for AGIs capable of acting as predictors) in games of adversarial sequence prediction.
    \item
    Hibbard's measure depends on one specific sequence of computable functions
    from $\mathbb N$ to $\mathbb N$.
    \item
    In Section \ref{agiperspectivesection}, we argued that all AGIs probably have
    intelligence $\infty$ according to Hibbard's definition. Essentially, this is because
    the specific functions that Hibbard's definition is based on should all be trivially
    well-known by any genuine AGI.
    \item
    In Section \ref{simplemeasuresection}, we introduced what we call \emph{simple Hibbard
    measures}. For each AGI $X$, there is a corresponding relative Hibbard measure which
    assigns an intelligence measurement $|Y|_X$ to every AGI $Y$. The relative Hibbard
    measure corresponding to $X$ might be thought of as a measure of ``intelligence as
    judged by $X$''. The key insight needed to define the
    relative Hibbard measure corresponding
    to $X$ is as follows: rather than depend on one fixed sequence of functions (as in
    Hibbard's original definition), we can delegate the task of choosing a function-sequence
    to $X$.
    \item
    We showed that relative Hibbard measures are less trivial than Hibbard's original measure.
    However, they still suffer a crucial flaw: the Hibbard measure corresponding to an
    AGI $X$ depends unnaturally on the \emph{order} in which $X$ can think of
    computable functions.
    \item
    To remedy the above-mentioned flaw in the relative Hibbard measures, we reviewed
    \emph{slow-growing hierarchies} from mathematical logic and used them to define
    (in Section \ref{transfinitehibbardsection}) what
    we call \emph{transfinite Hibbard measures}, which lead to
    computable-ordinal-number-valued
    intelligence measures rather than real-number-valued intelligence measures.
\end{itemize}

This paper exemplifies a useful technique for theoretical AGI research.
By viewing an AGI as an employee who is capable of engaging in casual human
language communication with its employer, and which can be commanded (using said
casual human language) to perform mathematical tasks, the AGI becomes a useful
black box to which many arbitrary decisions can be delegated. For example, instead
of arbitrarily choosing one particular function-sequence (as Hibbard did in order
to define his original measure), we can short-circuit the task of
function-sequence-selection by delegating it to an AGI.


\bibliographystyle{plain}
\bibliography{hibbard}
\end{document}
