\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{mathdots}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{informallemma}[theorem]{Informal Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{openquestion}[theorem]{Open Question}

\title{Measuring intelligence and growth rate: variations on
Hibbard's intelligence measure}
\author{Samuel Alexander\thanks{The U.S.\ Securities and Exchange Commission.}
\thanks{Samuel Alexander is the primary author.}\ \ and Bill Hibbard\thanks{Space Science
and Engineering Center, University of Wisconsin, Madison.}}
\date{2020}

\begin{document}

\maketitle

\begin{abstract}
    In 2011, Hibbard suggested an intelligence measure for agents
    who compete in an adversarial sequence prediction game. We argue
    that Hibbard's idea should actually be considered as two separate
    ideas: first, that the intelligence of such agents can be measured
    based on the growth rates of the runtimes of the competitors that
    they defeat; and second, one specific (somewhat arbitrary) method for measuring said
    growth rates. Whereas Hibbard's intelligence measure is based on the latter
    growth-rate-measuring method, we survey
    other methods for measuring function
    growth rates, and exhibit the resulting Hibbard-like intelligence measures
    and taxonomies. Of particular interest, we obtain intelligence taxonomies
    based on Big-O and Big-Î˜ notation systems, which taxonomies
    are novel in that they challenge conventional notions of what an
    intelligence measure should look like. We discuss how intelligence measurement
    of sequence predictors can indirectly serve as intelligence measurement for
    agents with Artificial General Intelligence (AGIs).
\end{abstract}

\section{Introduction}

In his insightful paper \cite{hibbard}, Bill Hibbard introduces a novel
intelligence measure (which we will here refer to as the \emph{original Hibbard measure})
for agents who play a game of adversarial sequence prediction
\cite{hibbard2008adversarial}
``against a hierarchy of increasingly difficult sets of'' evaders (environments that attempt
to emit $1$s and $0$s in such a way as to evade prediction).
The levels of Hibbard's hierarchy are labelled by natural numbers, and
an agent's original Hibbard measure is the maximum $n\in\mathbb N$ such that
said agent learns to predict all the evaders in the $n$th level of the hierarchy,
or implicitly\footnote{Hibbard does not explicitly include the $\infty$ case in his
definition, but in his Proposition 3 he refers to agents having ``finite intelligence'', and
it is clear from context that by this he means agents who fail to predict some evader
somewhere in the hierarchy.} an agent's original Hibbard measure is $\infty$
if said agent learns to predict all the evaders in all levels of Hibbard's hierarchy.

The hierarchy which Hibbard uses to measure intelligence is based on the growth
rates of the runtimes of evaders.
We will argue that Hibbard's idea is really a combination of two
orthogonal ideas. First: that in some sense the intelligence of a predicting agent
can be measured based on the growth rates of the runtimes of the evaders whom that
predictor learns to predict. Second: Hibbard proposed one particular method for
measuring said growth rates. The growth rate measurement which Hibbard proposed yields
a corresponding intelligence measure for these agents. We will argue that \emph{any}
method for measuring growth rates of functions yields a corresponding
\emph{adversarial sequence prediction intelligence} measure (or \emph{ASPI} measure
for short) provided the underlying number system provides a way of choosing canonical bounds
for bounded sets. If the underlying number system does not provide a way of choosing
canonical bounds for bounded sets, the growth-rate-measure will yield a corresponding
ASPI taxonomy (like the big-$O$ taxonomy of asymptotic complexity).

The particular method which Hibbard used to measure function growth rates is
not very standard. We will survey other
ways of measuring function growth rates, including some more standard ways,
and these will yield corresponding ASPI measures and taxonomies.

The structure of the paper is as follows.
\begin{itemize}
    \item
    In Section \ref{originalmeasuresection}, we review the original Hibbard measure.
    \item
    In Section \ref{growthratesection}, we argue that any method of measuring
    the growth rate of functions yields an ASPI measure or taxonomy,
    and that the original Hibbard measure is just a special case resulting from
    one particular method of measuring function growth rate.
    \item
    In Section \ref{bigosection}, we consider some of the
    most standard taxonomies of
    function growth rate---Big-O notation and Big-$\Theta$ notation---and define
    corresponding ASPI taxonomies.
    \item
    In Section \ref{exoticsection}, we consider several numeric solutions to
    the problem of measuring the growth rate of functions (using various number
    systems), and define
    corresponding ASPI measures and taxonomies.
    \item
    In Section \ref{prosandconssection}, we give pros and cons of different
    ASPI measures and taxonomies.
    \item
    In Section \ref{conclusionsection}, we summarize and make concluding remarks.
\end{itemize}

\section{Hibbard's original measure}
\label{originalmeasuresection}

Hibbard proposed an intelligence measure for measuring the intelligence
of agents who compete to predict evaders in a game of
adversarial sequence prediction (we define this
formally below). A predictor $p$ (whose intelligence we want to measure)
competes against evaders $e$. In each step of the game,
both predictor and evader simultaneously choose a binary digit, $1$ or $0$.
Only after both of them have made their choice do they see which choice the other
one made, and then the game proceeds to the next step. The predictor's goal in
each round is to choose the same digit that the evader will choose;
the evader's goal is to choose a different digit than the predictor. The predictor
wins the game (and is said to \emph{learn to predict $e$}, or simply to
\emph{learn $e$}) if, after finitely many
initial steps, eventually the predictor always chooses the same digit as the
evader.

\begin{definition}
By $B$, we mean the binary alphabet $\{0,1\}$. By $B^*$, we mean the set of all
finite binary sequences. By $\langle\rangle$ we mean the empty binary sequence.
\end{definition}

\begin{definition}
\label{evaderpredictordefn}
    (Predictors and evaders)
    \begin{enumerate}
        \item
        By a \emph{predictor}, we mean a Turing machine $p$
        which takes as input a finite (possibly empty) binary sequence
        $(x_1,\ldots,x_n)\in B^*$
        (thought of as a sequence of \emph{evasions})
        and outputs $0$ or $1$ (thought of as a \emph{prediction}), which output
        we write as $p(x_1,\ldots,x_n)$.
        \item
        By an \emph{evader}, we mean a Turing machine $e$
        which takes as input a finite (possibly empty) binary sequence
        $(y_1,\ldots,y_n)\in B^*$
        (thought of as a sequence of \emph{predictions})
        and outputs $0$ or $1$ (thought of as an \emph{evasion}), which output
        we write as $e(y_1,\ldots,y_n)$.
        \item
        For any predictor $p$ and evader $e$, the \emph{result of $p$ playing the
        game of adversarial sequence
        prediction against $e$} (or more simply, the \emph{result of
        $p$ playing against $e$}) is the infinite binary sequence
        $(x_1,y_1,x_2,y_2,\ldots)$
        defined as follows:
        \begin{enumerate}
            \item
            The first evasion
            $x_1=e(\langle\rangle)$ is
            the output of $e$ when run on the empty prediction-sequence.
            \item
            The first prediction
            $y_1=p(\langle\rangle)$ is
            the output of $p$ when run on the empty evasion-sequence.
            \item
            For all $n>0$, the $(n+1)$th evasion
            $x_{n+1}=e(y_1,\ldots,y_n)$ is
            the output of $e$ on the sequence of the first $n$ predictions.
            \item
            For all $n>0$, the $(n+1)$th prediction
            $y_{n+1}=p(x_1,\ldots,x_n)$ is
            the output of $p$ on the sequence of the first $n$ evasions.
        \end{enumerate}
        \item
        Suppose $r=(x_1,y_1,x_2,y_2,\ldots)$ is the result of a predictor $p$ playing
        against an evader $e$. For every $n\geq 1$,
        we say \emph{the predictor wins round $n$ in $r$}
        if $x_n=y_n$; otherwise,
        \emph{the evader wins round $n$ in $r$}.
        We say that \emph{$p$ learns to predict $e$}
        (or simply that \emph{$p$ learns $e$}) if there is some $N\in\mathbb N$
        such that for all $n>N$, $p$ is the winner of round $n$ in $r$.
    \end{enumerate}
\end{definition}

Note that if $e$ simply ignores its inputs $(y_1,\ldots,y_n)$ and instead
computes $e(y_1,\ldots,y_n)$ based only on $n$, then $e$ is essentially a sequence.
Thus Definition \ref{evaderpredictordefn} is a generalization of sequence prediction,
which many authors have written about (such as Legg \cite{legg2006there}, who gives many
references).

In the following definition, we differ from Hibbard's original paper
because of a minor (and fortunately, easy-to-fix) error there.

\begin{definition}
\label{tsubedefinition}
    Suppose $e$ is an evader.
    For each $n\in\mathbb N$, let $t_e(n)$ be the maximum number of steps that $e$ takes
    to run on any length-$n$ sequence of binary digits.
    In other words, $t_e(0)$ is the number of steps $e$ takes to run on $\langle\rangle$,
    and for all $n>0$,
    \[
        t_e(n) = \max_{b_1,\ldots,b_n\in \{0,1\}}
        (\text{number of steps $e$ takes to run on $(b_1,\ldots,b_n)$}).
    \]
\end{definition}

\begin{example}
    Let $e$ be an evader. Then
    $t_e(2)$ is equal to the number of steps $e$ takes to run on input
    $(0,0)$, or to run on input $(0,1)$, or to run on input $(1,0)$, or to run on input
    $(1,1)$---whichever of these four possibilities is largest.
\end{example}

\begin{definition}
\label{functionsuccdefn}
    Suppose $f:\mathbb N\to\mathbb N$ and $g:\mathbb N\to\mathbb N$.
    We say $f$ \emph{majorizes} $g$, written
    $f\succ g$, if there is some $n_0\in \mathbb N$ such that for all
    $n>n_0$, $f(n)>g(n)$.
\end{definition}

\begin{definition}
\label{evadersetdefinition}
    Suppose $f:\mathbb N\to\mathbb N$. We define
    $E_f$ to be the set of all evaders $e$ such that
    $f\succ t_e$.
\end{definition}

\begin{definition}
\label{classichibbardmeasuredefn}
    (The original Hibbard measure)
    Let $g_1,g_2,\ldots$ be the enumeration of the primitive recursive
    functions given by Liu \cite{liu1960enumeration}.
    For each $m>0$, define $f_m:\mathbb N\to\mathbb N$ by
    \[f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g_i(j).\]
    For any predictor $p$, we define the \emph{original Hibbard intelligence of $p$}
    to be the maximum $m>0$
    such that $p$ learns to predict $e$ for every $e\in E_{f_m}$
    (or $0$ if there is no such $m$, or $\infty$ if $p$ learns to predict $e$
    for every $e\in E_{f_m}$ for every $m>0$).
\end{definition}

\subsection{Predictor intelligence and AGI intelligence}
\label{agiproxysection}

Definition \ref{classichibbardmeasuredefn}, and similar measures and taxonomies
which we will
define later, as written, only quantify the intelligence of one very specific type
of agent, namely, predictors in the game of adversarial sequence prediction.
But any method for quantifying the intelligence of such predictors can also
approximately quantify the intelligence of (suitably idealized)
agents with Artificial General Intellience (that is, the intelligence of AGIs).

Presumably, a suitably idealized AGI should be capable of understanding, and
obedient in following or trying to follow, commands issued in everyday human
language\footnote{It is somewhat unclear how explicitly an AGI would
obey certain commands. To use an example of Yampolskiy
\cite{yampolskiycontrol}, if we asked a car-driving AGI
to stop the car, would the AGI stop the car
in the middle of traffic, or would it pull over to the side first?
We assume this ambiguity does not apply when we ask the AGI to perform
tasks of a sufficiently abstract and mathematical nature.}.
For example, if an AGI were commanded, ``until further notice, compute and list the
digits of pi,'' the AGI should be capable of understanding that command, and should
obediently compute said digits until commanded otherwise\footnote{Our thinking
here is reminiscent of some remarks of Yampolskiy \cite{yampolskiy2013turing}.}.

It is unclear how an AGI ought to respond if given an impossible command,
such as ``write a computer program
that solves the halting problem'', or Yampolskiy's \cite{yampolskiycontrol}
``Disobey!'' But an AGI should be capable of
understanding and attempting to obey an open-ended command, provided it is not
impossible. For example, we could command an AGI to ``until further notice,
write an endless poem about trees,'' and the AGI should be able to do so, writing
said poem line-by-line until we tell it to stop. This is despite the fact that the
command is open-ended and under-determined
(there are many decisions involved in writing a
poem about trees, and we have left all these decisions to the AGI's discretion).
The AGI's ability to obey such open-ended and under-determined commands
exemplifies its
ability to ``adapt with insufficient
knowledge and resources'' \cite{wang2019defining}.
One well-known example of an open-ended command which an AGI should be perfectly
capable of attempting to obey (perhaps at great peril to us all) is
Bostrom's ``manufacture as many paperclips as possible'' \cite{bostrom2003ethical}.

In particular, an AGI $X$ should be perfectly capable of obeying the following command:
``Act as a predictor in the game of adversarial sequence prediction''.
By giving $X$ this command, and then immediately filtering out all $X$'s
sensory input except only for input about the digits chosen by an evader,
we would obtain a formal predictor in the sense of Definition \ref{evaderpredictordefn}.
This predictor might be called ``the predictor generated by $X$''. Strictly speaking,
if the command is given to $X$ at time $t$, then it would be more proper to call
the resulting predictor ``the predictor generated by $X$ at time $t$'': up until
time $t$, the observations $X$ makes about the universe might have an effect on
the strategy $X$ chooses to take once commanded to act as a predictor; but as long
as we filter $X$'s sensory input immediately after giving $X$ the command, no
further such observations can so alter $X$'s strategy.
In short, to use Yampolskiy's terminology \cite{yampolskiy2012ai}, the act of
trying to predict adversarial sequence evaders is \emph{AI-easy}.

Thus, any intelligence measure (or taxonomy) for predictors also serves as an intelligence
measure (or taxonomy) for AGIs. Namely: the intelligence level of an AGI $X$ is equal to the
intelligence level of $X$'s predictor. Of course, a priori,
$X$ might be very intelligent at various other things while being poor
at sequence prediction, or vice versa, so this only
approximately captures $X$'s true intelligence.


\section{Quantifying growth rates of functions}
\label{growthratesection}

The following is a general and open-ended problem.

\begin{problem}
\label{bigoproblem}
    Quantify the growth-rate of functions from $\mathbb N$ to $\mathbb N$.
\end{problem}

The definition of the original Hibbard measure
(Definition \ref{classichibbardmeasuredefn})
can be thought of as implicitly depending on a specific solution to Problem
\ref{bigoproblem}, which we make explicit in the following definition.

\begin{definition}
\label{hibbardgrowthratedefn}
    For each $m>0$, let $f_m$ be as in Definition \ref{classichibbardmeasuredefn}.
    For each $f:\mathbb N\to\mathbb N$, we define the \emph{original Hibbard growth rate}
    $H(f)$ to be $\min\{m>0\,:\,f_m\succ f\}$ if there is any such $m>0$, and otherwise
    $H(f)=\infty$.
\end{definition}

\begin{lemma}
\label{straightfwdtechnicallemma}
    For every natural $m>0$ and every $f:\mathbb N\to\mathbb N$,
    $H(f)\leq m$ if and only if $f_m\succ f$.
\end{lemma}

\begin{proof}
    Straightforward.
\end{proof}

\begin{definition}
\label{variationondefinitionofEdefn}
    For every $m\in\mathbb N$, let $E^H_m$
    be the set of all evaders $e$ such that $H(t_e)\leq m$.
\end{definition}

\begin{lemma}
\label{equivalenceoftwoevadersetslemma}
    For every natural $m>0$, $E^H_m=E_{f_m}$.
\end{lemma}

\begin{proof}
    Let $e$ be an evader. By Definition \ref{variationondefinitionofEdefn},
    $e\in E^H_m$ if and only if $H(t_e)\leq m$.
    By Lemma \ref{straightfwdtechnicallemma}, $H(t_e)\leq m$ if and only if
    $f_m\succ t_e$. But by Definition \ref{evadersetdefinition}, this is the
    case if and only if $e\in E_{f_m}$.
\end{proof}

\begin{corollary}
\label{rephrasinghibbardsmeasurecorollary}
    For every predictor $p$, the original Hibbard measure of $p$
    is equal to the maximum natural $m>0$ such that
    $p$ learns $e$ whenever $e\in E^H_m$, or is equal to $\infty$
    if $p$ learns $e$ whenever $e\in E^H_m$ for all $m>0$.
\end{corollary}

\begin{proof}
    Immediate by Lemma \ref{equivalenceoftwoevadersetslemma}
    and Definition \ref{classichibbardmeasuredefn}.
\end{proof}

In other words, if $S$ is the set of all the $m$ as in Corollary
\ref{rephrasinghibbardsmeasurecorollary}, then the original Hibbard
measure of $p$ is the ``canonical upper bound'' of $S$, where
by the ``canonical upper bound'' of a set of natural numbers
we mean the maximum element of that set (or $\infty$ if that set
is unbounded).

\begin{remark}
\label{epiphanyremark}
Corollary \ref{rephrasinghibbardsmeasurecorollary} shows that
the definition of the original Hibbard measure can be rephrased in such a way
as to show that it depends in a uniform way on a particular solution to
Problem \ref{bigoproblem}, namely on the solution proposed by
Definition \ref{hibbardgrowthratedefn}. For \emph{any} solution $H'$ to
Problem \ref{bigoproblem}, we could define evader-sets $E^{H'}_m$ in a similar
way to Definition \ref{variationondefinitionofEdefn}, and, by copying
Corollary \ref{rephrasinghibbardsmeasurecorollary}, we could obtain a corresponding
intelligence measure given by $H'$
(provided there be some way of choosing canonical bounds of bounded sets in the
underlying number system---if not, we would have to be content with a taxonomy
rather than a measure, a predictor's intelligence falling into many nested
taxa corresponding to many different upper bounds, just as in Big-O notation a
function can simultaneously be $O(n^2)$ and $O(n^3)$).
This formalizes what we claimed in the Introduction,
that Hibbard's idea can be decomposed into two sub-ideas, firstly, that a predictor's
intelligence can be classified in terms of the growth rates of the runtimes of the
evaders it learns, and secondly, a particular method
(Definition \ref{hibbardgrowthratedefn})
of measuring those growth rates (i.e., a particular solution to
Problem \ref{bigoproblem}).
\end{remark}


\section{Big-O and Big-$\Theta$ intelligence}
\label{bigosection}

One of the most standard solutions
to Problem \ref{bigoproblem} in computer science is to categorize
growth rates of arbitrary functions by comparing them to more familiar functions using
Big-O notation or Big-$\Theta$ notation.
Knuth defines \cite{knuth1976big} these as follows
(we modify the definition slightly because
we are only concerned here with functions from $\mathbb N$ to $\mathbb N$).

\begin{definition}
\label{bigodefn}
    Suppose $f:\mathbb N\to\mathbb N$. We define the following function-sets.
    \begin{itemize}
        \item
        $O(f(n))$ is the set of all $g:\mathbb N\to\mathbb N$ such that
        there is some real $C>0$ and some $n_0\in\mathbb N$ such that
        for all $n\geq n_0$, $g(n)\leq Cf(n)$.
        \item
        $\Theta(f(n))$ is the set of all $g:\mathbb N\to\mathbb N$ such that
        there are some real $C>0$ and $C'>0$ and some $n_0\in\mathbb N$ such that
        for all $n\geq n_0$, $Cf(n)\leq g(n)\leq C'f(n)$.
    \end{itemize}
\end{definition}

Note that Definition \ref{bigodefn} does not measure growth rates, but rather
categorizes growth rates into Big-O and Big-$\Theta$ taxonomies.
For example, the same function can be
both $O(n^2)$ and $O(n^3)$, the former taxon being nested within the latter.

By Remark \ref{epiphanyremark}, Definition \ref{bigodefn} yields the following elegant
taxonomy of predictor intelligence.

\begin{definition}
\label{bigointelligencedefn}
    Suppose $p$ is a predictor, and suppose $f:\mathbb N\to\mathbb N$.
    \begin{itemize}
        \item
        We say \emph{$p$ has Big-O ASPI measure $O(f(n))$} if
        $p$ learns every evader $e$ such that $t_e$ is $O(f(n))$.
        \item
        We say \emph{$p$ has Big-$\Theta$ ASPI measure $\Theta(f(n))$} if
        $p$ learns every evader $e$ such that $t_e$ is $\Theta(f(n))$.
    \end{itemize}
\end{definition}

\section{ASPI measures and taxonomies using various number systems}
\label{exoticsection}

In this section we will consider various solutions to
Problem \ref{bigoproblem} in various different number systems,
and the ASPI measures and taxonomies they produce.

\subsection{The hyperreal ASPI taxonomy}

Hyperreal numbers, studied in the field of non-standard analysis \cite{robinson}
\cite{goldblatt2012lectures},
are equivalence classes of infinite sequences of reals,
so for every sequence $r=(r_0,r_1,r_2,\ldots)$ of reals, there is a corresponding
hyperreal $\hat r$ represented by that sequence.
Arithmetic is performed pointwise, so if $r=(r_0,r_1,r_2,\ldots)$ and
$s=(s_0,s_1,s_2,\ldots)$, then $\hat r + \hat s$
is the hyperreal represented by $(r_0+s_0,r_1+s_1,r_2+s_2,\ldots)$,
and $\hat r\cdot\hat s$ is the hyperreal represented by
$(r_0 s_0,r_1 s_1, r_2 s_2,\ldots)$.

The difficulty in constructing the hyperreals is how to compare two hyperreals.
We would like to compare them pointwise, so for example
with $r,s$ as above, we would want to have $\hat r<\hat s$ if
every $r_i<s_i$, or $\hat s<\hat r$ if every $s_i<r_i$.
Having done this, we would immediately obtain an elegant abstract
solution to Problem \ref{bigoproblem} using hyperreal numbers,
namely: the growth rate of $f(n)$ could be defined to be the
hyperreal number represented by $(f(0),f(1),f(2),\ldots)$.
But\footnote{This is similar to the problem of deciding which
of two reinforcement learning agents is more intelligent, if one agent
performs better in infinitely many environments, but the other agent performs
better in infinitely many other environments. For a treatment of that problem
using free ultrafilters, see \cite{alexander2019intelligence}.}
how should $\hat r$ and $\hat s$ compare if there are infinitely
many $i$ such that $r_i<s_i$ and infinitely many $i$ such that
$s_i<r_i$? The answer is to declare $\hat r<\hat s$ if the set
$\{i\in\mathbb N\,:\,r_i<s_i\}$ is ``large'', but it is not clear
what it should mean for a set of natural numbers to be ``large''.

It turns out that the best answer---the only answer which leads to
hyperreals with the properties we would want an extension of the
reals to have---is to let the question of largeness of natural numbers
be decided by an object called a \emph{free ultrafilter}.
Loosely speaking, a free ultrafilter can be thought
of as a black box which makes judgments about which subsets of $\mathbb N$
are ``large'' (and does so in a particularly consistent way).
Unfortunately, free ultrafilters are non-constructive: mathematicians have
shown that free ultrafilters
exist, but that it is impossible to concretely exhibit one.
For the remainder of the section, we assume a free ultrafilter has been
chosen, and we work in the resulting construction of the hyperreal numbers.

\begin{definition}
\label{hyperrealgrowthratedefn}
    (The hyperreal solution to Problem \ref{bigoproblem})
    For any function $f:\mathbb N\to\mathbb N$, the \emph{hyperreal growth rate
    of $f$} is the hyperreal number $\hat r$
    where $r=(f(0),f(1),f(2),\ldots)$.
\end{definition}

Because of the non-constructive nature of free ultrafilters, the following notion
is computationally impractical. However, it could potentially be useful for
proving theoretical properties about the intelligence of predictors. In the following
definition, rather than assigning a particular hyperreal number intelligence to every
predictor, rather, we categorize predictors into a taxonomy.
This is necessary because there is no way of choosing canonical bounds
of bounded sets of hyperreal numbers in general. For lack of a way of
choosing a particular bound, we are forced to consider many taxa corresponding
to many bounds.


\begin{definition}
\label{hyperrealhibbardintelligencedefn}
    (The hyperreal ASPI taxonomy)
    Let $p$ be a predictor and let $\hat r$ be a hyperreal number.
    We say that $p$ \emph{has hyperreal ASPI intelligence at least $\hat r$}
    if and only if the following condition holds:
    for every evader $e$, if the hyperreal growth rate of $t_e$ is
    $<\hat r$, then $p$ learns $e$.
\end{definition}

\subsection{The surreal ASPI measure}

The surreal numbers \cite{conway} \cite{knuth} \cite{ehrlich2012absolute}
are an even larger extension
of the real numbers
into which the hyperreals can be embedded.

\begin{definition}
    (The surreal solution to Problem \ref{bigoproblem})
    Let $\iota$ be the embedding of the hyperreal numbers into the surreal
    numbers.
    For any function $f:\mathbb N\to\mathbb N$, the \emph{surreal growth rate
    of $f$} is $\iota(\hat r)$ where $\hat r$ is the hyperreal growth
    rate of $f$ (Definition \ref{hyperrealgrowthratedefn}).
\end{definition}

The advantage of the surreal numbers is that for any set $L$ of surreal numbers,
there is a canonical way to choose a surreal upper bound on $L$,
which upper bound is written $\{L\,|\,\}$. This upper bound is similar to a
supremum of $L$ in a certain sense: the surreal numbers possess a
simplicity-hierarchical structure, and $\{L\,|\,\}$ is the \emph{simplest}
strict upper bound of $L$. This allows us to
exactly measure intelligence of predictors,
rather than merely classify predictors in a taxonomy as in the case of
the hyperreal ASPI measures (Definition \ref{hyperrealhibbardintelligencedefn}).

\begin{definition}
\label{surrealhibbardintelligencedefn}
    (The surreal ASPI measure)
    For every predictor $p$, the \emph{surreal ASPI measure} of $p$
    is defined to be $\{L\,|\,\}$, the simplest surreal strict upper bound
    of $L$, where $L$ is the set of all surreal numbers $\ell$ such that
    the following condition holds: for every evader $e$,
    if the surreal growth rate of $t_e$ is $<\ell$, then $p$ learns $e$.
\end{definition}

\subsection{ASPI measures based on majorization hierarchies}

Majorization hierarchies \cite{weiermann2002slow}
provide ordinal-number-valued measures for the growth
rates of certain functions. A majorization hierarchy depends
on many infinite-dimensional parameters. We will describe two
majorization hierarchies up to the ordinal $\epsilon_0$,
using standard choices for the parameters, and the ASPI measures
which they produce.

\begin{definition}
    (Classification of ordinal numbers)
    Ordinal numbers are divided into three types:
    \begin{enumerate}
        \item Zero: The ordinal $0$.
        \item Successor ordinals: Ordinals of the form $\alpha+1$ for some ordinal $\alpha$.
        \item Limit ordinals: Ordinals which are not successor ordinals nor $0$.
    \end{enumerate}
\end{definition}

For example, the smallest infinite ordinal, $\omega$, is a limit ordinal. It is not zero
(because zero is finite),
nor can it be a successor ordinal, because if it were a successor ordinal, say, $\alpha+1$,
then $\alpha$ would be finite (since $\omega$ is the \emph{smallest} infinite ordinal),
but then $\alpha+1$ would be finite as well.

Ordinal numbers have an arithmetical structure: two ordinals $\alpha$ and $\beta$
have a sum $\alpha+\beta$, a product $\alpha\cdot \beta$, and a power
$\alpha^\beta$. It would be beyond the scope of this paper to give the full
definition of these operations. We will only remark that some care is needed because
although ordinal arithmetic is associative---e.g.,
$(\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)$, and similarly for multiplication---it is
not generally commutative: $\alpha+\beta$ is not always equal to $\beta+\alpha$,
and $\alpha\cdot\beta$ is not always equal to $\beta\cdot\alpha$. For this reason,
one often sees products like $\alpha\cdot 2$, which are not necessarily equivalent to the
more familiar $2\cdot\alpha$.

The ordinal $\epsilon_0$ is the smallest ordinal bigger than the ordinals
$\omega,\omega^\omega,\omega^{\omega^\omega},\ldots$. It satisfies the equation
$\epsilon_0=\omega^{\epsilon_0}$ and can be intuitively thought of as
\[
    \epsilon_0 = \omega^{\omega^{\omega^{\iddots}}}.
\]
Ordinals below $\epsilon_0$ include such ordinals as $\omega$,
$\omega^{\omega+1}+\omega^{\omega}+\omega^5+3$,
\[
\omega^{\omega^{\omega^{\omega^\omega}}}+
\omega^{\omega^{\omega^\omega}+\omega^{\omega\cdot 2+1}+\omega^4 + 3}
+ \omega^{\omega^5+\omega^3}+\omega^8+1,
\]
and so on.
Any ordinal below $\epsilon_0$ can be uniquely written in the form
\[
    \omega^{\alpha_1}+\omega^{\alpha_2}+\cdots + \omega^{\alpha_k}
\]
where $\alpha_1\geq\cdots\geq\alpha_k$ are smaller ordinals below $\epsilon_0$---this form
for an ordinal below $\epsilon_0$ is called its \emph{Cantor normal form}.
For example, the Cantor normal form for $\omega^{\omega\cdot 2}\cdot 2+\omega\cdot 3+2$
is
\[
\omega^{\omega\cdot 2}\cdot 2+\omega\cdot 3+2
=
\omega^{\omega\cdot 2} + \omega^{\omega\cdot 2} + \omega^1 + \omega^1 + \omega^1
+\omega^0 + \omega^0.
\]

\begin{definition}
\label{fundsequencesdefn}
    (Standard fundamental sequences for limit ordinals $\leq\epsilon_0$)
    Suppose $\lambda$ is a limit ordinal $\leq\epsilon_0$. We define a
    \emph{fundamental sequence for $\lambda$},
    written $(\lambda[0],\lambda[1],\lambda[2],\ldots)$, inductively as follows.
    \begin{itemize}
        \item
        If $\lambda=\epsilon_0$, then $\lambda[0]=0$,
        $\lambda[1]=\omega^0$, $\lambda[2]=\omega^{\omega^0}$, and so on.
        \item
        If $\lambda$ has Cantor normal form
        $\omega^{\alpha_1}+\cdots+\omega^{\alpha_k}$ where $k>1$,
        then
        each
        \[
            \lambda[i] = \omega^{\alpha_1}+\cdots+\omega^{\alpha_{k-1}}
            + (\omega^{\alpha_k}[i]).
        \]
        \item
        If $\lambda$ has Cantor normal form $\omega^{\alpha+1}$,
        then each $\lambda[i]=\omega^{\alpha}\cdot i$.
        \item
        If $\lambda$ has Cantor normal form $\omega^{\lambda_0}$ where $\lambda_0$
        is a limit ordinal, then each $\lambda[i]=\omega^{\lambda_0[i]}$.
    \end{itemize}
\end{definition}

\begin{example}
    (Fundamental sequence examples)
    \begin{itemize}
        \item
        The fundamental sequence for $\lambda=\omega=\omega^1=\omega^{0+1}$ is
        $\omega^0\cdot 0, \omega^0\cdot 1, \omega^0\cdot 2, \ldots$,
        i.e., $0, 1, 2, \ldots$.
        \item
        The fundamental sequence for $\lambda=\omega^5$ is
        $0,\omega^4,\omega^4\cdot 2,\omega^4\cdot 3,\ldots$.
        \item
        The fundamental sequence for $\lambda=\omega^\omega$ is
        $\omega^0,\omega^1,\omega^2,\ldots$.
        \item
        The fundamental sequence for $\lambda=\omega^\omega+\omega$ is
        $\omega^\omega+0,\omega^\omega+1,\omega^\omega+2,\ldots$.
    \end{itemize}
\end{example}

\begin{definition}
\label{slowgrowinghierarchydefn}
    (The standard slow-growing hierarchy up to $\epsilon_0$)
    We define functions $g_\beta:\mathbb N\to\mathbb N$ (for all ordinals
    $\leq \epsilon_0$) by transfinite induction as follows.
    \begin{itemize}
        \item
        $g_0(n)=0$.
        \item
        $g_{\alpha+1}(n) = g_\alpha(n) + 1$ if $\alpha+1\leq\epsilon_0$.
        \item
        $g_{\lambda}(n) = g_{\lambda[n]}(n)$ if $\lambda\leq\epsilon_0$ is a limit ordinal.
    \end{itemize}
\end{definition}

Here are some early levels in the slow-growing hierarchy, spelled out in detail.

\begin{example}
\label{highdetailslowgrowingexample}
    (Early examples of functions in the slow-growing hierarchy)
    \begin{enumerate}
        \item
        $g_1(n)=g_{0+1}(n)=g_0(n)+1=0+1=1$.
        \item
        $g_2(n)=g_{1+1}(n)=g_1(n)+1=1+1=2$.
        \item
        More generally, for all $m\in\mathbb N$,
        $g_m(n)=m$.
        \item
        $g_\omega(n)=g_{\omega[n]}(n)=g_n(n)=n$.
        \item
        $g_{\omega+1}(n)=g_{\omega}(n)+1=n+1$.
        \item
        $g_{\omega+2}(n)=g_{\omega+1}(n)+1=(n+1)+1=n+2$.
        \item
        More generally, for all $m\in\mathbb N$,
        $g_{\omega+m}(n)=n+m$.
        \item
        $g_{\omega\cdot 2}(n)=g_{(\omega\cdot 2)[n]}(n)
        =g_{\omega+n}(n)=n+n=n\cdot 2$.
    \end{enumerate}
\end{example}

Following Example \ref{highdetailslowgrowingexample}, the reader should be able
to fill in the details in the following example.

\begin{example}
    (More examples from the slow-growing hierarchy)
    \begin{enumerate}
        \item
        $g_{\omega^2}(n)=n^2$.
        \item
        $g_{\omega^3}(n)=n^3$.
        \item
        $g_{\omega^\omega}(n)=n^n$.
        \item
        $g_{\omega^{\omega\cdot 3+1}+\omega+5}(n)=n^{3n+1}+n+5$.
        \item
        $g_{\omega^{\omega^{\omega}}}(n)=n^{n^n}$.
    \end{enumerate}
\end{example}

What about $g_{\epsilon_0}$? Thinking of $\epsilon_0$ as
\[\omega^{\omega^{\omega^{\iddots}}},\]
one might expect $g_{\epsilon_0}(n)$ to be
\[n^{n^{n^{\iddots}}},\]
but such an infinite tower
of natural number exponents makes no sense if $n>1$. Instead,
the answer defies familiar mathematical
notation.

\begin{example}
\label{epsilon0example}
(Level $\epsilon_0$ in the slow-growing hierarchy)
The values of $g_{\epsilon_0}$ are as follows:
\begin{itemize}
    \item
    $g_{\epsilon_0}(0)=0$.
    \item
    $g_{\epsilon_0}(1)=1^1$.
    \item
    $g_{\epsilon_0}(2)=2^{2^2}$.
    \item
    $g_{\epsilon_0}(3)=3^{3^{3^3}}$.
    \item
    And so on.
\end{itemize}
\end{example}

Examples \ref{highdetailslowgrowingexample}--\ref{epsilon0example} illustrate
how the slow-growing hierarchy systematically provides a family of reference
functions against which any particular function can be compared.
This yields a solution to Problem \ref{bigoproblem}: we can declare the growth
rate of an arbitrary function $f:\mathbb N\to\mathbb N$ to be the smallest ordinal
$\beta< \epsilon_0$ such that $g_\beta\succ f$ (or $\infty$ if there is no such
$\beta$).
For any bounded set $S$ of ordinals, there is a canonical upper bound for $S$,
namely, the supremum of $S$.
Thus we obtain an ASPI measure (not just a taxonomy).

\begin{definition}
\label{tradmajorizationhierarchyhibbardmeasuredefn}
    If $p$ is a predictor, the \emph{ASPI measure of $p$ given by the
    standard slow-growing hierarchy up to $\epsilon_0$} is defined to be the
    supremum of $S$ (or $\infty$
    if $\epsilon_0\in S$), where $S$ is the set of all ordinals
    $\alpha\leq\epsilon_0$
    such that the following condition holds:
    for every predictor $e$, if $g_\alpha\succ t_e$, then $p$ learns $e$.
\end{definition}

In Definition \ref{slowgrowinghierarchydefn}, in the successor ordinal case,
we chose to define $g_{\alpha+1}(n)=g_\alpha(n)+1$. The resulting majorization
hierarchy is referred to as \emph{slow-growing} because in some sense this
makes $g_{\alpha+1}$ just barely faster-growing than $g_\alpha$.
Different definitions of $g_{\alpha+1}$ would yield different majorization
hierarchies, such as the following.

\begin{definition}
\label{fastgrowinghierarchydefn}
    (The standard fast-growing hierarchy up to $\epsilon_0$, also known as
    the Wainer hierarchy)
    We define functions $h_\beta:\mathbb N\to\mathbb N$ (for all ordinals
    $\beta\leq \epsilon_0$) by transfinite induction as follows.
    \begin{itemize}
        \item
        $h_0(n)=0$.
        \item
        $h_{\alpha+1}(n) = h^n_\alpha(n)$, where $h^n_\alpha$ is the $n$th
        iterate of $h_\alpha$ (so $h^1_\alpha(x)=h_\alpha(x)$,
        $h^2_\alpha(x)=h_\alpha(h_\alpha(x))$,
        $h^3_\alpha(x)=h_\alpha(h_\alpha(h_\alpha(x)))$, and so on).
        \item
        $h_{\lambda}(n) = h_{\lambda[n]}(n)$ if $\lambda$ is a
        limit ordinal $\leq\epsilon_0$.
    \end{itemize}
\end{definition}

The functions in the fast-growing hierarchy grow quickly
as $\alpha$ grows. It can be shown \cite{wainer1987provably} that
for every computable function $f$ whose totality can be proven from the axioms of
Peano arithmetic, there is some $\alpha<\epsilon_0$ such that $h_\alpha\succ f$.

\begin{definition}
\label{fastmajorizationhierarchyhibbardmeasuredefn}
    If $p$ is a predictor, the \emph{ASPI measure of $X$ given by the
    standard fast-growing hierarchy up to $\epsilon_0$} is defined to be the
    supremum of $S$ (or $\infty$ if $\epsilon_0\in S$),
    where $S$ is the set of all ordinals $\alpha\leq\epsilon_0$ such that
    the following condition holds:
    for every predictor $e$, if $h_\alpha\succ t_e$, then $p$ learns $e$.
\end{definition}

Between Definitions \ref{tradmajorizationhierarchyhibbardmeasuredefn} and
\ref{fastmajorizationhierarchyhibbardmeasuredefn}, the former offers a higher
granularity
intelligence measure for the predictors which it assigns non-$\infty$
intelligence to, but the latter assigns non-$\infty$ intelligence to a much larger
set of predictors.

Definitions \ref{slowgrowinghierarchydefn}
and \ref{fastgrowinghierarchydefn} are only two
examples of
majorization hierarchies. Both the slow- and fast-growing hierarchies can be
extended by extending the fundamental sequences of Definition
\ref{fundsequencesdefn} to larger ordinals\footnote{Remarkably,
the slow-growing hierarchy eventually catches up with the fast-growing hierarchy
if both hierarchies are extended to sufficiently large ordinals
\cite{wainer1989slow} \cite{girard1981pi12}, a beautiful illustration of
how counter-intuitive
large ordinal numbers can be.}, however, the larger
the ordinals become, the more difficult it is to do this, and especially the less
clear it is how to do it in any sort of canonical way.
There are also other choices for how to proceed at successor ordinal stages besides
$g_{\alpha+1}(n)=g_\alpha(n)+1$ or $h_{\alpha+1}(n)=h^n_\alpha(n)$---for example,
one of the oldest majorization hierarchies is the Hardy hierarchy
\cite{hardy1904theorem}, where $H_{\alpha+1}(n)=H_\alpha(n+1)$.
And even for ordinals up to $\epsilon_0$,
there are other ways to choose fundamental sequences besides how we defined them in
Definition \ref{fundsequencesdefn}---choosing non-canonical fundamental sequences can
drastically alter the resulting majorization hierarchy \cite{weiermann1997sometimes}.
All these different majorization hierarchies yield different ASPI measures.

\subsection{A remark about ASPI measures and AGI intelligence}

All the ASPI measures we have defined so far double as indirect intelligence
measure for an AGI, by the argument we made in Subsection \ref{agiproxysection}.

For a given AGI $X$, a priori, we cannot say much for certain about the predictor $X$
would act as if $X$ were commanded to act as a predictor. But there is one particularly
elegant and parsimonious strategy which $X$ might use, a \emph{brute force strategy},
namely:
\begin{itemize}
    \item Enumerate all the
    computable functions $f$ which $X$ knows to be total, and for each one, attempt to
    predict the evader $e$ by assuming that the evader's runtime $t_e$
    satisfies $f\succ t_e$.
    If the evader proves not to be so majorized (by differing from every computable
    function whose runtime is so majorized), then move on to the next
    known total function $f$, and continue the process.
\end{itemize}
We do not
know for certain which predictor $X$ would imitate when commanded to act as a predictor,
but it seems plausible that $X$ would use this brute force strategy or something
equivalent.

For an AGI $X$ who uses the above brute force strategy, ASPI
measures of $X$'s intelligence would be determined by $X$'s knowledge, namely,
by the runtime complexity of the computable functions $X$ knows to be total.
Furthermore, the most natural way for $X$ to know totality of functions with large
runtime complexity, is for $X$ to know fundamental sequences for large ordinal
numbers, and produce said functions by means of majorization
hierarchies\footnote{It may be
possible for an AGI to be contrived to know totality of functions that are larger
than the functions produced by majorization hierarchies up to ordinals the AGI knows
about, but we conjecture that that is not the case for AGIs not so deliberately
contrived.}. This suggests a connection between
\begin{enumerate}
    \item
    ASPI measures like that of
    Definition \ref{fastmajorizationhierarchyhibbardmeasuredefn}, and
    \item
    intelligence measures based on which ordinals the AGI knows
    \cite{ioi1}.
\end{enumerate}
Indeed, Alexander has argued \cite{ioi2} that
the task of notating large ordinals is one which
spans the entire range of intelligence.
This is reminiscent of Chaitin's proposal to use ordinal notation
as a goal intended to facilitate evolution---``and the larger the ordinal,
the fitter the organism'' \cite{chaitin}---and Good's observation
\cite{good1969godel} that iterated Lucas-Penrose contests boil down to
contests to name the larger ordinal.

% \subsection{Generalized majorization hierarchies}

% There are many other majorization hierarchies besides the slow-growing hierarchy.
% In Definition \ref{slowgrowinghierarchydefn},
% there is nothing special about defining $g_{\alpha+1}(n)=g_{\alpha}(n)+1$.
% Many other definitions for $g_{\alpha+1}$ would work, provided $g_{\alpha+1}$ ends
% up being faster-growing than $g_\alpha$.
% For example, in the so-called \emph{fast-growing hierarchy},
% $g_{\alpha+1}(n)$ is defined to be $g^n_\alpha(n)$, where $g^n_\alpha$
% denotes the result of iterating $g_\alpha$ $n$ times, that is,
% $g^1_\alpha(n)=g_\alpha(n)$, $g^2_\alpha(n)=g_\alpha(g_\alpha(n))$,
% $g^3_\alpha(n)=g_\alpha(g_\alpha(g_\alpha(n)))$, and so on.
% In the early levels, this produces much faster-growing functions,
% but astonishingly, at sufficiently high ordinals, the slow-growing hierarchy
% actually catches up with the fast-growing hierarchy \cite{girard1981pi12}
% (a beautiful illustration of how counter-intuitive large ordinal numbers can be).
% One of the earliest majorization hierarchies is the Hardy
% hierarchy \cite{hardy1904theorem}, where $g_{\alpha+1}(n)=g_\alpha(n+1)$.

% Likewise, there is also much flexibility in choosing fundamental sequences.
% For small ordinals such as the ordinals below $\epsilon_0$, there are very clear
% canonical fundamental sequences, but the larger the ordinals become, the harder
% it becomes to single out any choice of fundamental sequences as canonical.
% And even at low levels, choosing non-canonical fundamental sequences can
% drastically alter the resulting majorization hierarchy \cite{weiermann1997sometimes}.

% In short, there is no consensus at all about which majorization hierarchies are
% most canonical. If anything, there is consensus that there is no consensus.
% However, Hibbard-style intelligence measures are primarily of interest to researchers
% interested in agents with Artificial General Intelligence (that is, researchers
% interested in AGIs). No-one knows what exactly an AGI is, but presumably an AGI can
% be thought of\footnote{Our thinking here is reminiscent of some remarks of
% Yampolskiy \cite{yampolskiy2013turing}.} as a patient, obedient, careful,
% mechanical employee who can
% be given commands in English, and who will follow those commands (at least when
% the commands are \emph{possible} to follow---one could command an AGI to act as a
% Halting Problem solver, but it is unclear how the AGI would respond to such a command,
% since no mechanical agent can solve the Halting Problem).

% Rather than attempt the futile task of choosing a canonical majorization hierarchy
% ourselves, we can instead delegate that task to an AGI. By doing so for an arbitrary
% AGI, we will obtain an AGI-indexed family of semi-canonical majorization hierarchies.

% \begin{definition}
% \label{fairsequencedefn}
%     Suppose $X$ is an AGI. By $h^X_1,h^X_2,\ldots$, we mean the total computable
%     increasing functions
%     from $\mathbb N$ to $\mathbb N$ which $X$ would output if $X$ were commanded:
%     \begin{quote}
%         ``Until further notice, output (codes of) total computable increasing
%         functions $h_1,h_2,\ldots$ from $\mathbb N$ to $\mathbb N$ satisfying the
%         following constraints:
%         \begin{enumerate}
%             \item (Linear ordering) For any two $i,j\in\mathbb N$ with $i\neq j$, either
%             $h_i\succ h_j$ or $h_j\succ h_i$.
%             \item (Largeness) For every Turing machine $M$ such that you know
%             $M$ computes a total computable function $h:\mathbb N\to\mathbb N$,
%             there is some $i$ such that $h_i\succ h$.
%             \item (Well-foundedness) There is no sequence $i_1,i_2,\ldots$ such that
%             $h_{i_1}\succ h_{i_2}\succ\cdots$.
%             \item (Pseudo-density)
%             The $h_i$'s are to be as close as possible to being \emph{dense}---that is
%             to say, they are to be as close as possible to having the property that
%             for all $i,k\in\mathbb N$ with $h_k\succ h_i$, there is some $j\in\mathbb N$
%             such that $h_k\succ h_j\succ h_i$---without violating the above
%             well-foundedness constraint; you are to use your judgment and discretion
%             to interpret this pseudo-density requirement.''
%         \end{enumerate}
%     \end{quote}
% \end{definition}

% The above pseudo-density constraint is intentionally vague, which we can get away
% with because the definition does not depend on what pseudo-density actually means,
% but only on how the AGI interprets the \emph{words} (i.e., how the AGI responds to a
% specific well-defined stimulus, regardless of how vague the semantics of that stimulus
% may be).
% Thus, we are taking advantage of the AGI's ability to ``adapt with insufficient
% knowledge and resources'' \cite{wang2019defining}.
% We assume the AGI understands and obeys the command, so $h^X_1,h^X_2,\ldots$ really are
% total computable increasing functions from $\mathbb N$ to $\mathbb N$ satisfying the
% linear ordering, largeness\footnote{Note that the largeness requirement is defined in
% terms of the AGI's mathematical
% knowledge. See \cite{alexanderinprep} for a definition of what
% it means for an AGI to know a mathematical fact.}, and well-foundedness requirements.
% Note that the resulting $h_i$'s
% cannot actually be dense, as that would violate well-foundedness: given any $i,j$
% with $h_j\succ h_i$, there would be some $k_1$ such that $h_j\succ h_{k_1}\succ h_i$,
% and then there would be some $k_2$ such that $h_{k_1}\succ h_{k_2}\succ h_i$,
% and then there would be some $k_3$ such that $h_{k_2}\succ h_{k_3}\succ h_i$, and so
% on, but then $h_{k_1}\succ h_{k_2}\succ \cdots$ would violate well-foundedness.
% We will offer some motivation for pseudo-density in
% Remark \ref{pseudodensityremark} below.

% \begin{definition}
% \label{alphaidefn}
%     Let $X$ be an AGI. We define a sequence $\alpha^X_1,\alpha^X_2,\ldots$
%     of ordinals by recursion as follows. Note that at first glance,
%     the following recursive definition looks too circular to work.
%     We will show in Lemma \ref{transfiniterecursionmagiclemma} that
%     it avoids infinite regress and thus
%     it does work. For each $i$, let $\alpha^X_i$ be the the smallest
%     ordinal which is larger than every ordinal $\alpha^X_j$ such that
%     $h^X_i\succ h^X_j$.
% \end{definition}

% \begin{lemma}
% \label{transfiniterecursionmagiclemma}
%     Definition \ref{alphaidefn} works (it does not lead to infinite regress).
% \end{lemma}

% \begin{proof}
%     Assume, for the sake of contradiction, that Definition \ref{alphaidefn}
%     leads to infinite regress. This means there is some $i_1$ such that
%     in order to define $\alpha^X_{i_1}$ we must first define $\alpha^X_{i_2}$
%     for some $i_2$, and in order to define $\alpha^X_{i_2}$ we must first
%     define $\alpha^X_{i_3}$ for some $i_3$, and in order to define
%     $\alpha^X_{i_3}$ we must first define $\alpha^X_{i_4}$ for some $i_4$,
%     and so on forever. Thus, there is an infinite sequence $i_1,i_2,\ldots$
%     such that in order to define each $\alpha^X_{i_j}$, we must first
%     define $\alpha^X_{i_{j+1}}$. Now, each $\alpha^X_{i_j}$ is defined as
%     the smallest ordinal larger than every ordinal $\alpha^X_j$ such that
%     $h^X_{i_j}\succ h^X_j$. So, since defining $\alpha^X_{i_j}$ requires
%     us to first define $\alpha^X_{i_{j+1}}$, this implies $i_{j+1}$ is
%     such a $j$, i.e., that $h^X_{i_j}\succ h^X_{i_{j+1}}$.
%     Thus $h^X_{i_1}\succ h^X_{i_2}\succ h^X_{i_3}\succ\cdots$,
%     but this contradicts the \emph{well-foundedness} part of the command
%     from Definition \ref{fairsequencedefn}.
% \end{proof}

% \begin{lemma}
% \label{technicallemmaaboutalphaXi}
%     Let $X$ be an AGI. For all $i,j$,
%     $h^X_i\succ h^X_j$ if and only if $\alpha^X_i>\alpha^X_j$.
% \end{lemma}

% \begin{proof}
%     Fix $i$ and $j$.
%     By the \emph{linear ordering} part of the command in Definition
%     \ref{fairsequencedefn}, either $h^X_i\succ h^X_j$ or $h^X_j\succ h^X_i$.
%     Assume $h^X_i\succ h^X_j$, the other case is similar.
%     By definition, $\alpha^X_i$ is defined to be the smallest ordinal
%     which is larger than $\alpha^X_{j'}$ for every $j'$ such that
%     $h^X_i\succ h^X_{j'}$. One such $j'$ is $j$ itself,
%     so by definition $\alpha^X_i$ is larger than $\alpha^X_j$, as desired.
% \end{proof}

% \begin{definition}
% \label{generalizedmajorizationhierarchydefn}
% (Generalized majorization hierarchies)
%     Let $X$ be an AGI. Let $\alpha=\sup_i \alpha^X_i$ be the smallest ordinal
%     bigger than all of the $\alpha^X_i$'s. The \emph{generalized majorization
%     hierarchy given by $X$} is the family $(g_\beta)_{\beta<\alpha}$ of functions
%     labeled by ordinals below $\alpha$, where each $g_{\beta}$ is defined
%     such that $g_{\beta}=h^X_i$ where $i$ is such that $\beta=\alpha^X_i$.
% \end{definition}

% \begin{remark}
% \label{pseudodensityremark}
% With Definition \ref{generalizedmajorizationhierarchydefn} in view,
% the pseudo-density
% constraint in Definition \ref{fairsequencedefn} can be better motivated:
% the point of pseudo-density is to ensure that the ordinal
% $\sup_i \alpha^X_i$ is as large as possible\footnote{Chaitin \cite{chaitin}
% and Good \cite{good1969godel} have remarked
% about the importance of the size of the ordinals which an entity can notate---``and
% the larger the ordinal,
% the fitter the organism'', to quote Chaitin. See also \cite{ioi1} and \cite{ioi2}.}. An
% alternative to pseudo-density would
% be to directly command (in Definition \ref{fairsequencedefn}) that the $h_i$'s should
% be chosen in such a way as to make $\alpha=\sup_i\alpha^X_i$ large (leaving it up
% to the AGI's judgment and discretion how to interpret that), but this would be
% difficult because it would mean that Definition \ref{generalizedmajorizationhierarchydefn}
% (and its dependencies) would need to be embedded into the command in
% Definition \ref{fairsequencedefn}, which would require some significant acrobatics.
% \end{remark}

% A generalized majorization hierarchy (Definition \ref{generalizedmajorizationhierarchydefn})
% serves as a solution to Problem \ref{bigoproblem}: given any AGI $X$, we can say
% that a function $f:\mathbb N\to\mathbb N$ has growth rate
% $\beta$ where $\beta$ is the smallest ordinal $<\sup_i \alpha^X_i$
% such that $g_\beta\succ f$---or $f$ has growth rate $\infty$ if there is no
% such $\beta$. To this solution to Problem \ref{bigoproblem}, there is a corresponding
% Hibbard-style intelligence measure.

% \begin{definition}
%     (Hibbard intelligence given by an AGI)
%     Suppose $X$ is an AGI. By the \emph{transfinite Hibbard measure given by $X$},
%     we mean the measure $\|\bullet\|_X$ which assigns to every predictor $p$ an
%     intelligence measure $\|p\|_X$ defined as follows.
%     $\|p\|_X$ is defined to be the smallest $\beta<\sup_i\alpha^X_i$
%     such that for all $\gamma<\beta$,
%     $p$ learns every evader $e$ such that $g_\gamma\succ e$
%     (or $\|p\|_X=\infty$ if
%     $p$ learns every evader $e$ such that $g_\gamma\succ e$ for every
%     $\gamma<\sup_i \alpha^X_i$).
% \end{definition}



\section{Pros and cons of different ASPI measures}
\label{prosandconssection}

Here are pros and cons of the ASPI measures which arise from different solutions
to the problem (Problem \ref{bigoproblem}) of measuring the growth rate of functions.

\begin{itemize}
    \item
    The original Hibbard measure (Definition \ref{classichibbardmeasuredefn}),
    which arises by measuring growth rate by comparing
    a function with Liu's enumeration \cite{liu1960enumeration} of the primitive
    recursive functions:
    \begin{itemize}
        \item
        Pro: Relatively concrete.
        \item
        Pro: Measures intelligence using a familiar number system (the natural numbers).
        \item
        Con: The numbers which the measure outputs are not very meaningful, in
        that predictor $p$ having a measure of
        $+1$ higher than predictor $q$ tells us little
        about how \emph{much} more computationally complex the evaders which $p$
        learns are, versus the evaders which $q$ learns.
        \item
        Con: Only distinguishes sufficiently non-intelligent predictors; all predictors
        sufficiently intelligent receive measure $\infty$.
    \end{itemize}
    \item
    Big-O/Big-$\Theta$ (Definition \ref{bigointelligencedefn}),
    in which, rather than directly measuring the intelligence of a predictor, instead, we
    would talk of a predictor's intelligence being $O(f(n))$ or $\Theta(f(n))$
    for various functions $f:\mathbb N\to\mathbb N$:
    \begin{itemize}
        \item
        Pro: Gets directly at the underlying concept, without obfuscation.
        \item
        Pro: Computer scientists already use Big-O/Big-$\Theta$ routinely
        and are comfortable with them.
        \item
        Con: This option is not really a measure, but more of a taxonomy---and a
        non-numerical taxonomy at that.
    \end{itemize}
    \item
    Hyperreal intelligence (Definition \ref{hyperrealhibbardintelligencedefn}):
    \begin{itemize}
        \item
        Pro: A taxonomy like Big-O/Big-$\Theta$, but with the added benefit
        that the taxons are numerical (hyperreal numerical, to be more precise).
        \item
        Con: Depends on a free ultrafilter (rendering it
        computationally impractical).
    \end{itemize}
    \item
    Surreal intelligence (Definition \ref{surrealhibbardintelligencedefn}):
    \begin{itemize}
        \item
        Pro: An actual numerical measure (not just a taxonomy), with about the same perfect
        granularity as the Big-O/Big-$\Theta$ taxonomies.
        \item
        Con: Abstract and impractical: depends not only on
        a free ultrafilter, but also on an embedding of the hyperreals into the surreals.
        \item
        Con: The numbers which the measure outputs are surreal numbers, which may be
        unfamiliar to some users.
    \end{itemize}
    \item
    Intelligence based on a majorization hierarchy such as the
    standard slow- or fast-growing hierarchy up to $\epsilon_0$
    (Definitions \ref{tradmajorizationhierarchyhibbardmeasuredefn}
    and \ref{tradmajorizationhierarchyhibbardmeasuredefn}):
    \begin{itemize}
        \item
        Pro: A numerical measure, albeit less granular than the
        Big-O/Big-$\Theta$ taxonomies.
        \item
        Pro: Relatively concrete.
        \item
        Pro: The numbers which the measure outputs are meaningful, in the sense that
        the degree to which a predictor $p$ is more intelligent than a
        predictor $q$ is reflected
        in the degree to which $p$'s intelligence-measure is larger than $q$'s.
        \item
        Con: The numbers which the measure outputs are ordinal numbers, which may be
        unfamiliar to some users.
        \item
        Con: Only distinguishes sufficiently non-intelligent predictors; for any particular
        majorization hierarchy, all predictors
        sufficiently intelligent receive measure $\infty$.
    \end{itemize}
\end{itemize}

\section{Conclusion}
\label{conclusionsection}

To summarize:
\begin{itemize}
    \item
    Hibbard proposed \cite{hibbard} an intelligence measure for predictors
    in games of adversarial sequence prediction.
    \item
    We argued that Hibbard's idea actually splits into two orthogonal sub-ideas.
    First: that intelligence can be measured via the growth-rates of the run-times
    of evaders that a predictor can learn to predict. Second: that such growth-rates can
    be measured in one specific way (involving an enumeration of the primitive recursive
    functions). We argued that there many other ways to measure growth-rates,
    and that each method of measuring growth-rates yields a corresponding
    adversarial sequence prediction intelligence (ASPI) measure.
    \item
    We considered several specific ways of measuring growth-rate of functions, and exhibited
    corresponding ASPI measures. The growth-rate-measuring methods
    which we considered were: Big-O/Big-$\Theta$ notation; hyperreal numbers;
    surreal numbers; and majorization hierarchies.
    \item
    We also discussed how measuring the intelligence of adversarial sequence predictors
    provides an indirect measure of the intelligence of idealized AGIs.
\end{itemize}

\section*{Acknowledgments}

We acknowledge Philip Ehrlich for correcting a mistake, and we
acknowledge Roman Yampolskiy for providing literature references.

\bibliographystyle{plain}
\bibliography{hibbard}
\end{document}
