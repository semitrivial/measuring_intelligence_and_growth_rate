\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{mathdots}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{informallemma}[theorem]{Informal Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{openquestion}[theorem]{Open Question}

\title{Measuring intelligence and growth rate: variations on
Hibbard's intelligence measure}
\author{Samuel Alexander\thanks{The U.S.\ Securities and Exchange Commission}}
\date{2020}

\begin{document}

\maketitle

\begin{abstract}
    In 2011, Hibbard suggested an intelligence measure for agents
    who compete in an adversarial sequence prediction game. We argue
    that Hibbard's idea should actually be considered as two separate
    ideas: first, that the intelligence of such agents can be measured
    based on the growth rates of the runtimes of the competitors that
    they defeat; and second, one specific method for measuring said
    growth rates. Hibbard combined these ideas to propose an intelligence
    measure based on one particular method of measuring function growth
    rates. We survey some more standard methods for measuring function
    growth rates, and exhibit the Hibbard-like intelligence measures
    which result.
\end{abstract}

\section{Introduction}

In his insightful paper \cite{hibbard}, Bill Hibbard introduces a novel
intelligence measure (which we will here refer to as the \emph{original Hibbard measure})
for agents who play a game of adversarial sequence prediction
\cite{hibbard2008adversarial}
``against a hierarchy of increasingly difficult sets of'' evaders (environments that attempt
to emit $1$s and $0$s in such a way as to evade prediction).
The levels of Hibbard's hierarchy are labelled by natural numbers, and
an agent's original Hibbard measure is the maximum $n\in\mathbb N$ such that
said agent learns to predict all the evaders in the $n$th level of the hierarchy,
or implicitly\footnote{Hibbard does not explicitly include the $\infty$ case in his
definition, but in his Proposition 3 he refers to agents having ``finite intelligence'', and
it is clear from context that by this he means agents who fail to predict some evader
somewhere in the hierarchy.} an agent's original Hibbard measure is $\infty$
if said agent learns to predict all the evaders in all levels of Hibbard's hierarchy.

The hierarchy which Hibbard uses to measure intelligence is based on the growth
rate of the runtime complexity of evaders as the adversarial sequence prediction
progresses. We will argue that Hibbard's idea is really a combination of two
orthogonal ideas. First: that in some sense the intelligence of a predicting agent
can be measured based on the growth rates of the runtimes of the evaders whom that
predictor learns to predict. Second: Hibbard proposed one particular method for
measuring said growth rates. The growth rate measurement which Hibbard proposed yields
a corresponding intelligence measure for these agents. We will argue that \emph{any}
method for measuring growth rates of functions yields a corresponding Hibbard measure.

The particular method which Hibbard used to measure function growth rates is
not very standard, nor (in our opinion) very useful. We will survey standard
ways of measuring function growth rates, and these will yield corresponding
Hibbard-like intelligence measures.

In this paper, we will argue that the original Hibbard measure is
trivial: we will argue that \emph{all} suitably idealized AGIs should have
original Hibbard intelligence $\infty$. This is because Hibbard's hierarchy
depends on a function-sequence which is (we would argue) arbitrarily chosen,
and which happens to consist of functions which should be trivial to a genuine AGI.

The structure of the paper is as follows.
\begin{itemize}
    \item
    In Section \ref{originalmeasuresection}, we review the original Hibbard measure.
    \item
    In Section \ref{growthratesection}, we argue that any method of measuring
    the growth rate of functions yields a Hibbard-like intelligence measure,
    and that the original Hibbard measure is just a special case resulting from
    one particular method of measuring function growth rate.
    \item
    In Section \ref{exoticsection}, we consider several other solutions to
    the problem of measuring the growth rate of functions, and the
    corresponding Hibbard-like measures of intelligence.
    \item
    In Section \ref{prosandconssection}, we give pros and cons of different
    Hibbard-style measures.
    \item
    In Section \ref{conclusionsection}, we summarize and make concluding remarks.
\end{itemize}

\section{Hibbard's original measure}
\label{originalmeasuresection}

Hibbard proposed an intelligence measure for measuring the intelligence
of agents who compete to predict evaders in a game of
adversarial sequence prediction (we define this
formally below). A predictor $p$ (whose intelligence we want to measure)
competes against evaders $e$. In each step of the game,
both predictor and evader simultaneoulsy choose a binary digit, $1$ or $0$.
Only after both of them have made their choice do they see which choice the other
one made, and then the game proceeds to the next step. The predictor's goal in
each step of the game is to choose the same digit that the evader will choose;
the evader's goal is to choose a different digit than the predictor. The predictor
wins the game (and is said to \emph{learn to predict $e$}, or simply to
\emph{learn $e$}) if, after finitely many
initial steps, eventually the predictor always chooses the same digit as the
evader.

\begin{definition}
By $B$, we mean the binary alphabet $\{0,1\}$. By $B^*$, we mean the set of all
finite binary sequences. By $\langle\rangle$ we mean the empty binary sequence.
\end{definition}

\begin{definition}
\label{evaderpredictordefn}
    (Predictors and evaders)
    \begin{enumerate}
        \item
        By a \emph{predictor}, we mean a Turing machine $p$
        which takes as input a finite (possibly empty) binary sequence
        $(x_1,\ldots,x_n)\in B^*$
        (thought of as a sequence of \emph{evasions})
        and outputs $0$ or $1$ (thought of as a \emph{prediction}), which output
        we write as $p(x_1,\ldots,x_n)$.
        \item
        By an \emph{evader}, we mean a Turing machine $e$
        which takes as input a finite (possibly empty) binary sequence
        $(y_1,\ldots,y_n)\in B^*$
        (thought of as a sequence of \emph{predictions})
        and outputs $0$ or $1$ (thought of as an \emph{evasion}), which output
        we write as $e(y_1,\ldots,y_n)$.
        \item
        For any predictor $p$ and evader $e$, the \emph{result of $p$ playing the
        game of adversarial prediction against $e$} (or more simply, the \emph{result of
        $p$ playing against $e$}) is the infinite binary sequence
        $(x_1,y_1,x_2,y_2,\ldots)$
        defined as follows:
        \begin{enumerate}
            \item
            The first evasion
            $x_1=e(\langle\rangle)$ is
            the output of $e$ when run on the empty prediction-sequence.
            \item
            The first prediction
            $y_1=p(\langle\rangle)$ is
            the result of applying $p$ to the empty evasion-sequence.
            \item
            For all $n>0$, the $(n+1)$th evasion
            $x_{n+1}=e(y_1,\ldots,y_n)$ is
            the output of $e$ on the sequence of the first $n$ predictions.
            \item
            For all $n>0$, the $(n+1)$th prediction
            $y_{n+1}=p(x_1,\ldots,x_n)$ is
            the result of applying $p$ to the first $n$ evasions.
        \end{enumerate}
        \item
        Suppose $r=(x_1,y_1,x_2,y_2,\ldots)$ is the result of a predictor $p$ playing
        against an evader $e$. For every $n\geq 1$,
        we say \emph{the predictor wins round $n$ in $r$}
        if $x_n=y_n$; otherwise,
        \emph{the evader wins round $n$ in $r$}.
        We say that \emph{$p$ learns to predict $e$}
        (or simply that \emph{$p$ learns $e$}) if there is some $N\in\mathbb N$
        such that for all $n>N$, $p$ is the winner of round $n$ in $r$.
    \end{enumerate}
\end{definition}

Note that if $e$ simply ignores its inputs $(y_1,\ldots,y_n)$ and instead
computes $e(y_1,\ldots,y_n)$ based only on $n$, then $e$ is essentially a sequence.
Thus Definition \ref{evaderpredictordefn} is a generalization of sequence prediction,
which many authors have written about (such as \cite{legg2006there}, who gives many
references).

In the following definition, we differ from Hibbard's original paper
because of a minor (and fortunately, easy-to-fix) error there.

\begin{definition}
\label{tsubedefinition}
    Suppose $M$ is any Turing machine which computes a total function from $B^*$ to $B$.
    For any $n\in\mathbb N$, let $T_M(e)$ be the maximum number of steps that $M$ takes
    to run on any length-$n$ sequence of binary digits.
    In other words, $t_M(0)$ is the number of steps $M$ takes to run on $\langle\rangle$,
    and for all $n>0$,
    \[
        t_M(n) = \max_{b_1,\ldots,b_n\in \{0,1\}}
        (\text{number of steps $M$ takes to run on $(b_1,\ldots,b_n)$}).
    \]
\end{definition}

\begin{example}
    Let $e$ be an evader. Then
    $t_e(2)$ is equal to the number of steps $e$ takes to run on input
    $(0,0)$, or to run on input $(0,1)$, or to run on input $(1,0)$, or to run on input
    $(1,1)$---whichever of these four possibilities is largest.
\end{example}

\begin{definition}
\label{functionsuccdefn}
    Suppose $f:\mathbb N\to\mathbb N$ and $g:\mathbb N\to\mathbb N$.
    We say $f\succ g$ if there is some $n_0\in \mathbb N$ such that for all
    $n>n_0$, $f(n)>g(n)$.
\end{definition}

\begin{definition}
\label{evadersetdefinition}
    Suppose $f:\mathbb N\to\mathbb N$. We define
    $E_f$ to be the set of all evaders $e$ such that
    $f\succ t_e$.
\end{definition}

\begin{definition}
\label{classichibbardmeasuredefn}
    (The original Hibbard measure)
    Let $g_1,g_2,\ldots$ be the enumeration of the primitive recursive
    functions given by Liu \cite{liu1960enumeration}.
    For each $m>0$, define $f_m:\mathbb N\to\mathbb N$ by
    \[f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g_i(j).\]
    For any predictor $p$, we define the \emph{original Hibbard intelligence of $p$}
    to be the maximum $m>0$
    such that $p$ learns to predict $e$ for every $e\in E_{f_m}$
    (or $0$ if there is no such $m$, or $\infty$ if $p$ learns to predict $e$
    for every $e\in E_{f_m}$ for every $m>0$).
\end{definition}


\section{Quantifying growth rates of functions}
\label{growthratesection}

The following is a very general and open-ended problem.

\begin{problem}
\label{bigoproblem}
    Quantify the growth-rate of functions from $\mathbb N$ to $\mathbb N$.
\end{problem}

The definition of the original Hibbard measure (Definition \ref{classichibbardmeasuredefn})
can be thought of as implicitly depending on a specific solution to Problem
\ref{bigoproblem}, which we make explicit in the following definition.

\begin{definition}
\label{hibbardgrowthratedefn}
    For each $m>0$, let $f_m$ be as in Definition \ref{classichibbardmeasuredefn}.
    For each $f:\mathbb N\to\mathbb N$, we define the \emph{original Hibbard growth rate}
    $H(f)$ to be $\min\{m>0\,:\,f_m\succ f\}$ if there is any such $m>0$, and otherwise
    $H(f)=\infty$.
\end{definition}

\begin{lemma}
\label{straightfwdtechnicallemma}
    For every natural $m>0$ and every $f:\mathbb N\to\mathbb N$,
    $H(f)\leq m$ if and only if $f_m\succ f$.
\end{lemma}

\begin{proof}
    Straightforward.
\end{proof}

\begin{definition}
\label{variationondefinitionofEdefn}
    For every $m\in\mathbb N$, let $E^H_m$
    be the set of all evaders $e$ such that $H(t_e)\leq m$.
\end{definition}

\begin{lemma}
\label{equivalenceoftwoevadersetslemma}
    For every natural $m>0$, $E^H_m=E_{f_m}$.
\end{lemma}

\begin{proof}
    Let $e$ be an evader. By Definition \ref{variationondefinitionofEdefn},
    $e\in E^H_m$ if and only if $H(t_e)\leq m$.
    By Lemma \ref{straightfwdtechnicallemma}, $H(t_e)\leq m$ if and only if
    $f_m\succ t_e$. But by Definition \ref{evadersetdefinition}, this is the
    case if and only if $e\in E_{f_m}$.
\end{proof}

\begin{corollary}
\label{rephrasinghibbardsmeasurecorollary}
    For every predictor $p$, the original Hibbard measure of $p$
    is equal to the maximum natural $m>0$ such that
    $p$ learns $e$ whenever $e\in E^H_m$, or is equal to $0$ if there are no such
    $m>0$, or is equal to $\infty$ if $p$ learns $e$ whenever $e\in E^H_m$ for
    all $m>0$.
\end{corollary}

\begin{proof}
    Immediate by Lemma \ref{equivalenceoftwoevadersetslemma}
    and Definition \ref{classichibbardmeasuredefn}.
\end{proof}

\begin{remark}
\label{epiphanyremark}
Corollary \ref{rephrasinghibbardsmeasurecorollary} shows that
the definition of the original Hibbard measure can be rephrased in such a way
as to show that it depends in a uniform way on a particular solution to
Problem \ref{bigoproblem}, namely to the solution proposed by
Definition \ref{hibbardgrowthratedefn}. For \emph{any} solution $H'$ to
Problem \ref{bigoproblem}, we could define evader-sets $E^{H'}_m$ in a similar
way to Definition \ref{variationondefinitionofEdefn}, and, by copying
Corollary \ref{rephrasinghibbardsmeasurecorollary}, we could obtain a corresponding
intelligence measure given by $H'$ (it might be necessary to replace the
``maximum'' in Corollary \ref{rephrasinghibbardsmeasurecorollary}
by a ``supremum'', if $H'$ measures growth rates using
a non-discrete number system, or transform the form of it if $H'$
solves Problem \ref{bigoproblem} by categorizing functions into classes
rather than by assigning
them numerical measurements, as in the case of Big-O notation). This
formalizes what we claimed in the Introduction,
that Hibbard's idea can be decomposed into two sub-ideas, firstly, that a predictor's
intelligence can be measured in terms of the growth rates of the runtimes of the
evaders it learns, and secondly, a particular method (Definition \ref{hibbardgrowthratedefn})
of measuring those growth rates (i.e., a particular solution to
Problem \ref{bigoproblem}).
\end{remark}


\section{Big-O, Big-$\Omega$, and Big-$\Theta$ intelligence measurement}

The standard solution to Problem \ref{bigoproblem} in computer science is to quantify
growth rates of arbitrary functions by comparing them to more familiar functions using
Big-O notation, Big-$\Omega$ notation, or Big-$\Theta$ notation.
Knuth defines \cite{knuth1976big} these as follows (we modify the definition slightly because
we are only concerned here with functions from $\mathbb N$ to $\mathbb N$).

\begin{definition}
\label{bigodefn}
    Suppose $f:\mathbb N\to\mathbb N$. We define the following the following function-sets.
    \begin{itemize}
        \item
        $O(f(n))$ is the set of all $g:\mathbb N\to\mathbb N$ such that
        there is some real $C>0$ and some natural number $n_0$ such that
        for all $n\geq n_0$, $g(n)\leq Cf(n)$.
        \item
        $\Omega(f(n))$ is the set of all $g:\mathbb N\to\mathbb N$ such that
        there is some real $C>0$ and some natural $n_0$ such that
        for all $n\geq n_0$, $g(n)\geq Cf(n)$.
        \item
        $\Theta(f(n))$ is the set of all $g:\mathbb N\to\mathbb N$ such that
        there are some real $C>0$ and $C'>0$ and some natural $n_0$ such that
        for all $n\geq n_0$, $Cf(n)\leq g(n)\leq C'f(n)$.
    \end{itemize}
\end{definition}

We would argue that Definition \ref{bigodefn} is a strictly better solution to
Problem \ref{bigoproblem} than Definition \ref{hibbardgrowthratedefn}.
Definition \ref{hibbardgrowthratedefn} would clearly not be much use in
practice. It is much more useful to say that an algorithm has, say, asymptotic
runtime $O(n^3)$ than to say that said algorithm's runtime has original Hibbard
complexity (say) $835$. If someone were told that an algorithm's runtime had
original Hibbard complexity (say) $835$, that number would be totally meaningless
to them except as a key which they could use to look up which function $f_{835}$
happens to be (in Definition \ref{originalhibbardcomplexitydefn}). The number
$835$ would merely serve to obfuscate, it would merely play the role of a worthless
middleman.

By Remark \ref{epiphanyremark}, Definition \ref{bigodefn} yields the following elegant
measure of predictor intelligence.

\begin{definition}
\label{bigointelligencedefn}
    Suppose $p$ is a predictor, and suppose $f:\mathbb N\to\mathbb N$.
    \begin{itemize}
        \item
        We say \emph{$p$ has Hibbard intelligence $O(f(n))$} if
        $p$ learns every evader $e$ such that $t_e$ is $O(f(n))$.
        \item
        We say \emph{$p$ has Hibbard intelligence $\Omega(f(n))$} if
        $p$ learns every evader $e$ such that $t_e$ is $\Omega(f(n))$.
        \item
        We say \emph{$p$ has Hibbard intelligence $\Theta(f(n))$} if
        $p$ learns every evader $e$ such that $t_e$ is $\Theta(f(n))$.
    \end{itemize}
\end{definition}

At first glance, Definition \ref{bigointelligencedefn} might seem inferior to
Definition \ref{classichibbardmeasuredefn} because
Definition \ref{classichibbardmeasuredefn} assigns \emph{numerical} intelligence levels.
However, as we pointed out above, those numbers are almost meaningless except as indices for
a dictionary-lookup making them equivalent to (a more limited version of)
Definition \ref{bigointelligencedefn}. We could imagine someone declaring:
\begin{quote}
    From now on, $f(n)=n$ is complexity $5$, $f(n)=n^2$ is complexity $8$,
    $f(n)=2^n$ is complexity $203$,
    $f(n)=n!$ is complexity $8022$, ..., and from now on, instead of saying a
    function is $\Theta(n)$, we will say that function has growth rate $5$,
    and instead of saying a function is $\Theta(n^2)$, we will say that function
    has growth rate $8$, and instead of saying a function is $\Theta(2^n)$, we will
    say that function has growth rate $203$, and instead of saying a function is
    $\Theta(n!)$, we shall say that function has growth rate $8022$, and ...
\end{quote}
Superficially, this would ``improve'' upon Big-$\Theta$ by giving a ``more quantitative''
solution to Problem \ref{bigoproblem}, however, it is clear
that this would just be sleight of hand and there would be no actual improvement.

\section{Hibbard measures using extended number systems}
\label{exoticsection}

We have argued above that it is silly to try to replace asymptotic complexity classes
with natural numbers. In \cite{alexander2020archimedean}, we go further, and cite
asymptotic runtime complexity as an example of a \emph{non-Archimedean} measure which,
we argue, implies that it is silly to replace asymptotic complexity classes
even with \emph{real} numbers. There are, however, non-Archimedean number systems
flexible enough to measure some or all growth rates, and these alternative solutions to
Problem \ref{bigoproblem} would in turn yield Hibbard-style intelligence measures taking
values from said non-Archimedean number systems.
\begin{itemize}
    \item
    Hyperreal numbers, studied in the field of non-standard analysis \cite{robinson}
    \cite{goldblatt2012lectures},
    are equivalence classes of infinite sequences of reals,
    so for every sequence $(r_0,r_1,r_2,\ldots)$ of reals, there is a corresponding
    hyperreal represented by that sequence.
    Thus, there is a natural and elegant way to solve Problem \ref{bigoproblem}
    using hyperreal numbers. Namely: the growth rate of $f(n)$ is the hyperreal number
    represented by $(f(0),f(1),f(2),\ldots)$. This solution to Problem \ref{bigoproblem}
    will yield an approximate Hibbard-style intelligence measure similar to
    Definition \ref{bigointelligencedefn} (the reason this only yields an approximate
    Hibbard-style intelligence measure is because the hyperreals are not complete).
    \item
    The surreal numbers \cite{conway} \cite{knuth} are an even larger extension
    of the real numbers, into which the hyperreals can be embedded
    \cite{ehrlich2012absolute}.
    Thus, for any such embedding,
    there is another natural and elegant way to solve Problem \ref{bigoproblem},
    namely: the growth rate of $f(n)$ is the surreal number corresponding to the
    hyperreal number represented by $(f(0),f(1),f(2),\ldots)$ under the embedding.
    The advantage of the surreal numbers is that they are complete, which will allow
    the corresponding Hibbard-style measure to be exact, not approximate.
    \item
    Another natural way to measure growth rate is using majorization hierarchies
    (such as the slow-growing hierarchy or the fast-growing hierarchy
    \cite{weiermann2002slow}) from mathematical
    logic. A majorization hierarchy assigns ordinal number values to growth rates of
    functions (but not to all functions---for any particular majorization hierarchy, there
    are functions which grow too fast for that hierarchy). These yield corresponding
    Hibbard-style intelligence measures which are ordinal-number-valued.
    \item
    In order to reduce the arbitrary limitations of traditional majorization
    hierarchies, we could delegate the problem of defining a majorization hierarchy to
    an Artificial General Intelligence (or AGI). This leads to a family of Hibbard-style
    measures---one measure
    $|\bullet|_X$ for each AGI $X$, so that for any particular AGI $X$, for any
    predictor $p$, there is a corresponding intelligence measure $|p|_X$ which might be
    thought of as ``$p$'s intelligence as judged by $X$''.
\end{itemize}

\subsection{Hyperreal Hibbard intelligence}

The so-called \emph{ultrapower construction} of the hyperreals depends on an object
called a \emph{free ultrafilter}, which is a set of subsets of $\mathbb N$ satisfying
certain requirements. It is not important for the purposes of this paper to define what
a free ultrafilter is here. The important things to know are:
\begin{itemize}
    \item
    A free ultrafilter $\mathscr U$ provides a notion of what it means for a subset
    $S\subseteq\mathbb N$ to be ``large''. Namely: $S$ is considered to be ``large''
    if and only if $S\in \mathscr U$.
    \item
    Mathematical logicians have proven that free ultrafilters exist, but that it is
    impossible to constructively exhibit one. This makes definitions based on free
    ultrafilters non-constructive, and computationally impractical.
\end{itemize}

Because of the computational impracticality of free ultrafilters, the following notion
is also computationally impractical. However, it could potentially be useful for
proving theoretical properties about the intelligence of predictors. In the following
definition, rather than assigning a particular hyperreal number intelligence to every
predictor, rather, we categorize predictors into classes. This is necessary because
the hyperreals are not complete, so Corollary \ref{rephrasinghibbardsmeasurecorollary}
cannot directly be mimicked either with ``maximum'' or with ``supremum''.

\begin{definition}
    (Hyperreal Hibbard intelligence)
    The \emph{hyperreal Hibbard intelligence} of a predictor $p$ is defined to be
    $\geq$ a hyperreal number $r$ if and only if $p$ learns every evader $e$
    such that if $r'$ is the hyperreal number represented by
    $(t_e(0), t_e(1), t_e(2), \ldots)$ then $r'<r$.
\end{definition}

\subsection{Surreal Hibbard intelligence}

The surreal number system is even
more flexible than the hyperreal number system.
There are many ways to embed the hyperreals into the surreals, and there is no
standard or canonical way which stands out. In this subsection, we fix some embedding
of the hyperreals into the surreals.

A key property of the surreals
is that they are complete. Thus, given any set $S$ of surreals with a surreal upper bound,
there is a \emph{least} surreal upper bound of $S$, called the \emph{supremum} of $S$
(written $\sup S$). This allows for a Hibbard-style intelligence measure which is more
exact than Definition \ref{hyperrealhibbardintelligencedefn}.

\begin{definition}
\label{surrealhibbardintelligencedefn}
    (Surreal Hibbard intelligence)
    For every predictor $p$, the \emph{surreal Hibbard intelligence} of $p$
    is equal to the supremum of all surreal numbers $r$ such that
    $p$ learns $e$ whenever the surreal number corresponding to
    $(t_e(0),t_e(1),t_e(2),\ldots)$ is $<r$.
\end{definition}

\subsection{Hibbard intelligence and the traditional majorization hierarchies}

Majorization hierarchies \cite{weiermann2002slow}
provide ordinal-number-valued measures for the growth
rate of certain functions. A majorization hierarchy depends
on many infinite-dimensional parameters. For illustrative purposes,
we will describe the slow-growing hierarchy up to the ordinal $\epsilon_0$,
using standard choices for the parameters.

\begin{definition}
    (Classification of ordinal numbers)
    Ordinal numbers are divided into three types:
    \begin{enumerate}
        \item Zero: The ordinal $0$.
        \item Successor ordinals: Ordinals of the form $\alpha+1$ for some ordinal $\alpha$.
        \item Limit ordinals: Ordinals which are not successor ordinals nor $0$.
    \end{enumerate}
\end{definition}

For example, the smallest infinite ordinal, $\omega$, is a limit ordinal. It is not zero
(because zero is finite),
nor can it be a successor ordinal, because if it were a successor ordinal, say, $\alpha+1$,
then $\alpha$ would be finite (since $\omega$ is the \emph{smallest} infinite ordinal),
but then $\alpha+1$ would be finite as well.

The ordinal $\epsilon_0$ is the smallest ordinal bigger than the ordinals
$\omega,\omega^\omega,\omega^{\omega^\omega},\ldots$. It satisfies the equation
$\epsilon_0=\omega^{\epsilon_0}$ and can be intuitively thought of as
\[
    \epsilon_0 = \omega^{\omega^{\omega^{iddots}}}.
\]
Ordinals below $\epsilon_0$ include such ordinals as $\omega$,
$\omega^{\omega+1}+\omega^{\omega}+\omega^5+3$,
\[
\omega^{\omega^{\omega^{\omega^\omega}}}+
\omega^{\omega^{\omega^\omega}+\omega^{\omega\cdot 2+1}+\omega^4 + 3}
+ \omega^{\omega^5+\omega^3}+\omega^8+1,
\]
and so on.
Any ordinal below $\epsilon_0$ can be uniquely written in the form
\[
    \omega^{\alpha_1}+\omega^{\alpha_2}+\cdots + \omega^{\alpha_k}
\]
where $\alpha_1\geq\cdots\geq\alpha_k$ are smaller ordinals below $\epsilon_0$---this form
for an ordinal below $\epsilon_0$ is called its \emph{Cantor normal form}.
For example, the Cantor normal form for $\omega^{\omega\cdot 2}\cdot 2+\omega\cdot 3+2$
is
\[
\omega^{\omega\cdot 2}\cdot 2+\omega\cdot 3+2
=
\omega^{\omega\cdot 2} + \omega^{\omega\cdot 2} + \omega^1 + \omega^1 + \omega^1
+\omega^0 + \omega^0.
\]

\begin{definition}
    (Standard fundamental sequences for limit ordinals $\leq\epsilon_0$)
    Suppose $\lambda$ is a limit ordinal $\leq\epsilon_0$. We define a
    \emph{fundamental sequence for $\lambda$},
    written $(\lambda[0],\lambda[1],\lambda[2],\ldots)$, inductively as follows.
    \begin{itemize}
        \item
        If $\lambda=\epsilon_0$, then $\lambda[0]=0$,
        $\lambda[1]=\omega^0$, $\lambda[2]=\omega^{\omega^0}$, and so on.
        \item
        If $\lambda$ has Cantor normal form
        $\omega^{\alpha_1}+\cdots+\omega^{\alpha_k}$ where $k>1$,
        then
        each
        \[
            \lambda[i] = (\omega^{\alpha_1}+\cdots+\omega^{\alpha_{k-1}})
            + (\omega^{\alpha_k})[i].
        \]
        \item
        If $\lambda$ has Cantor normal form $\omega^0$, then each $\lambda[i]=i$.
        \item
        If $\lambda$ has Cantor normal form $\omega^{\alpha+1}$,
        then each $\lambda[i]=\omega^{\alpha}\cdot i$.
        \item
        If $\lambda$ has Cantor normal form $\omega^{\lambda_0}$ where $\lambda_0$
        is a limit ordinal, then each $\lambda[i]=\omega^{\lambda_0[i]}$.
    \end{itemize}
\end{definition}

\begin{example}
    (Fundamental sequence examples)
    \begin{itemize}
        \item
        The fundamental sequence for $\lambda=\omega^5$ is
        $0,\omega^4,\omega^4\cdot 2,\omega^4\cdot 3,\ldots$.
        \item
        The fundamental sequence for $\lambda=\omega^\omega$ is
        $\omega^0,\omega^1,\omega^2,\ldots$.
        \item
        The fundamental sequence for $\lambda=\omega^\omega+\omega$ is
        $\omega^\omega+0,\omega^\omega+1,\omega^\omega+2,\ldots$.
    \end{itemize}
\end{example}

\begin{definition}
\label{slowgrowinghierarchydefn}
    (The standard slow-growing hierarchy up to $\epsilon_0$)
    We define functions $g_\beta:\mathbb N\to\mathbb N$ (for all ordinals
    $\beta\leq \epsilon_0$) by transfinite induction as follows.
    \begin{itemize}
        \item
        $g_0(n)=0$.
        \item
        $g_{\alpha+1}(n) = g_\alpha(n) + 1$.
        \item
        $g_{\lambda}(n) = g_{\lambda[n]}(n)$ if $\lambda$ is a limit ordinal.
    \end{itemize}
\end{definition}

Here are some early levels in the slow-growing hierarchy, spelled out in detail.

\begin{example}
\label{highdetailslowgrowingexample}
    (Early examples of functions in the slow-growing hierarchy)
    \begin{enumerate}
        \item
        $g_1(n)=g_{0+1}(n)=g_0(n)+1=0+1=1$.
        \item
        $g_2(n)=g_{1+1}(n)=g_1(n)+1=1+1=2$.
        \item
        More generally, for all $m\in\mathbb N$,
        $g_m(n)=m$.
        \item
        $g_\omega(n)=g_{\omega[n]}(n)=g_n(n)=n$.
        \item
        $g_{\omega+1}(n)=g_{\omega}(n)+1=n+1$.
        \item
        $g_{\omega+2}(n)=g_{\omega+1}(n)+1=(n+1)+1=n+2$.
        \item
        More generally, for all $m\in\mathbb N$,
        $g_{\omega+m}(n)=n+m$.
        \item
        $g_{\omega\cdot 2}(n)=g_{(\omega\cdot 2)[n]}(n)
        =g_{\omega+n}(n)=n+n=n\cdot 2$.
    \end{enumerate}
\end{example}

Following Example \ref{highdetailslowgrowingexample}, the reader should be able
to fill in the details in the following example.

\begin{example}
    (More examples from the slow-growing hierarchy)
    \begin{enumerate}
        \item
        $g_{\omega^2}(n)=n^2$.
        \item
        $g_{\omega^3}(n)=n^3$.
        \item
        $g_{\omega^\omega}(n)=n^n$.
        \item
        $g_{\omega^{\omega\cdot 3+1}+\omega+5}(n)=n^{3n+1}+n+5$.
        \item
        $g_{\omega^{\omega^{\omega}}}=n^{n^n}$.
    \end{enumerate}
\end{example}

What about $g_{\epsilon_0}$? Thinking of $\epsilon_0$ as
\[\omega^{\omega^{\omega^{\iddots}}},\]
one might expect $g_{\epsilon_0}(n)$ to be
\[n^{n^{n^{\iddots}}},\]
but such an infinite tower
of exponents makes no sense if $n>1$. Instead, the answer defies familiar mathematical
notation.

\begin{example}
\label{epsilon0example}
(Level $\epsilon_0$ in the slow-growing hierarchy)
The values of $g_{\epsilon_0}$ are as follows:
\begin{itemize}
    \item
    $g_{\epsilon_0}(0)=0$.
    \item
    $g_{\epsilon_0}(1)=1^1$.
    \item
    $g_{\epsilon_0}(2)=2^{2^2}$.
    \item
    $g_{\epsilon_0}(3)=3^{3^{3^3}}$.
    \item
    And so on.
\end{itemize}
\end{example}

Example \ref{epsilon0example} illustrates how the slow-growing hierarchy can systematically
lead to fast-growing computable functions. By extending the slow-growing hierarchy to
larger ordinals (and choosing appropriate fundamental sequences for those larger ordinals),
one can obtain stupendously fast-growing functions in this way. These in turn serve as
a partial solution to Problem \ref{bigoproblem}: we can say that the growth rate of
an arbitrary function $f:\mathbb N\to\mathbb N$
is equal to $\alpha$, where $\alpha$ is the smallest ordinal such
that $g_\alpha\succ f$ (or $\infty$ if no such $\alpha$ exists).
This in turn provides a corresponding Hibbard-style measure.

\begin{corollary}
\label{rephrasinghibbardsmeasurecorollary}
    For every predictor $p$, the original Hibbard measure of $p$
    is equal to the maximum natural $m>0$ such that
    $p$ learns $e$ whenever $e\in E^H_m$, or is equal to $0$ if there are no such
    $m>0$, or is equal to $\infty$ if $p$ learns $e$ whenever $e\in E^H_m$ for
    all $m>0$.
\end{corollary}

\begin{definition}
\label{tradmajorizationhierarchyhibbardmeasuredefn}
    If $p$ is a predictor, the \emph{Hibbard intelligence of $X$ given by the
    standard slow-growing hierarchy up to $\epsilon_0$} is defined to be the
    supremum of all ordinals $\alpha<\epsilon_0$ such that
    $p$ learns every evader $e$ such that $g_\alpha\succ t_e$ (or to
    $\infty$ if said property holds for all ordinals $\alpha\leq\epsilon_0$).
\end{definition}

\subsection{Generalized majorization hierarchies}

There are many other majorization hierarchies besides the slow-growing hierarchy.
In Definition \ref{slowgrowinghierarchydefn},
there is nothing special about defining $g_{\alpha+1}(n)=g_{\alpha}(n)+1$.
Many other definitions for $g_{\alpha+1}$ would work, provided $g_{\alpha+1}$ ends
up being faster-growing than $g_\alpha$.
For example, in the so-called \emph{fast-growing hierarchy},
$g_{\alpha+1}(n)$ is defined to be $g^n_\alpha(n)$, where the $g^n_\alpha$
denotes the result of iterating $g_\alpha$ $n$ times, that is,
$g^1_\alpha(n)=g_\alpha(n)$, $g^2_\alpha(n)=g_\alpha(g_\alpha(n))$,
$g^3_\alpha(n)=g_\alpha(g_\alpha(g_\alpha(n)))$, and so on.
In the early levels, this produces much faster-growing functions,
but astonishingly, at sufficiently high ordinals, the slow-growing hierarchy
actually catches up with the fast-growing hierarchy \cite{girard1981pi12}
(a beautiful illustration of how counter-intuitive large ordinal numbers can be).
One of the earliest majorization hierarchies is the Hardy
hierarchy \cite{hardy1904theorem}, where $g_{\alpha+1}(n)=g_\alpha(n+1)$.

Likewise, there is also much flexibility in choosing fundamental sequences.
For small ordinals such as the ordinals below $\epsilon_0$, there are very clear
canonical fundamental sequences, but the larger the ordinals become, the harder
it becomes to single out any choice of fundamental sequences as canonical.
And even at low levels, choosing non-canonical fundamental sequences can
drastically alter the resulting majorization hierarchy \cite{weiermann1997sometimes}.

In short, there is no consensus at all about which majorization hierarchies are
most canonical. If anything, there is consensus that there is no consensus.
However, Hibbard-style intelligence measures are primarily of interest to researchers
interested in agents with Artificial General Intelligence (that is, researchers
interested in AGIs). No-one knows what exactly an AGI is, but presumably an AGI can
be thought of as a patient, obedient, careful, mechanical employee who can
be given commands in English, and who will follow those commands (at least when
the commands are \emph{possible} to follow---one could command an AGI to act as a
Halting Problem solver, but it is unclear how the AGI would respond to such a command,
since no mechanical agent can solve the Halting Problem).

Rather than attempt the futile task of choosing a canonical majorization hierarchy
ourselves, we can instead delegate that task to an AGI. By doing so for an arbitrary
AGI, we will obtain an AGI-indexed family of semi-canonical majorization hierarchies.

\begin{definition}
\label{fairsequencedefn}
    Suppose $X$ is an AGI. By $h^X_1,h^X_2,\ldots$, we mean the total computable
    increasing functions
    from $\mathbb N$ to $\mathbb N$ which $X$ would output if $X$ were commanded:
    \begin{quote}
        ``Until further notice, output (codes of) total computable increasing
        functions $h_1,h_2,\ldots$ from $\mathbb N$ to $\mathbb N$ satisfying the
        following constraints:
        \begin{enumerate}
            \item (Linear ordering) For any two $i,j\in\mathbb N$ with $i\neq j$, either
            $h_i\succ h_j$ or $h_j\succ h_i$.
            \item (Largeness) For every Turing machine $M$ such that you know
            $M$ computes a total computable function $h:\mathbb N\to\mathbb N$,
            there is some $i$ such that $h_i\succ h$.
            \item (Well-foundedness) There is no sequence $i_1,i_2,\ldots$ such that
            $h_{i_1}\succ h_{i_2}\succ\cdots$.
            \item (Pseudo-density)
            The $h_i$'s are to be as close as possible to being \emph{dense}---that is
            to say, they are to be as close as possible to having the property that
            for all $i,k\in\mathbb N$ with $h_k\succ h_i$, there is some $j\in\mathbb N$
            such that $h_k\succ h_j\succ h_i$---without violating the above
            well-foundedness constraint; you are to use your judgment and discretion
            to interpret this pseudo-density requirement.''
        \end{enumerate}
    \end{quote}
\end{definition}

The above pseudo-density constraint is intentionally vague, which we can get away
with because the definition does not depend on what pseudo-density actually means,
but only on how the AGI interprets the \emph{words} (i.e., how the AGI responds to a
specific well-defined stimulus, regardless of how vague the semantics of that stimulus
may be).
Thus, we are taking advantage of the AGI's ability to ``adapt with insufficient
knowledge and resources'' \cite{wang2019defining}.
We assume the AGI understands and obeys the commands, so $h^X_1,h^X_2,\ldots$ really are
total computable increasing functions from $\mathbb N$ to $\mathbb N$ satisfying the
linear ordering, largeness\footnote{Note that the largeness requirement is defined in
terms of the AGI's knowledge. See \cite{alexanderinprep} for a definition of what
it means for an AGI to know a mathematical fact.}, and well-foundedness requirements.
Note that the resulting $h_i$'s
cannot actually be dense, as that would violate well-foundedness: given any $i,j$
with $h_j\succ h_i$, there would be some $k_1$ such that $h_j\succ h_{k_1}\succ h_i$,
and then there would be some $k_2$ such that $h_{k_1}\succ h_{k_2}\succ h_i$,
and then there would be some $k_3$ such that $h_{k_2}\succ h_{k_3}\succ h_i$, and so
on, but then $h_{k_1}\succ h_{k_2}\succ \cdots$ would violate well-foundedness.
We will offer some motivation for pseudo-density below in
Remark \ref{pseudodensityremark} below.

\begin{definition}
\label{alphaidefn}
    Let $X$ be an AGI. We define a sequence $\alpha^X_1,\alpha^X_2,\ldots$
    of ordinals by recursion as follows. Note that at first glance,
    the following recursive definition looks too circular to work.
    We will show in Lemma \ref{transfiniterecursionmagiclemma} that
    it avoids infinite regress and thus
    it does work. For each $i$, let $\alpha^X_i$ be the the smallest
    ordinal which is larger than every ordinal $\alpha^X_j$ such that
    $h^X_i\succ h^X_j$.
\end{definition}

\begin{lemma}
\label{transfiniterecursionmagiclemma}
    Definition \ref{alphaidefn} works (it does not lead to infinite regress).
\end{lemma}

\begin{proof}
    Assume, for the sake of contradiction, that Definition \ref{alphaidefn}
    leads to infinite regress. This means there is some $i_1$ such that
    in order to define $\alpha^X_{i_1}$ we must first define $\alpha^X_{i_2}$
    for some $i_2$, and in order to define $\alpha^X_{i_2}$ we must first
    define $\alpha^X_{i_3}$ for some $i_3$, and in order to define
    $\alpha^X_{i_3}$ we must first define $\alpha^X_{i_4}$ for some $i_4$,
    and so on forever. Thus, there is an infinite sequence $i_1,i_2,\ldots$
    such that in order to define each $\alpha^X_{i_j}$, we must first
    define $\alpha^X_{i_{j+1}}$. Now, each $\alpha^X_{i_j}$ is defined as
    the smallest ordinal larger than every ordinal $\alpha^X_j$ such that
    $h^X_{i_j}\succ h^X_j$. So, since defining $\alpha^X_{i_j}$ requires
    us to first define $\alpha^X_{i_{j+1}}$, this implies $i_{j+1}$ is
    such a $j$, i.e., that $h^X_{i_j}\succ h^X_{i_{j+1}}$.
    Thus $h^X_{i_1}\succ h^X_{i_2}\succ h^X_{i_3}\succ\cdots$,
    but this contradicts the \emph{well-foundedness} part of the command
    from Definition \ref{fairsequencedefn}.
\end{proof}

\begin{lemma}
\label{technicallemmaaboutalphaXi}
    Let $X$ be an AGI. For all $i,j$,
    $h^X_i\succ h^X_j$ if and only if $\alpha^X_i>\alpha^X_j$.
\end{lemma}

\begin{proof}
    Fix $i$ and $j$.
    By the \emph{linear ordering} part of the command in Definition
    \ref{fairsequencedefn}, either $h^X_i\succ h^X_j$ or $h^X_j\succ h^X_i$.
    Assume $h^X_i\succ h^X_j$, the other case is similar.
    By definition, $\alpha^X_i$ is defined to be the smallest ordinal
    which is larger than $\alpha^X_{j'}$ for every $j'$ such that
    $h^X_i\succ h^X_{j'}$. One such $j'$ is $j$ itself,
    so by definition $\alpha^X_i$ is larger than $\alpha^X_j$, as desired.
\end{proof}

\begin{definition}
\label{generalizedmajorizationhierarchydefn}
(Generalized majorization hierarchies)
    Let $X$ be an AGI. Let $\alpha=\sup_i \alpha^X_i$ be the smallest ordinal
    bigger than all of the $\alpha^X_i$'s. The \emph{generalized majorization
    hierarchy given by $X$} is the family $(g_\beta)_{\beta<\alpha}$ of functions
    labeled by ordinals below $\alpha$, where each $g_{\beta}$ is defined
    such that $g_{\beta}=h^X_i$ where $i$ is such that $\beta=\alpha^X_i$.
\end{definition}

\begin{remark}
\label{pseudodensityremark}
With Definition \ref{generalizedmajorizationhierarchydefn} in view,
the pseudo-density
constraint in Definition \ref{fairsequencedefn} can be better motivated:
the point of pseudo-density is to ensure that the ordinal
$\sup_i \alpha^X_i$ is as large as possible. An alternative to pseudo-density would
be to directly command (in Definition \ref{fairsequencedefn}) that the $h_i$'s should
be chosen in such a way as to make $\alpha=\sup_i\alpha^X_i$ large (leaving it up
to the AGI's judgment and discretion how to interpret that), but this would be
difficult because it would mean that Definition \ref{generalizedmajorizationhierarchydefn}
(and its dependencies) would need to be embedded into the command in
Definition \ref{fairsequencedefn}, which would require some significant acrobatics.
\end{remark}

A generalized majorization hierarchy (Definition \ref{generalizedmajorizationhierarchydefn})
serves as a solution to Problem \ref{bigoproblem}: given any AGI $X$, we can say
that a function $f:\mathbb N\to\mathbb N$ has growth rate
$\beta$ where $\beta$ is the smallest ordinal $<\sup_i \alpha^X_i$
such that $g_\beta\succ f$---or $f$ has growth rate $\infty$ if there is no
such $\beta$. To this solution to Problem \ref{bigoproblem}, there is a corresponding
Hibbard-style intelligence measure.

\begin{definition}
    (Transfinite Hibbard measures)
    Suppose $X$ is an AGI. By the \emph{transfinite Hibbard measure given by $X$},
    we mean the measure $\|\bullet\|_X$ which assigns to every predictor $p$ an
    intelligence measure $\|p\|_X$ defined as follows.
    $\|p\|_X$ is defined to be the smallest $\beta<\sup_i\alpha^X_i$
    such that for all $\gamma<\beta$,
    $p$ learns every evader $e$ such that $g_\gamma\succ e$
    (or $\|p\|_X=\infty$ if
    $p$ learns every evader $e$ such that $g_\gamma\succ e$ for any
    $\gamma<\sup_i \alpha^X_i$).
\end{definition}


\section{Do all AGIs have original Hibbard intelligence $\infty$?}
\label{trivialitysection}

In this section, we will argue that under certain idealizing
assumptions, every AGI should have original Hibbard intelligence $\infty$.
Thus, we would suggest that Definition \ref{classichibbardmeasuredefn} is really
only appropriate for certain weak AIs who are strong enough that they can be
induced to participate in adversarial sequence prediction games, but who are
too weak to qualify as genuine AGIs.


\subsection{A semi-optimal predictor}
\label{semioptimalpredictorsubsection}

The most obvious way to try to predict an evader would be to
enumerate some list $M_1,M_2,\ldots$ of Turing machines and
sequentially try to predict $e$ by assuming $e$ computes the same
function as $M_1$, and if that ever fails, then predict $e$ by
assuming $e$ computes the same function as $M_2$, and if that ever
fails, then predict $e$ by assuming $e$ computes the same function
as $M_3$, and so on. In doing so, we should limit ourselves
to Turing machines $M_i$ which define total functions, lest
we end up waiting forever for a non-terminating computation
and never getting around to making our next
prediction. Unfortunately, the set of total Turing machines is
not computably enumerable, so the best we can hope for is to enumerate
some subset of the total Turing machines. But which subset? This is
a tricky and arbitrary decision---thankfully, we do not need to
decide it ourselves, we can let the AGI decide for us.

\begin{definition}
\label{bruteforcepredictordefn}
    (Brute-Force Predictors)
    Suppose $X$ is an AGI. Let $M_1,M_2,\ldots$ be the list of Turing machines
    which $X$ would enumerate if $X$ were commanded: ``Enumerate all the Turing
    machines which you know define total functions from $B^*$ to $B$''.
    By \emph{$X$'s brute-force predictor}, we mean the predictor $p$ defined
    as follows.
    \begin{enumerate}
        \item
        Initially, $p$ shall attempt to predict the evader $e$ by assuming that $e$
        defines the same function as $M_1$. When (if ever) this fails,
        say that \emph{$M_1$ is ruled out from being the evader}.
        \item
        Once $M_1$ has been ruled out from being the evader (if ever),
        $p$ shall attempt to predict $e$ by assuming that $e$ defines the same
        function as $M_2$. When (if ever) this fails,
        say that \emph{$M_2$ is ruled out from being the evader}.
        \item
        Once $M_2$ has been ruled out from being the evader (if ever),
        $p$ shall attempt to predict $e$ by assuming that $e$ defines the same
        function as $M_3$. When (if ever) this fails,
        say that \emph{$M_3$ is ruled out from being the evader}.
        \item
        And so on forever...
    \end{enumerate}
\end{definition}

Note that $X$'s brute-force predictor
is total precisely because of the mathematical truthfulness assumption
(from Definition \ref{idealizingassumption}): whenever $X$ knows that
$M_i$ defines a total function from $B^*$ to $B$, $M_i$ really \emph{does}
define a total function from $B^*$ to $B$ (hereafter, we will suppress
remarks like this and routinely use the mathematical truthfulness assumption
without explicit mention).

\begin{lemma}
\label{knowingimplieslearninglemma}
    Let $X$ be an AGI and let $e$ be an evader (so $e$ is a Turing machine which
    computes a function from $B^*$ to $B$).
    Let $M$ be any Turing machine which computes the same function from $B^*$ to $B$
    as $e$ computes.
    If $X$ knows that $M$ defines a total function from $B^*$ to $B$,
    then $X$'s brute-force predictor learns to predict $e$.
\end{lemma}

\begin{proof}
    Let $p$ be $X$'s brute-force predictor.
    Let $M_1,M_2,\ldots$ be as in Definition \ref{bruteforcepredictordefn}.
    Since $X$ knows that $M$ defines a total
    function from $B^*$ to $B$,
    it follows that $M=M_k$ for some $k$.
    When $p$ plays against $e$, it cannot occur that $M_k$ is ruled out
    from being the evader, because in order for that to occur, $p$ would have
    to fail at predicting $e$ when $p$ assumes that $e$ computes the same
    function as $M_k$, but that cannot fail because that assumption is true.
    Since $M_k$ cannot be ruled out from being the evader, it follows that
    step $k+1$ of Definition \ref{bruteforcepredictordefn} will never be
    reached, which in turn implies that $p$ stops failing at predicting $e$
    after finitely many initial failures, in other words, $p$ learns to
    predict $e$.
\end{proof}

For any AGI $X$, we would like to claim that $X$'s brute-force predictor is
optimal among all predictors $X$ could act as; unfortunately this
is not true in the strongest sense it possibly could be true, as the following
example shows.

\begin{example}
\label{bruteforcenottotallyoptimalexample}
    Let $X$ be an AGI. Let $f:\mathbb N\to B$ be a total computable function
    which is not computed\footnote{Such an $f$ must exist because
    otherwise, $X$ could enumerate all the total
    computable functions from $\mathbb N$ to $B$, which is absurd because those functions
    are not computably enumerable.} by any Turing machine $M$ such that $X$ knows $X$ computes
    a total function from $\mathbb N$ to $B$.
    For each $i\in\{0,1\}$, let $e_i$ be an evader such that:
    \begin{align*}
        e_i(\langle\rangle) &= i,\\
        e_i(y_1,\ldots,y_n) &=
        \begin{cases}
            i &\mbox{if $y_1=\cdots=y_n=i$,}\\
            f(n) &\mbox{otherwise.}
        \end{cases}
    \end{align*}
    For each $i\in\{0,1\}$, let $p_i$ be a
    constantly-$i$ predictor, $p_i(x_1,\ldots,x_n)=i$.
    Then $p_0$ learns to predict $e_0$ and $p_1$ learns to predict $e_1$,
    but $X$'s brute-force predictor learns to predict at most one of $e_0$ or $e_1$.
\end{example}

\begin{proof}
    Clearly the result of $p_0$ playing against $e_0$ is
    $(x_0,y_0,x_1,y_1,\ldots)=(0,0,0,0,\ldots)$, so $p_0$ learns to predict $e_0$.
    Likewise, the result of $p_1$ playing against $e_1$ is
    $(x_0,y_0,x_1,y_1,\ldots)=(1,1,1,1,\ldots)$, so $p_1$ learns to predict $e_1$.
    It remains to show that $X$'s brute-force predictor $p$ cannot learn to predict
    both $e_0$ and $e_1$.

    Let $M_1,M_2,\ldots$ be as in Definition \ref{bruteforcepredictordefn}.
    Let $g:B^*\to B$ be the function computed by $M_1$.

    Case 1: $g(\langle\rangle)=1$. Then when $p$ plays against $e_0$,
    after the first step, it will never be the case that
    $y_1=\cdots=y_n=0$ (because $y_1=g(\langle\rangle)=1$).
    Thus, for all $n>0$, $e_0(y_1,\ldots,y_n)=f(n)$.
    I claim that $p$ does not learn $e_0$.
    To see this, assume (for the sake of contradiction)
    that $p$ learns $e_0$. It follows that there is some $k$ (which we may take
    as small as possible) such that $M_k$ never gets ruled out from being the
    evader (Definition \ref{bruteforcepredictordefn}). Let $h:B^*\to B$ be the
    function defined by $M_k$.
    Let $(x_0,y_0,x_1,y_1,\ldots)$ be the result of $p$ playing against $e_0$.
    It follows that there is some $j$ such that for all $i>j$,
    $h(y_1,\ldots,y_{i-1})=x_i=y_i=f(i)$.
    This shows that for all but finitely many $i\in\mathbb N$,
    $f(i)=h(y_1,\ldots,y_{i-1})$. Since $X$ knows that $M_k$ defines a total
    function from $B^*$ to $B$, it follows that
    there is a Turing machine $M$ such that $M$ computes $f$ and $X$ knows
    $M$ computes a total function from $\mathbb N$ to $B$. Absurd, this
    contradicts our choice of $f$.

    Case 2: $g(\langle\rangle)=0$. Then by similar reasoning as in Case 1,
    it can be shown that $p$ does not learn $e_1$.
\end{proof}

Example \ref{bruteforcenottotallyoptimalexample} shows that we cannot
hope for the brute-force to be totally optimal in the most extreme possible sense:
there will always be evaders that the AGI's brute-force predictor
fails to learn, but which other
predictors (which the AGI is capable of acting as)
do nevertheless learn. Example \ref{bruteforcenottotallyoptimalexample} involves
highly contrived evaders which are custom-made to act stupidly in one specific case
(allowing them to be learned by stupid predictors), while being
highly sophisticated in other cases. In the following definition, we rule out
situations where a less sophisticated predictor manages to learn a
more sophisticated evader due to the evader concealing its true sophistication from
the predictor.

\begin{definition}
\label{notwithoutafightdefn}
    Suppose $p$ is a predictor and $e$ is an evader.
    We say that \emph{$p$ learns $e$ but-not-without-a-fight}
    if the following conditions hold:
    \begin{enumerate}
        \item $p$ learns $e$.
        \item For each $i$, $t_p(i)\geq t_e(i)$.
    \end{enumerate}
\end{definition}

Armed with Definition \ref{notwithoutafightdefn}, we can now state a theorem
which shows the semi-optimality of the brute-force predictor.

\begin{theorem}
\label{semioptimalitytheorem}
    (Semi-optimality of brute force)
    Let $X$ be an AGI and let $p$ be any predictor.
    If $X$ knows that $p$ computes a total function from $B^*$ to $B$,
    and if $p$ learns an evader $e$ but-not-without-a-fight,
    then $X$'s brute-force predictor learns $e$.
\end{theorem}

\begin{proof}
    Since $X$ knows $p$ computes a total
    function from $B^*$ to $B$, $X$ knows that $e'$ is a total
    computable function from $B^*$ to $B$, where $e'$ is the Turing machine which
    takes an input $b\in B^*$ and operates as follows:
    \begin{enumerate}
        \item
        Calculate $t_p(i)$ (by running $p$ on all length-$i$ binary sequences).
        \item
        Run $e$ on $b$ for up to $t_p(i)$ steps. If $e$ outputs a result $x$ within that
        time, then output $x$. Otherwise, output $0$.
    \end{enumerate}
    Since $p$ learns $e$ but-not-without-a-fight, each $t_p(i)\geq t_e(i)$,
    so in fact $e'$ computes the same function as $e$.
    By Lemma \ref{knowingimplieslearninglemma}, $X$'s brute-force predictor
    learns $e'$. Since $e'$ and $e$ compute the same function, this implies
    $X$'s brute-force predictor learns $e$.
\end{proof}

\subsection{Triviality of the original Hibbard measure}
\label{trivialitysubsection}

Although Example \ref{bruteforcenottotallyoptimalexample} showed that
an AGI $X$'s brute-force predictor
is not optimal in the strongest possible sense, Theorem \ref{semioptimalitytheorem}
shows that $X$'s brute-force predictor is still semi-optimal. In some sense,
$X$'s brute-force predictor learns every evader which any other predictor $p$ (that $X$
knows is a predictor) would learn, except possibly for cases where $p$ only learns
an evader $e$ because $e$ conceals its full sophistication from $p$.

Since we only used basic mathematics to prove Theorem \ref{semioptimalitytheorem},
any genuine AGI should also eventually figure out Theorem \ref{semioptimalitytheorem}.
Thus, when an AGI is commanded to compete as a predictor in the adversarial
sequence prediction game, the resulting predictor which the AGI acts as should be
at least as good as the brute-force predictor, because why would the AGI act as
a worse predictor if it can figure out that brute-force is semi-optimal?
We formalize this in the following assumption.

\begin{assumption}
\label{bruteforceassumption}
    For every AGI $X$, $X$'s predictor is at least as good as
    $X$'s brute-force predictor, by which we mean that for every evader $e$,
    if $X$'s brute-force predictor learns $e$, then $X$'s predictor
    learns $e$.
\end{assumption}

Based on Assumption \ref{bruteforceassumption},
we are now ready to argue that the original Hibbard measure is
trivial: that it assigns intelligence level $\infty$ to every AGI.

\begin{theorem}
\label{everyagihasoriginalhibbardintinfinitytheorem}
    Every AGI $X$ has original Hibbard intelligence $\infty$.
\end{theorem}

\begin{proof}
    Let $p$ be $X$'s brute-force predictor, and let $q$ be $X$'s predictor.
    By Definition \ref{generalintelligencemeasuredefn}, in order
    to show $X$ has original Hibbard intelligence $\infty$, we must
    show that $q$ learns to predict $e$ for every $e$ in $E_{f_m}$ for
    every $m\in\mathbb N$,
    where each $f_m:\mathbb N\to\mathbb N$ is defined by
    $f_m(k)=\max_{0<i\leq m}\max_{j\leq k}g_i(j)$,
    where $g_i$ is the $i$th primitive recursive function
    in Liu's enumeration
    (Definition \ref{classichibbardmeasuredefn}).
    By Assumption \ref{bruteforceassumption}, it suffices to show that
    $q$ learns all such $e$, for then Assumption \ref{bruteforceassumption}
    says that $p$ learns all such $e$ as well.

    Let $m\in\mathbb N$ be arbitrary and let $e\in E_{f_m}$ be arbitrary.
    By Definition \ref{evadersetdefinition},
    for all but finitely many $n\in\mathbb N$, $t_e(n)<f_m(n)$.
    We will show that $p$ learns to predict $e$.

    Let $M$ be a Turing machine which takes an input
    $(y_1,\ldots,y_n)\in B^*$ and
    operates as follows:
    \begin{itemize}
        \item
        Spend up to $f_m(n)$ steps computing $e(y_1,\ldots,y_n)$.
        If $e$ halts (with output $x$) during that time, then output $x$.
        Otherwise, output $0$.
    \end{itemize}
    Since, for all but finitely many $n\in\mathbb N$, $t_e(n)<f_m(n)$,
    it follows that $M$ computes the same function as $e$ except for finitely
    many exceptions.

    It is well-known that for every primitive recursive function $g$, Peano
    arithmetic proves that $g$ is total. Thus, by the \emph{basic mathematical
    exposure} and \emph{mathematical reasoning ability} assumptions from
    Assumption \ref{idealizingassumption}, it follows that $X$ knows that
    $M$ is total. Since $M$ computes the same function as $e$ except for
    finitely many exceptions, it follows that there is a Turing machine $M'$
    which computes the same function as $e$, and such that $X$
    knows that $M'$ is total. By Lemma \ref{knowingimplieslearninglemma},
    $p$ learns to predict $e$.
\end{proof}

\begin{corollary}
\label{trivialityofslowgrowinghierarchycorollary}
    Every AGI $X$ has intelligence $\infty$ according to
    the Hibbard measure given by the standard slow-growing hierarchy
    up to $\epsilon_0$
    (Definition \ref{tradmajorizationhierarchyhibbardmeasuredefn}).
\end{corollary}

\begin{proof}
    Similar to the proof of Theorem \ref{everyagihasoriginalhibbardintinfinitytheorem}
    (just like a genuine AGI should know totality of functions outgrowing all
    primitive recursive functions, likewise a genuine AGI should have no problem
    knowing the totality of functions outgrowing all levels of the standard
    slow-growing hierarchy up to $\epsilon_0$).
\end{proof}

We will finish this section by stating one other important, possibly
counterintuitive consequence of Assumption \ref{bruteforceassumption}.

\begin{theorem}
\label{counterintuitivetheorem}
    If $X$ is an AGI and $p$ is $X$'s predictor, then $X$ does not know that
    $p$ defines a total function from $B^*$ to $B$.
\end{theorem}

\begin{proof}
    Let $e$ be the evader which attempts to evade the predictor by assuming that
    the predictor is $p$ and always playing the opposite digit which $p$ is
    about to play. Clearly $p$ does not learn $e$.

    The fact that $e$ defines a total function from $B^*$ to $B$ follows
    by basic mathematical reasoning from the fact that $p$ defines a total
    function from $B^*$ to $B$. Thus, if $X$ knows that $p$ defines a total
    function from $B^*$ to $B$, then $X$ should know that $e$ defines a total
    function from $B^*$ to $B$. If so, then $X$'s brute-force predictor learns
    $e$ by Lemma \ref{knowingimplieslearninglemma}. But then
    Assumption \ref{bruteforceassumption} would imply that $p$ learns $e$,
    a contradiction.
\end{proof}

Theorem \ref{counterintuitivetheorem} is reminiscent of
Examples \ref{counterintuitiveexample1} and \ref{counterintuitiveexample2}.

\section{Pros and cons of different Hibbard-style measures}
\label{prosandconssection}

Here are pros and cons of the Hibbard measures which arise from different solutions
to the problem (Problem \ref{bigoproblem}) of measuring the growth rate of functions.

\begin{itemize}
    \item
    The original Hibbard measure (Definition \ref{classichibbardmeasuredefn}),
    which arises by measuring growth rate by comparing
    a function with one particular enumeration \cite{liu1960enumeration} of the primitive
    recursive functions:
    \begin{itemize}
        \item
        Pro: Relatively concrete.
        \item
        Pro: Measures intelligence using a familiar number system (the natural numbers).
        \item
        Con: The numbers which the measure outputs are not very meaningful, in the sense
        that AGI $X$ having a measure of just $+1$ higher than AGI $Y$ tells us absolutely
        nothing about how \emph{much} more computationally complex the evaders which $X$'s
        predictor learns are, versus the evaders which $Y$'s predictor learns.
        \item
        Con: In Theorem \ref{everyagihasoriginalhibbardintinfinitytheorem}, we argued
        that the original Hibbard measure assigns intelligence $\infty$ to every AGI.
    \end{itemize}
    \item
    Big-O/Big-$\Theta$/Big-$\Omega$ (Definition \ref{bigointelligencedefn}),
    in which, rather than directly measuring the intelligence of an AGI, instead, we
    would talk of an AGI's intelligence being $O(f(n))$, or $\Theta(f(n))$, or
    $\Omega(f(n))$, for various functions $f:\mathbb N\to\mathbb N$:
    \begin{itemize}
        \item
        Pro: Gets directly at the underlying concept, without obfuscation.
        \item
        Pro: Computer scientists already use Big-O/Big-$\Theta$/Big-$\Omega$ routinely
        and are comfortable with them.
        \item
        Con: This option is not really a measure, but more of a taxonomy---and a non-numerical
        taxonomy at that.
    \end{itemize}
    \item
    Hyperreal intelligence (Definition \ref{hyperrealhibbardintelligencedefn}):
    \begin{itemize}
        \item
        Pro: A taxonomy like Big-O/Big-$\Theta$/Big-$\Omega$, but with the added benefit
        that the taxons are numerical (hyperreal numerical, to be more precise).
        \item
        Con: Depends on a non-constructive choice of a free ultrafilter (rendering it
        impractical for any actual computation).
    \end{itemize}
    \item
    Surreal intelligence (Definition \ref{surrealhibbardintelligencedefn}):
    \begin{itemize}
        \item
        Pro: An actual numerical measure (not just a taxonomy), with the same perfect
        precision as the Big-O/Big-$\Theta$/Big-$\Omega$ approach.
        \item
        Con: Abstract and impractical: depends not only on a
        non-constructive choice of
        a free ultrafilter, but also on an embedding of the hyperreals into the surreals.
        \item
        Con: The numbers which the measure outputs are surreal numbers, which may be
        unfamiliar to some users.
    \end{itemize}
    \item
    Intelligence based on a standard majorization hierarchy such as the
    standard slow-growing hierarchy up to $\epsilon_0$
    (Definition \ref{tradmajorizationhierarchyhibbardmeasuredefn}):
    \begin{itemize}
        \item
        Pro: A numerical measure, albeit without as much precision as the
        Big-O/Big-$\Theta$/Big-$\Omega$ taxonomy.
        \item
        Pro: Relatively concrete.
        \item
        Pro: The numbers which the measure outputs are meaningful, in the sense that
        the degree to which an AGI $X$ is more intelligent than an AGI $Y$ is reflected
        in the degree to which $X$'s intelligence-measure is larger than $Y$'s.
        \item
        Con: The numbers which the measure outputs are ordinal numbers, which may be
        unfamiliar to some users.
        \item
        Con: In Corollary \ref{trivialityofslowgrowinghierarchycorollary}, we argued
        that the original Hibbard measure assigns intelligence $\infty$ to every AGI.
    \end{itemize}
    \item
    Intelligence based on a generalized majorization hierarchy
    (Definition \ref{generalizedmajorizationhierarchydefn}):
    \begin{itemize}
        \item
        Pro: A numerical measure, albeit without as much precision as the
        Big-O/Big-$\Theta$/Big-$\Omega$ taxonomy.
        \item
        Pro: The numbers which the measure outputs are meaningful, in the sense that
        the degree to which an AGI $X$ is more intelligent than an AGI $Y$ is reflected
        in the degree to which $X$'s intelligence-measure is larger than $Y$'s.
        \item
        Con: The numbers which the measure outputs are ordinal numbers, which may be
        unfamiliar to some users.
        \item
        Con: Actually realizing one of these measures would require access to an AGI.
    \end{itemize}
\end{itemize}

\section{Summary and Conclusion}
\label{conclusionsection}

To summarize:
\begin{itemize}
    \item
    Hibbard proposed \cite{hibbard} an intelligence measure for predictors (and, implicitly,
    for AGIs capable of acting as predictors) in games of adversarial sequence prediction.
    \item
    We argued that Hibbard's idea actually splits into two orthogonal sub-ideas.
    Firstly: that intelligence can be measured via the growth-rate of the run-times
    of evaders that an AGI can learn to predict. Secondly: that such growth-rate can
    be measured in one specific way (involving an enumeration of the primitive recursive
    functions). We argue that there are other, more standard ways to measure growth-rates,
    and that each method of measuring growth-rates yields a corresponding Hibbard-style
    intelligence measure.
    \item
    We considered several specific ways of measuring growth-rate of functions, and exhibited
    corresponding Hibbard-style intelligence measures. The growth-rate-measuring methods
    which we considered were: Big-O/Big-$\Theta$/Big-$\Omega$ notation; hyperreal numbers;
    surreal numbers; standard majorization hierarchies; and (in their debut appearance here)
    generalized majorization hierarchies.
    \item
    Finally, in Section \ref{trivialitysection}, we argued that all AGIs probably have
    intelligence $\infty$ according to Hibbard's definition. Essentially, this is because
    the specific functions that Hibbard's definition is based on should all be trivially
    well-known by any genuine AGI.
\end{itemize}

This paper exemplifies a useful technique for theoretical AGI research.
By viewing an AGI as an employee who is capable of engaging in casual human
language communication with its employer, and which can be commanded (using said
casual human language) to perform mathematical tasks, the AGI becomes a useful
black box to which many arbitrary decisions can be delegated. For example, instead
of arbitrarily choosing one particular majorization hierarchy (a difficult task
because there are many majorization hierarchies and there is no consensus about
which majorization hierarchies are canonical), we can short-circuit the decision
by delegating it to an AGI.


\bibliographystyle{plain}
\bibliography{hibbard}
\end{document}
