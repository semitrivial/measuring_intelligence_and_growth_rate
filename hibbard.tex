\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{mathdots}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}

\title{Extending Hibbard's intelligence measure by delegating to the agent}
\author{Samuel Alexander\thanks{The U.S.\ Securities and Exchange Commission}}
\date{2020}

\begin{document}

\maketitle

\begin{abstract}
In 2011, Hibbard suggested an intelligence measure for predictors in adversarial
sequence prediction games (and, implicitly, for agents with Artificial General Intelligence
(AGIs) capable of acting as
predictors). Hibbard's measure depends on a function-sequence
imported from a paper by Liu. We argue that Hibbard's measure is trivial:
any genuine AGI should have intelligence $\infty$ according to it,
because the functions in Liu's paper are
trivial to a genuine AGI. Our key insight is this: rather than depend on an
arbitrary choice of function-sequence, we can delegate that decision to an AGI.
In this way, we propose what we call simple Hibbard measures,
which are like Hibbard's original measure but are not trivial.
However, simple Hibbard measures are still flawed. To repair their flaws,
we further propose what we call transfinite Hibbard measures,
similar to simple Hibbard measures except that
they depend on an AGI choosing a slow-growing hierarchy (from mathematical logic) rather
than a function-sequence.
\end{abstract}

\section{Introduction}

\begin{quote}
    Todo:
    \begin{enumerate}
        \item Fix the subscripts in generalintelligencemeasuredefn to start at 0.
        \item More examples in AGI section, including Turing Test.
        \item Better formal encoding of slow-growing hierarchies.
        \item Formal theorem suggesting THM/IOI connection.
        \item References about adversarial sequence prediction etc (including Gamez).
        \item More background about fast- and slow-growing hierarchies.
    \end{enumerate}
\end{quote}

In his insightful paper \cite{hibbard}, Bill Hibbard introduces a novel
intelligence measure (which we will here refer to as the \emph{classical Hibbard measure})
for agents with Artificial General Intelligence (or AGIs).
Hibbard's measure is based on ``the game of adversarial sequence prediction
against a hierarchy of increasingly difficult sets of'' evaders (environments that attempt
to emit $1$s and $0$s in such a way as to evade prediction).
The levels of Hibbard's hierarchy are labelled by natural numbers\footnote{Technically,
Hibbard's hierarchy begins at level $1$ and he separately defines what it means for
an agent to have intelligence $0$, but that definition is equivalent to what would result
by declaring that the $0$th level of the hierarchy consists of the empty set of evaders.}, and
an agent's classical Hibbard measure is the maximum $n\in\mathbb N$ such that
said agent can eventually predict all the evaders in the $n$th level of the hierarchy,
or implicitly\footnote{Hibbard does not explicitly include the $\infty$ case in his
definition, but in his Proposition 3 he refers to agents having ``finite intelligence'', and
it is clear from context that by this he means agents who fail to predict some evader
somewhere in the hierarchy.} an agent's classical Hibbard measure is defined to be $\infty$
if said agent can eventually predict all the evaders in all levels of the hierarchy.

In this paper, we will argue that the evader-hierarchy which Hibbard originally proposed is
trivial: we will argue that \emph{all} suitably idealized AGIs probably have $\infty$
intelligence according to the classical Hibbard measure.
We will suggest two different methods to repair Hibbard's intelligence measure.
\begin{itemize}
    \item
    The first method we describe will be elementary, in the sense that it will
    essentially involve
    no mathematics more advanced than the mathematics used in Hibbard's original approach.
    However, we will show that the intelligence measure yielded by this elementary
    method has a crucial flaw.
    \item
    The second method we describe will make use of two advanced notions from
    mathematical logic: the \emph{slow-growing hierarchy}
    \cite{weiermann2002slow} and the ordinal notation system known as
    \emph{Kleene's $\mathcal O$} \cite{kleene1938notation}.
\end{itemize}
Both of these methods will, rather than producing a single intelligence measure,
rather, produce a family of intelligence measures indexed by a parameter $X$ where
$X$ is an AGI. In other words, for every AGI $X$, for each of the above two methods,
there will be a corresponding intelligence measure, which can informally be thought
of as ``intelligence as judged by $X$'': $X$ itself will have intelligence $\infty$
according to the intelligence measure corresponding to $X$, but some other AGI $Y$
may have non-$\infty$ intelligence. This captures the intuition that an entity who
measures intelligence of less intelligent entities cannot accurately measure
its own intelligence, nor the intelligence of entities more intelligent than itself.

The structure of the paper is as follows.
\begin{itemize}
    \item
    In Section \ref{originalmeasuresection}, we review the classical Hibbard measure.
    \item
    In Section \ref{agiperspectivesection}, we present our viewpoint of AGIs and argue that
    under certain idealizing assumptions, \emph{every} AGI probably has intelligence
    $\infty$ according to the classical Hibbard measure.
    \item
    In Section \ref{simplemeasuresection}, we present an elementary way to
    remedy Hibbard's intelligence
    measure so that not every AGI has intelligence $\infty$; however, the resulting
    intelligence measures are shown to still have a crucial flaw.
    \item
    In Section \ref{slowgrowinghierarchysection}, we review the \emph{slow-growing hierarchy}.
    \item
    In Section \ref{transfinitehibbardsection}, we use the
    slow-growing hierarchy and Kleene's $\mathcal O$
    to present another way to
    remedy Hibbard's intelligence measure. This resulting intelligence measures do not
    have the flaw that is seen in Section \ref{simplemeasuresection}.
    \item
    In Section \ref{conclusionsection}, we summarize and make concluding remarks.
\end{itemize}

\section{Hibbard's original measure}
\label{originalmeasuresection}

Hibbard's intelligence measure is based on predictors and evaders---the predictor
representing the AGI whose intelligence we would like to measure, and the evader
representing an environment---which we define below. A predictor and an evader
are thought of as interacting together in a ``game of adversarial sequence prediction''.

\begin{definition}
By $B$, we mean the binary alphabet $\{0,1\}$. By $B^*$, we mean the set of all
finite binary sequences. By $B^\infty$, we mean the set of all infinite binary
sequences. By $\langle\rangle$ we mean the empty binary sequence.
\end{definition}

\begin{definition}
\label{evaderpredictordefn}
    (Evaders and predictors)
    \begin{enumerate}
        \item
        By an \emph{evader}, we mean a Turing machine $e$
        which takes as input a finite (possibly empty) binary sequence
        $(y_1,\ldots,y_n)\in B^*$
        (thought of as a sequence of \emph{predictions})
        and outputs $0$ or $1$ (thought of as an \emph{evasion}), which output
        we write as $e(y_1,\ldots,y_n)$.
        \item
        By a \emph{predictor}, we mean a function $p:B^*\to B$
        which takes as input a finite (possibly empty) binary sequence
        $(x_1,\ldots,x_n)\in B^*$
        (thought of as a sequence of \emph{evasions})
        and outputs $0$ or $1$ (thought of as a \emph{prediction}).
        \item
        For any evader $e$ and predictor $p$, the \emph{result of $p$ playing the
        game of adversarial prediction against $e$} (or more simply, the \emph{result of
        $p$ playing against $e$}) is the infinite binary sequence
        $(x_1,y_1,x_2,y_2,\ldots)\in B^\infty$
        defined as follows:
        \begin{enumerate}
            \item
            $x_1=e(\langle\rangle)$ is
            the output of $e$ when run on the empty prediction-sequence.
            This is thought of as $e$'s first evasion.
            \item
            $y_1=p(\langle\rangle)$ is
            the result of applying $p$ to the empty evasion-sequence.
            This is thought of as $p$'s first prediction.
            \item
            For all $n>0$,
            $x_{n+1}=e(y_1,\ldots,y_n)$ is
            the output of $e$ on the sequence of $p$'s first $n$ predictions.
            This is thought of as $e$'s $(n+1)$th evasion.
            \item
            For all $n>0$,
            $y_{n+1}=p(x_1,\ldots,x_n)$ is
            the result of applying $p$ to $e$'s first $n$ evasions.
            This is thought of as $p$'s $(n+1)$th prediction.
        \end{enumerate}
        \item
        Suppose $r=(x_1,y_1,x_2,y_2,\ldots)$ is the result of a predictor $p$ playing
        against an evader $e$. For every $n\geq 1$,
        we say that \emph{the predictor wins round $n$ in $r$}
        if $x_n=y_n$; otherwise, if $x_n\neq y_n$, we say that
        \emph{the evader wins round $n$ in $r$}.
        We say that \emph{$p$ learns to predict $e$} if there is some $N\in\mathbb N$
        such that for all $n>N$, $p$ is the winner of round $n$ in $r$.
    \end{enumerate}
\end{definition}

\begin{definition}
\label{tsubedefinition}
    For any evader $e$ and natural $n>0$,
    let
    \[
        t_e(n) = \max_{b_1,\ldots,b_n\in \{0,1\}}
        (\text{number of steps $e$ takes to run on input $(b_1,\ldots,b_n)$}).
    \]
\end{definition}

\begin{example}
Let $e$ be an evader.
\begin{enumerate}
    \item
    $t_e(0)$ is simply the number of steps $e$ takes to run on input $\langle\rangle$,
    the empty binary sequence.
    \item
    $t_e(2)$ is equal to the number of steps $e$ takes to run on input
    $(0,0)$, or to run on input $(0,1)$, or to run on input $(1,0)$, or to run on input
    $(1,1)$---whichever of these four possibilities is largest.
\end{enumerate}
\end{example}

\begin{definition}
\label{evadersetdefinition}
    Suppose $f:\mathbb N\to\mathbb N$. We define the \emph{evader-set bounded by $f$},
    written $E_f$, to be the set of all evaders $e$ such that
    there is some $k\in\mathbb N$ such that $\forall n>k$,
    $t_e(n)<f(n)$.
\end{definition}

\begin{definition}
\label{generalintelligencemeasuredefn}
    Suppose $g_i$ ($i\in \mathbb N$) is any family of functions,
    each $g_i:\mathbb N\to\mathbb N$.
    For each $m\in\mathbb N$, define $f_m:\mathbb N\to\mathbb N$ by
    \[f_m(k)=\max_{i\leq m}\max_{j\leq k}g_i(j).\]
    For any predictor $p$, the \emph{Hibbard intelligence of $p$ (given by the family $g_i$)}
    is defined to be the maximum $m$ such that
    $p$ learns to predict $e$ for every $e$ in $E_{f_m}$ (or $\infty$
    if $p$ learns to predict $e$ for every $e$ in $E_{f_m}$ for every $m$).
\end{definition}

\begin{definition}
\label{classichibbardmeasuredefn}
    The \emph{classic Hibbard measure} is defined to be the Hibbard intelligence
    measure given by one specific family $g_i$ of functions, namely:
    the enumeration of the primitive recursive functions described by S.C.\ Liu
    \cite{liu1960enumeration}.
\end{definition}


\section{Do all AGIs have classic Hibbard intelligence $\infty$?}
\label{agiperspectivesection}

\begin{quote}
    ``Thus it is a property of man to be capable of learning
    grammar; for if he is a man, then he is capable of learning
    grammar, and if he is capable of learning grammar, then he is
    a man.'' ---Aristotle \cite{aristotle}
\end{quote}

As yet, we are unaware of any formal mathematical definition of what an AGI
actually is. We take the stance that an AGI should be capable of understanding
practical conversations and instructions in a common human language (such as
English) and, if commanded by their employers, to obey commands expressed
therein. So if the AGI's employer said, ``Recite digits of pi until I tell you to
stop,'' then the AGI would begin computing and reciting digits of pi, until said
employer told it to stop (if ever). Unlike a human employee, who would eventually
get fed up with such a task, an AGI should have no fear of tedium, and should
never grow tired of performing whatever task it has been assigned.

We think assumptions like the above are implicit in many attempts to study AGIs.
Many authors who set out to study
AGIs actually study not the full AGI, but rather the AGI's persona when it is
performing some general type of task. For example:
\begin{itemize}
    \item
    Legg and Hutter measure the intelligence of AGIs based on their performance
    in reinforcement learning environments \cite{legg}. On a superficial
    level, that approach is inappropriate because a genuine AGI is much more than
    merely a reinforcement learning agent (however good that agent might be).
    But at a deeper level, the approach is appropriate because although an AGI is
    more than an RL agent, we could command the AGI to act as an RL agent, saying,
    ``I am going to put you in a certain environment where you can take such-and-such
    tasks, and rewards and observations will be communicated to you; please try to
    reverse-engineer the environment and act in such a way as to maximize rewards.''
    And while it is difficult to say anything about a full AGI, we can say quite a
    lot about an RL agent, and thus we can study AGIs by proxy.
    \item
    In the Non-Axiomatic Reasoning System research program (NARS) \cite{nars},
    AGIs are reduced to agents who are bombarded with assertions in a specific formal
    language, each assertion being accompanied by a priority measure, and some of
    which assertions might contradict each-other. At any time during the bombardment
    of assertions, the agent might also be queried, at which point the agent's job is
    to estimate the probability of the truth of a queried assertion, based on the
    assertions and priorities it has seen so far. This is certainly not all an AGI
    is (for an AGI should be able to reason about first- and higher-order logics
    involving quantifiers, for example). Nevertheless, an AGI's employer could command
    it to behave like such an agent, and in response the AGI would behave like such an
    agent.
    \item
    Many philosophers and logicians reduce an AGI to a mere \emph{knowing
    agent} who performs no actions but simply knows things in some formal language.
    Superficially, this is inappropriate because an AGI does much more than merely
    know things \cite{wang2007three}. But at a deeper level, this is appropriate
    because an AGI could certainly be commanded to act as such an agent, e.g., via 
    a command like: ``Until further notice, do nothing except enumerate consequences
    of Peano arithmetic'' (or some other formal language). And again, while it is
    hard to say anything about a full AGI, we can say a lot about such computably
    enumerable theories as would be recited by an AGI in response to such a question
    (and they would indeed be computably enumerable because an AGI, whatever else it
    is, must be mechanical).
\end{itemize}

In the same way, an AGI is certainly more than a predictor competing in
games of adversarial sequence prediction. But an AGI could be commanded to
act as such a predictor. That is why it makes sense to refer to the measures
from Definition \ref{generalintelligencemeasuredefn} as ``intelligence'' measures
(rather than as, say, ``prediction power'' measures). In the same way that
IQ tests are intended to measure overall human intelligence despite the fact that
human intelligence is so much more than the ability to take IQ tests, in the same
way, adversarial sequence prediction games can serve as a sort of intelligence
test for AGIs.

In the remainder of this section, we will argue that under certain idealizing
assumptions, every AGI should have classical Hibbard intelligence $\infty$.
Thus, we would suggest that Definition \ref{classichibbardmeasuredefn} is really
only appropriate for certain weak AIs who are strong enough that they can be
induced to participate in adversarial sequence prediction games, but who are
not strong enough to qualify as genuine AGIs. Later in the paper, we will argue
that suitable extensions of Hibbard's intelligence measure are more relevant
for genuine AGIs.

\begin{assumption}
\label{idealizingassumption}
    We make the following idealizing assumptions about an AGI $X$.
    \begin{itemize}
        \item
        (Mathematical truthfulness) If $X$ knows some statement in the language
        of Peano arithmetic, then that statement is true.
        \item
        (Mathematical reasoning ability) If $X$ knows some set $S$ of mathematical
        axioms then, given sufficient time to think about it, $X$ would eventually
        become aware of all the consequences of $S$.
        \item
        (Basic mathematical exposure) $X$ knows the axioms of Peano arithmetic.
        \item
        (Caution) $X$ avoids infinite loops: if $X$ is commanded to play the
        role of a predictor, then the resulting predictor $p$ will indeed
        be a predictor (a total computable function
        from $B^*$ to $B$). More generally, if $X$ is commanded to carry out any
        task which involves outputting things repeatedly
        until further notice, and the task is not impossible
        (e.g., does not require solving the Halting Problem or doing other
        non-computable things), then $X$ will continue outputting things (perhaps
        after long intervals in between outputs), without ever entering into an
        infinite period without output.
    \end{itemize}
\end{assumption}

\begin{definition}
\label{Xspredictordefn}
    Suppose $X$ is an AGI.
    \begin{enumerate}
        \item
        \emph{$X$'s predictor} is the predictor which
        would result if $X$ were commanded to play the role of a predictor (a
        genuine predictor by the \emph{caution} part of Assumption
        \ref{idealizingassumption}).
        \item
        For any family $g_i$ of functions as in
        Definition \ref{generalintelligencemeasuredefn},
        the \emph{Hibbard intelligence of $X$ (given by the family $g_i$)}
        is defined to be the Hibbard intelligence of
        $X$'s predictor (given by the family $g_i$).
    \end{enumerate}
\end{definition}

\subsection{A semi-optimal predictor}
\label{semioptimalpredictorsubsection}

\begin{definition}
\label{bruteforcepredictordefn}
    (The Brute-Force Predictor)
    Suppose $X$ is an AGI. Let $M_1,M_2,\ldots$ be the list of Turing machines
    which $X$ would enumerate if $X$ were commanded: ``Enumerate all the Turing
    machines which you know define total functions from $B^*$ to $B$''.
    By \emph{$X$'s brute-force predictor}, we mean the predictor $p$ defined
    as follows.
    \begin{enumerate}
        \item
        Initially, $p$ shall attempt to predict the evader $e$ by assuming that $e$
        defines the same function as $M_1$. When (if ever) this fails,
        say that \emph{$M_1$ is ruled out from being the evader}.
        \item
        Once $M_1$ has been ruled out from being the evader (if ever),
        $p$ shall attempt to predict $e$ by assuming that $e$ defines the same
        function as $M_2$. When (if ever) this fails,
        say that \emph{$M_2$ is ruled out from being the evader}.
        \item
        Once $M_2$ has been ruled out from being the evader (if ever),
        $p$ shall attempt to predict $e$ by assuming that $e$ defines the same
        function as $M_3$. When (if ever) this fails,
        say that \emph{$M_3$ is ruled out from being the evader}.
        \item
        And so on forever...
    \end{enumerate}
\end{definition}

Note that $X$'s predictor (Definition \ref{Xspredictordefn})
may or may not be equal to $X$'s brute-force predictor
(Definition \ref{bruteforcepredictordefn}). Note also that $X$'s brute-force predictor
is total precisely because of the mathematical truthfulness assumption
(from Definition \ref{idealizingassumption}): whenever $X$ knows that
$M_i$ defines a total function from $B^*$ to $B$, $M_i$ really \emph{does}
define a total function from $B^*$ to $B$ (hereafter, we will suppress
remarks like this and routinely use the mathematical truthfulness assumption
without explicit mention).

\begin{lemma}
\label{knowingimplieslearninglemma}
    Let $X$ be an AGI and let $e$ be an evader (so $e$ is a Turing machine which
    computes a function from $B^*$ to $B$).
    Let $M$ be any Turing machine which computes the same function from $B^*$ to $B$
    as $e$ computes.
    If $X$ knows that $M$ defines a total function from $B^*$ to $B$,
    then $X$'s brute-force predictor learns to predict $e$.
\end{lemma}

\begin{proof}
    Let $p$ be $X$'s brute-force predictor.
    Let $M_1,M_2,\ldots$ be as in Definition \ref{bruteforcepredictordefn}.
    Since $X$ knows that $M$ defines a total
    function from $B^*$ to $B$,
    it follows that $M=M_k$ for some $k$.
    When $p$ plays against $e$, it cannot occur that $M_k$ is ruled out
    from being the evader, because in order for that to occur, $p$ would have
    to fail at predicting $e$ when $p$ assumes that $e$ computes the same
    function as $M_k$, but that cannot fail because that assumption is true.
    Since $M_k$ cannot be ruled out from being the evader, it follows that
    step $k+1$ of Definition \ref{bruteforcepredictordefn} will never be
    reached, which in turn implies that $p$ stops failing at predicting $e$
    after finitely many initial failures, in other words, $p$ learns to
    predict $e$.
\end{proof}

For any AGI $X$, we would like to claim that $X$'s brute-force predictor is
optimal among all predictors $X$ could act as; unfortunately this
is not true in the strongest sense it possibly could be true, as the following
example shows.

\begin{example}
\label{bruteforcenottotallyoptimalexample}
    Let $X$ be an AGI. Let $f:\mathbb N\to B$ be a total computable function which
    is different from every total computable function $X$ knows.
    For each $i\in\{0,1\}$, $e_i$ be an evader defined as follows:
    \[
        e_i(y_1,\ldots,y_n) =
        \begin{cases}
            i &\mbox{if $y_1=\cdots=y_n=i$ (or if $n=0$),}\\
            f(n) &\mbox{otherwise.}
        \end{cases}
    \]
    For each $i\in\{0,1\}$, let $p_i$ be the
    constantly-$i$ predictor, $p_i(x_1,\ldots,x_n)=i$.
    Then $p_0$ learns to predict $e_0$ and $p_1$ learns to predict $e_1$,
    but $X$'s brute-force predictor learns to predict at most one of $e_0$ or $e_1$.
\end{example}

\begin{proof}
    Clearly the result of $p_0$ playing against $e_0$ is
    $(x_0,y_0,x_1,y_1,\ldots)=(0,0,0,0,\ldots)$, so $p_0$ learns to predict $e_0$.
    Likewise, the result of $p_1$ playing against $e_1$ is
    $(x_0,y_0,x_1,y_1,\ldots)=(1,1,1,1,\ldots)$, so $p_1$ learns to predict $e_1$.
    It remains to show that $X$'s brute-force predictor cannot learn to predict
    both $e_0$ and $e_1$.

    Let $p$ be $X$'s brute-force predictor.
    Let $M_1,M_2,\ldots$ be as in Definition \ref{bruteforcepredictordefn}.
    Let $g:B^*\to B$ be the function defined by $M_1$.

    Case 1: $g(\langle\rangle)=1$. Then when $p$ plays against $e_0$,
    after the first step, it will never be the case that
    $y_1=\cdots=y_n=0$ (because $y_1=g(\langle\rangle)=1$).
    Thus, for all $n>0$, $e_0(y_1,\ldots,y_n)=f(n)$.
    I claim that $p$ does not learn $e_0$.
    To see this, assume (for the sake of contradiction)
    that $p$ learns $e_0$. It follows that there is some $k$ (which we may take
    as small as possible) such that $M_k$ never gets ruled out from being the
    evader (Definition \ref{bruteforcepredictordefn}). Let $h:B^*\to B$ be the
    function defined by $M_k$.
    Let $(x_0,y_0,x_1,y_1,\ldots)$ be the result of $p$ playing against $e_0$.
    It follows that there is some $j$ such that for all $i>j$,
    $h(y_1,\ldots,y_{i-1})=x_i=y_i=f(i)$.
    This shows that for all but finitely many $i\in\mathbb N$,
    $f(i)=h(y_1,\ldots,y_{i-1})$. Since $X$ knows that $M_k$ defines a total
    function from $B^*$ to $B$, it follows that $X$ knows $f$ is total computable,
    which contradicts our choice of $f$.

    Case 2: $g(\langle\rangle)=0$. Then by similar reasoning as in Case 1,
    it can be shown that $p$ does not learn $e_1$.
\end{proof}

Example \ref{bruteforcenottotallyoptimalexample} shows that we cannot
hope for the brute-force to be totally optimal in the most extreme possible sense:
there will always be evaders that the AGI's brute-force fails to learn, but which other
predictors (which the AGI knows about)
do nevertheless learn. Example \ref{bruteforcenottotallyoptimalexample} involves
highly contrived evaders which are custom made to act stupidly in one specific case
(allowing them to be learned by a correspondingly stupid predictor), while being
highly sophisticated in all other cases. In the following definition, we rule out
situations where a less sophisticated predictor manages to learn a
more sophisticated evader due to the latter cloaking its true sophistication from
the former.

\begin{definition}
    Suppose $M$ is a Turing machine which computes a predictor $p$.
    Suppose $e$ is an evader.
    We say that \emph{$M$ learns $e$ but-not-without-a-fight}
    if the following conditions hold:
    \begin{enumerate}
        \item $p$ learns $e$.
        \item For each $i$, $t_M(i)\geq t_e(i)$.
    \end{enumerate}
\end{definition}

\begin{theorem}
\label{semioptimalitytheorem}
    (Semi-optimality of brute force)
    Let $X$ be an AGI.
    Suppose $M$ is a Turing machine which computes a predictor $p$.
    If $X$ knows that $M$ computes a predictor, and if $M$ learns $e$
    but-not-without-a-fight, then $X$'s brute-force predictor learns $e$.
\end{theorem}

\begin{proof}
    Since $X$ knows $M$ computes a predictor, $X$ knows $M$ computes a total
    function from $B^*$ to $B$. Thus $X$ knows that that $e'$ is a total
    computable function from $B^*$ to $B$, where $e'$ is a Turing machine which
    takes an input $b\in B^*$ and operates as follows:
    \begin{enumerate}
        \item
        Calculate $t_M(i)$ (by running $M$ on all length-$i$ binary sequences).
        \item
        Run $e$ on $b$ up to $t_M(i)$ steps. If $e$ outputs a result $x$ within that
        time, then output $x$. Otherwise, output $0$.
    \end{enumerate}
    Since $M$ learns $e$ but-not-without-a-fight, each $t_M(i)\geq t_e(i)$,
    so in fact $e'$ computes the same function as $e$.
    By Lemma \ref{knowingimplieslearninglemma}, $X$'s brute-force predictor
    learns $e'$. Since $e'$ and $e$ compute the same function, this implies
    $X$'s brute-force predictor learns $e$.
\end{proof}

\subsection{Triviality of the classical Hibbard measure}
\label{trivialitysubsection}

Although Example \ref{bruteforcenottotallyoptimalexample} showed that
an AGI $X$'s brute-force predictor
is not optimal in the strongest possible sense, Theorem \ref{semioptimalitytheorem}
shows that $X$'s brute-force predictor is still semi-optimal. In some sense,
$X$'s brute-force predictor learns every evader which any other predictor $p$ (that $X$
knows is a predictor) would learn, except possibly for cases where $p$ only learns
an evader $e$ because $e$ withholds its full sophistication from $p$.

Based on the above, we informally conjecture that the brute-force predictor is
the most sensible predictor for an AGI $X$ to act as, if $X$ is commanded to
act as a predictor and try to predict as many evaders as possible. If this conjecture
is true, then the following theorem suggests that the classical Hibbard measure is
trivial: that it assigns intelligence level $\infty$ to every AGI.

\begin{theorem}
    Suppose $X$ is an AGI. If $X$'s predictor is $X$'s brute-force predictor,
    then $X$ has classical Hibbard intelligence $\infty$.
\end{theorem}

\begin{proof}
    By Definition \ref{Xspredictordefn}, $X$'s classical Hibbard intelligence
    equals the classical Hibbard intelligence of $X$'s predictor, which is
    $X$'s brute-force predictor by assumption. Let $p$ be $X$'s brute-force
    predictor. By Definition \ref{generalintelligencemeasuredefn}, in order
    to show $p$ has classical Hibbard intelligence $\infty$, we must
    show that $p$ learns to predict $e$ for every $e$ in $E_{f_m}$ for
    every $m\in\mathbb N$,
    where each $f_m:\mathbb N\to\mathbb N$ is defined by
    $f_m(k)=\max_{i\leq m}\max_{j\leq k}g_i(j)$,
    where $g_i$ is the $i$th primitive recursive function
    (Definition \ref{classichibbardmeasuredefn}).

    Let $m\in\mathbb N$ be arbitrary and let $e\in E_{f_m}$ be arbitrary.
    By Definition \ref{evadersetdefinition},
    for all but finitely many $n\in\mathbb N$, $t_e(n)<f_m(n)$.
    We must show that $p$ learns to predict $e$.

    Let $M$ be a Turing machine which takes an input
    $(y_1,\ldots,y_n)\in B^*$ and
    operates as follows:
    \begin{itemize}
        \item
        Spend up to $f_m(n)$ steps computing $e(y_1,\ldots,y_n)$.
        If $e$ halts during that time, say with output $x$, then output $x$.
        Otherwise, output $0$.
    \end{itemize}
    Since, for all but finitely many $n\in\mathbb N$, $t_e(n)<f_m(n)$,
    it follows that $M$ computes the same function as $e$ except for finitely
    many exceptions.

    It is well-known that for any primitive recursive function $g$, Peano
    arithmetic proves that $g$ is total. Thus, by the \emph{basic mathematical
    exposure} and \emph{mathematical reasoning ability} assumptions from
    Assumption \ref{idealizingassumption}, it follows that $X$ knows that
    $M$ is total. Since $M$ computes the same function as $e$ except for
    finitely many exceptions, it follows that there is a Turing machine $M'$
    which computes the same function as $e$ all thet time, and such that $X$
    knows that $M'$ is total. By Lemma \ref{knowingimplieslearninglemma},
    $p$ learns to predict $e$, as desired.
\end{proof}

\section{An elementary method to non-trivialize Hibbard's intelligence measure}
\label{simplemeasuresection}

In Subsection \ref{trivialitysubsection}, we saw that every AGI probably has
intelligence $\infty$ according to the classical Hibbard measure. If so, this
means the classical Hibbard measure is trivial. In this section, we will present
the first of two methods for remedying this state of affairs. Rather than define
one single intelligence measure, we will define a family of intelligence measures:
one intelligence measure for each AGI $X$, which one might think of informally as
a measure of ``intelligence as judged by $X$''.

The idea is simple. The classical Hibbard measure
(Definition \ref{classichibbardmeasuredefn}) depends on a sequence $(g_0,g_1,\ldots)$
of total computable functions $g_i:\mathbb N\to\mathbb N$ imported from one specific
outside source, namely Liu \cite{liu1960enumeration}. Rather than artificially depend
on Liu, we will instead depend on an AGI $X$.

\begin{definition}
\label{functionlistdefinition}
    If $X$ is an AGI, let $(C^X_1, C^X_2, \ldots)$ be the sequence of
    Turing machines which would result if $X$ were commanded: ``Until further
    notice, list all the Turing machines $C$ that you can think of such that
    you know $C$ computes a total function from $\mathbb N$ to $\mathbb N$.''
    For each $i>0$, let $g^X_i:\mathbb N\to\mathbb N$ be the function computed by
    $C^X_i$.
\end{definition}

For example, if $X$ is an AGI, then in response to the command in Definition
\ref{functionlistdefinition}, $X$ might think for a while, figure out a Turing
machine $C^X_1$ which computes the constant function $g^X_1(n)=0$. Then $X$
might think some more and figure out a Turing machine $C^X_2$ which computes
the identity function $g^X_2(n)=n$. Then $X$ might think some more and figure
out a Turing machine $C^X_3$ which computes the prime number function, so that
$g^X_3(n)$ is the $(n+1)$th prime number. And so on.

It is philosophically interesting that although there is no apparent ordering that
would turn the set of all total-function-from-$\mathbb N$-to-$\mathbb N$-computing
Turing machines into a sequence, an AGI automatically acts as a kind of oracle for
so ordering said Turing machines (or at least, those which said AGI knows to be in
said set).

\begin{definition}
    For any AGI $X$, the \emph{simple Hibbard measure given by $X$}
    is defined to be the Hibbard measure given by
    $(g^X_1,g^X_2,\ldots$) (see Definition \ref{generalintelligencemeasuredefn}).
    For any AGI $Y$, we will write $|Y|_X$ for the intelligence of $Y$
    according to the simple Hibbard measure given by $X$.
\end{definition}

\subsection{Non-triviality of the simple Hibbard measures}

We will argue that, at least for certain AGIs $X$,
the simple Hibbard measure given by $X$ is
not trivial in the same way that the classical Hibbard measure is:
that at least for certain $X$, there exist $Y$ such that
$|Y|_X$ is finite.

\begin{theorem}
\label{simplehibbardnontrivialtheorem}
    (Non-triviality of simple Hibbard measures)
    Suppose $X$ and $Y$ are AGIs. Let $p$ be $Y$'s predictor.
    If $X$ knows that $p$ defines a total function from $B^*$ to $B$,
    then $|Y|_X<\infty$.
\end{theorem}

\begin{proof}
    Let $e$ be the evader which attempts to evade the predictor by assuming
    that the predictor is $p$ and always outputting the opposite of what
    the predictor will output based on that assumption. Clearly, $p$ does
    not learn to predict $e$.

    Since $X$ knows that $p$ defines a total function from $B^*$ to $B$,
    it follows that there is a Turing machine $C$ such that:
    \begin{enumerate}
        \item
        $C$ computes the function $g:\mathbb N\to \mathbb N$ defined by
        $g(n)=t_e(n)+1$, where $t_e$ is as in
        Definition \ref{tsubedefinition}.
        \item
        $X$ knows that $C$ computes a total function from $\mathbb N$ to $\mathbb N$.
    \end{enumerate}
    By (2), $C=C^X_m$ for some $m$, and thus $g^X_m=g$.
    So if $f_m:\mathbb N\to\mathbb N$ is defined
    (as in Definition \ref{generalintelligencemeasuredefn})
    as $f_m(k)=\max_{i\leq m}\max_{j\leq k}g^X_i(j)$,
    then for every $k$, $f_m(k)\geq g^X_m(k)=g(k)=t_e(k)+1>t_e(k)$.
    This shows that $e\in E_{f_m}$ (from Definition \ref{evadersetdefinition}).
    Since $p$ does not learn to predict $e$,
    it is not the case that $p$ learns to predict every evader in $E_{f_m}$.
    Therefore, $|Y|_X<m$.
\end{proof}

\subsection{The problem with simple Hibbard measures}
\label{problemwithsimplehibbardsection}

In Theorem \ref{simplehibbardnontrivialtheorem} we proved more than was necessary,
yielding the following stronger result.

\begin{corollary}
\label{technicalcorollaryaboutsimplehibbardmeasures}
    Suppose $X$ and $Y$ are AGIs. Let $p$ be $Y$'s predictor.
    Suppose that $X$ knows that $p$ defines a total function from
    $B^*$ to $B$.
    Then there is a Turing machine $C$ such that:
    \begin{enumerate}
        \item
        $C$ computes the function $g:\mathbb N\to \mathbb N$ defined by
        $g(n)=t_e(n)+1$, where $t_e$ is as in
        Definition \ref{tsubedefinition}.
        \item
        $X$ knows that $C$ computes a total function from $\mathbb N$ to $\mathbb N$.
    \end{enumerate}
    Furthermore: $|Y|_X<m$ where $m$ is such that $C=C^X_m$.
\end{corollary}

On the other hand, the following result also holds.

\begin{lemma}
\label{technicallemmaaboutsimplehibbardmeasures}
    Suppose $X$ and $Y$ are AGIs. Suppose that for all $i=1,\ldots,m$,
    $g^X_i$ is identically zero: $g^X_i(n)=0$.
    Then $|Y|_X\geq m$.
\end{lemma}

\begin{proof}
    If $f_m:\mathbb N\to\mathbb N$
    is defined (as in Definition \ref{generalintelligencemeasuredefn})
    by $f_m(k)=\max_{i\leq m}\max_{j\leq k}g^X_i(j)$, then, by
    assumption, $f_m(k)=\max_{i\leq m}\max_{j\leq k}0=0$.
    Thus $E_{f_m}$ is empty, and so, vacuously, $Y$'s predictor learns
    to predict every evader in $E_{f_m}$. This shows $|Y|_X\geq m$.
\end{proof}

By the \emph{mathematical reasoning ability} and \emph{basic mathematical
exposure} assumptions from Assumption \ref{idealizingassumption},
for any AGI $X$, there are infinitely many Turing machines $C$ such that
\begin{enumerate}
    \item
    $C$ defines the zero function $g(n)=0$ defined on all of $\mathbb N$, and
    \item
    $X$ knows $C$ defines a total function from $\mathbb N$ to $\mathbb N$.
\end{enumerate}
Thus, combining Corollary \ref{technicalcorollaryaboutsimplehibbardmeasures}
and Lemma \ref{technicallemmaaboutsimplehibbardmeasures},
we see that if $X$ knows that $Y$'s predictor defines a total function
from $B^*$ to $B$, then we can make $|Y|_{X'}$ have any value we like,
by letting $X'$ be an AGI identical to $X$ in every way except that
$X'$ outputs Turing machines in a different order than $X$ when commanded
as in Definition \ref{functionlistdefinition}.
This is a crucial flaw in the simple Hibbard measures, because it shows
that $|Y|_X$ depends just as much on the arbitrary order in which $X$
outputs Turing machines as it does on how intelligent $Y$ is.

In Section ..., we will define a more sophisticated type of Hibbard measure
which avoids the above problem. First, though, we need to borrow some machinery
from mathematical logic.

\section{The slow-growing hierarchy}
\label{slowgrowinghierarchysection}

The classic Hibbard measure
(Definition \ref{classichibbardmeasuredefn}) depends on a specific list of
quickly-growing computable functions from $\mathbb N$ to $\mathbb N$, imported from
\cite{liu1960enumeration}. In Section \ref{agiperspectivesection}, we argued
that the classic Hibbard measure is trivial because the functions thus imported
are too slow-growing.
In Section \ref{simplemeasuresection} we generalized
the classic Hibbard measure
by delegating the choice of a list of quickly-growing computable functions to an AGI rather
than to a single external paper. The resulting family of simple Hibbard measures is
non-trivial (Theorem \ref{simplehibbardnontrivialtheorem}), but in
Subsection \ref{problemwithsimplehibbardsection} we argued that these generalized
measures still have a crucial flaw: they depend too heavily on the order in which
the AGI supplies its list of computable functions.

In order to solve the problem of dependence on computable functions, we will take
a different strategy.
\begin{itemize}
    \item
    In mathematical logic, there is a general recipe for obtaining
    quickly-growing computable
    functions. This recipe is called the \emph{slow-growing hierarchy}.
    \item
    The recipe takes as input a computable
    ordinal number $\alpha$ along with some so-called \emph{fundamental
    sequences} for certain ordinals $\lambda<\alpha$, and outputs
    a quickly-growing computable function.
    \item
    Thus, instead of
    commanding our AGI to directly produce a list of quickly-growing computable functions,
    we can instead command our AGI to produce computable ordinal numbers and
    fundamental sequences, and then obtain a list of quickly-growing
    computable functions indirectly, by means of the slow-growing hierarchy.
\end{itemize}
This solves the problem of dependence on ordering: we can completely ignore the order
in which the AGI outputs the computable ordinals, because computable ordinals are
\emph{themselves} ordered. In other words, if the AGI outputs a small computable ordinal
and a large computable ordinal, we can consider the small computable ordinal to precede
the large computable ordinal, regardless of in which order the AGI outputs them.

\begin{definition}
    (Classification of ordinal numbers)
    Let $\alpha$ be an ordinal number.
    \begin{enumerate}
        \item
        If $\alpha=\beta+1$ for some ordinal number $\beta$, then $\alpha$ is called
        a \emph{successor ordinal}.
        \item
        If $\alpha$ is not a successor ordinal and $\alpha\neq 0$, then $\alpha$ is
        called a \emph{limit ordinal}.
    \end{enumerate}
\end{definition}

\begin{definition}
\label{fundamentalsequencedefn}
    If $\lambda$ is a limit ordinal, a \emph{fundamental sequence} for $\lambda$
    is a sequence $(\lambda[0],\lambda[1],\lambda[2],\ldots)$
    of ordinals, such that the following requirements hold:
    \begin{enumerate}
        \item
        Each $\lambda[i]<\lambda[i+1]<\lambda$.
        \item
        $\lim_{i\to\infty}\lambda[i]=\lambda$, by which we mean that for
        any ordinal $\alpha<\lambda$, there is some $N\in\mathbb N$ such that
        for all $i>N$, $\lambda[i]>\alpha$.
    \end{enumerate}
\end{definition}

\begin{definition}
\label{slowgrowinghierarchiesdefn}
    (Slow-Growing Hierarchies)
    Suppose $\alpha$ is an ordinal and suppose $\mathcal F$ is a function which
    takes as input a limit ordinal $\lambda<\alpha$ and outputs a fundamental
    sequence $\mathcal F(\lambda)=(\lambda[0],\lambda[1],\lambda[2],\ldots)$
    for $\lambda$. The \emph{slow-growing hierarchy given by $\alpha$ and $\mathcal F$}
    is the family of family of functions consisting of a function
    $G_\beta:\mathbb N\to\mathbb N$ for every
    ordinal $\beta<\alpha$, defined by transfinite induction by the following cases.
    \begin{enumerate}
        \item
        $G_0(x)=0$.
        \item
        $G_{\beta+1}(x) = G_\beta(x) + 1$.
        \item
        $G_{\lambda}(x) = G_{\lambda[x]}(x)$ (for every limit ordinal $\lambda<\alpha$),
        where $(\lambda[0],\lambda[1],\lambda[2],\ldots)$ are the fundamental sequence
        $\mathcal F(\lambda)$ of $\lambda$.
    \end{enumerate}
\end{definition}

\begin{lemma}
    Suppose $\{G_\beta\}_{\beta<\alpha}$ is the slow-growing hierarchy given by
    an ordinal $\alpha$ and function $\mathcal F$.
    If $\alpha$ is computable and $\mathcal F$ is computable,
    then each $G_\beta$ is computable.
\end{lemma}

\begin{proof}
By Church's thesis.
\end{proof}

\begin{example}
    Consider the ordinal $\alpha=\omega^2$ (where $\omega$ is the smallest infinite
    ordinal).
    The limit ordinals $\lambda<\omega^2$ are exactly the ordinals
    $\{\omega\cdot (n+1)\,:\,n\in\mathbb N,\}$.
    A natural way to assign fundamental sequences to these limit ordinals is to define,
    for all $n,m\in\mathbb N$,
    \[
        \mathcal F(\omega\cdot(n+1))(m) = (\omega\cdot(n+1))[m] = (\omega\cdot n)+m.
    \]
    Let us compute some of the functions $\{G_{\beta}\,:\,\beta<\alpha\}$
    given by $\alpha$ and $\mathcal F$. Below, $x$ and $n$
    denote arbitrary natural numbers.
    \begin{enumerate}
        \item
        By the base case, $G_0(x)=0$ for all $x\in\mathbb N$.
        \item
        By the successor case, $G_1(x)=G_0(x)+1=0+1=1$.
        \item
        By the successor case, $G_2(x)=G_1(x)+1=1+1=2$.
        \item
        Generalizing the above pattern, $G_n(x)=n$.
        \item
        By the limit case,
        $G_\omega(x)=G_{\omega\cdot(0+1)}(x)
        =G_{(\omega\cdot(0+1))[x]}(x)=G_{(\omega\cdot 0)+x}(x)
        =G_x(x)=x$ (by (4) above).
        \item
        By the successor case, $G_{\omega+1}(x)=G_{\omega}(x)+1=x+1$.
        \item
        By the successor case, $G_{\omega+2}(x)=G_{\omega+1}(x)+1=x+2$.
        \item
        Generalizing the above pattern, $G_{\omega+n}(x)=x+n$.
        \item
        By the limit case,
        $G_{\omega\cdot 2}(x)=G_{\omega\cdot(1+1)}(x)
        =G_{(\omega\cdot(1+1))[x]}(x)=G_{(\omega\cdot 1)+x}(x)
        =x+x$.
        \item
        Similarly, the reader can check that $G_{\omega\cdot 3}(x)=x+x+x$.
        \item
        Generalizing the above pattern, $G_{\omega\cdot n}(x)=x\cdot n$.
    \end{enumerate}
\end{example}

\begin{example}
\label{epsilon0example}
    The ordinal $\epsilon_0$
    (pronounced ``epsilon-nought'') is the smallest ordinal which is larger than
    all the ordinals $\omega, \omega^\omega, \omega^{\omega^\omega}, \ldots$.
    It satisfies the equation $\epsilon_0=\omega^{\epsilon_0}$, and can be
    intuitively thought of as
    \[
        \epsilon_0 = \omega^{\omega^{\omega^{\iddots}}}.
    \]
    Examples of ordinals below $\epsilon_0$ include such ordinals as
    $\omega^\omega$, $\omega^{\omega^\omega+\omega}$,
    \[
        \omega^{\omega^{\omega^{\omega^\omega+\omega^3+5}+\omega^{\omega^2}+\omega^\omega}+1}
        +\omega^{\omega^{\omega^2+\omega+1}+\omega^{800}}
        +\omega^{\omega^5\cdot 12 + \omega^4\cdot 9 + 1000}
        +1,
    \]
    and so on. There is a natural way to assign fundamental sequences to ordinals
    up to $\epsilon_0$, yielding a corresponding slow-growing hierarchy where, for example,
    \begin{align*}
        G_{\omega^\omega}(x) &= x^x,\\
        G_{\omega^{\omega^\omega}+5}(x) &= x^{x^x}+5,\\
        G_{\omega^{\omega^{\omega^{\omega^\omega}}}}(x) &= x^{x^{x^{x^{x}}}},
    \end{align*}
    and so on. Likewise, $(\omega,\omega^\omega,\omega^{\omega^\omega},\ldots)$ is itself a
    fundamental sequence for $\epsilon_0$. What could $G_{\epsilon_0}(x)$ be?
    Thinking of $\epsilon_0$ as $\omega^{\omega^{\iddots}}$, one might initially think
    $G_{\epsilon_0}(x)=x^{x^{\iddots}}$, but such an infinite tower of natural numbers
    makes no sense for $x>1$. Instead, the answer defies familiar mathematical notation:
    \begin{align*}
        G_{\epsilon_0}(0) &= 0\\
        G_{\epsilon_0}(1) &= 1^1\\
        G_{\epsilon_0}(2) &= 2^{2^2}\\
        G_{\epsilon_0}(3) &= 3^{3^{3^3}},
    \end{align*}
    and so on.
\end{example}

Example \ref{epsilon0example} illustrates how the slow-growing hierarchy reduces
the open-ended problem, ``Invent a quickly-growing computable function,'' into a slightly
less open-ended and more manageable problem: ``Invent fundamental sequences up to a
large computable ordinal.''

Slow-growing hierarchies provide an elegant means of obtaining quickly-growing
computable functions from $\mathbb N$ to $\mathbb N$.
The larger the computable ordinal, the larger the resulting computable function.
However, inventing large computable ordinals is a non-trivial task---in
\cite{ioi2} we argue that it might be a task that exhausts the full range
of intelligence (i.e., that for any possible intelligence level, there is a corresponding
computable ordinal whose invention requires at least that much intelligence).
Even having invented a large computable ordinal, the task of assigning fundamental
sequences to the limit ordinals below it is another difficult task in general\footnote{The
choice of fundamental sequences can dramatically change the growth rate of the
resulting slow-growing hierarchy---see \cite{weiermann1997sometimes}.}.
Fortunately, this is a theoretical paper about AGI, so we can completely dodge all this
work by delegating it to our AGI. In order to do so in a sensible way, we need a certain
technical lemma which will allow us to command the AGI to give us a slow-growing hierarchy
one piece at a time.

\begin{definition}
\label{fundamentalsequenceextensiondef}
    Suppose $\mathcal H_1$ is the slow-growing hierarchy given by
    ordinal $\alpha_1$ and function $\mathcal F_1$, and suppose
    $\mathcal H_2$ is the slow-growing hierarchy given by
    ordinal $\alpha_2$ and function $\mathcal F_2$.
    We say \emph{$\mathcal H_2$ extends $\mathcal H_1$},
    written $\mathcal H_1\prec \mathcal H_2$, if the following
    requirements hold:
    \begin{enumerate}
        \item
        $\alpha_1<\alpha_2$.
        \item
        For every limit ordinal $\lambda<\alpha_1$,
        $\mathcal F_1(\lambda)=\mathcal F_2(\lambda)$.
    \end{enumerate}
\end{definition}

\begin{lemma}
\label{slowgrowingtechnicallemma}
    Suppose for every $i\in\mathbb N$,
    $\mathcal H_i$ is the slow-growing hierarchy given by an ordinal
    $\alpha_i$ and function $\mathcal F_i$.
    If $\mathcal H_0\prec \mathcal H_1\prec \mathcal H_2\prec\cdots$,
    then
    $\mathcal F_\infty=\cup_i\mathcal F_i$ is a function which assigns
    fundamental sequences
    to all limit ordinals $\lambda<\alpha_\infty=\cup_i\alpha_i$
    (so that together, $\alpha_\infty$ and $\mathcal F_\infty$
    give a slow-growing hierarchy).
\end{lemma}

\begin{proof}
    By definition, $\mathcal F_\infty$ is a relation whose domain is
    the union of the domains of all the $\mathcal F_i$, i.e.,
    the set of all limit ordinals $\{\lambda\,:\,\lambda<\alpha_i\mbox{ for some $i$}\}$.
    To show that $\mathcal F_\infty$ is a function, which must show that for any two pairs
    $(\lambda,y_1)\in\mathcal F_\infty$ and $(\lambda,y_2)\in\mathcal F_\infty$,
    $y_1=y_2$ (i.e., that
    $\mathcal F_\infty$ ``passes the vertical line test'').
    Assume $(\lambda,y_1)\in\mathcal F_\infty$ and $(\lambda,y_2)\in\mathcal F_\infty$.
    This means there are some $i_1,i_2\in\mathbb N$ such that
    $\mathcal F_{i_1}(\lambda)=y_1$ and $\mathcal F_{i_2}(\lambda)=y_2$.
    If $i_1=i_2$ then $y_1=y_2$ because $\mathcal F_{i_1}=\mathcal F_{i_2}$ is a function,
    but assume $i_1\neq i_2$. Without loss of generality we may
    assume $i_1<i_2$ (the other case is similar).
    Since $\mathcal H_{i_1}\prec \cdots \prec \mathcal H_{i_2}$,
    it follows by a simple inductive argument that $\mathcal H_{i_1}\prec \mathcal H_{i_2}$.
    Thus by condition 2 of Definition \ref{fundamentalsequenceextensiondef},
    $y_1=y_2$, as desired.

    It remains to let $\lambda<\alpha_\infty$ be a limit ordinal and show
    that conditions 1 and 2 of Definition \ref{fundamentalsequencedefn}
    hold for $\mathcal F_\infty(\lambda)$.
    Since $\lambda<\alpha_\infty$, that means $\lambda<\alpha_i$ for some $i\in\mathbb N$.
    Let $(\lambda[0],\lambda[1],\ldots)=\mathcal F_\infty(\lambda)$.
    Then $(\lambda[0],\lambda[1],\ldots)=\mathcal F_i(\lambda)$, so
    conditions 1 and 2 of Definition \ref{fundamentalsequencedefn} hold because
    $\mathcal F_i$ is a function which assigns fundamental sequences to all limit
    ordinals $<\alpha_i$.
\end{proof}

\section{The Transfinite Hibbard measures}
\label{transfinitehibbardsection}

We would like to delegate the problem of inventing large computable ordinals and
fundamental sequences to an AGI. In order to do so, we need a systematic
way for the AGI to encode those things. Since we do not care about the specific
details of the encoding, we can get away with the following high-level definition.
A more concrete definition would be possible by using, say, the ordinal notation
system known as Kleene's $\mathcal O$ \cite{kleene1938notation}, but the details
would be long and tedious.

\begin{definition}
    By a \emph{slow-growing hierarchy notation}, we mean a
    definition (in the language of ZFC) of a pair $(\alpha,\mathcal F)$
    such that $\alpha$ is a computable ordinal and $\mathcal F$ is a computable
    function that assigns fundamental sequences to limit ordinals $\lambda<\alpha$.
\end{definition}

\begin{definition}
\label{slowgrowinghierarchyofanagidefn}
    Let $X$ be an AGI. The \emph{slow-growing hierarchy of $X$} is defined to be
    the slow-growing hierarchy given by $\alpha_\infty$ and $\mathcal F_\infty$
    (via Lemma \ref{slowgrowingtechnicallemma}) where $(\alpha_i)_{i\in\mathbb N}$
    and $(\mathcal F_i)_{i\in\mathbb N}$ are the defined by the
    slow-growing hierarchy notations which
    $X$ would output if $X$ were commanded as follows:
    ``Until further notice, output slow-growing hierarchy
    notations of pairs $(\alpha_i,\mathcal F_i)$, such that
    the corresponding slow-growing hierarchies $\mathcal H_i$ satisfy
    the hypotheses of Lemma \ref{slowgrowingtechnicallemma}. Do this in such a way
    that the $\alpha_i$s include computable ordinals as large as you can think of.''
\end{definition}

\begin{definition}
\label{transfinitehibbardmeasuredefn}
    Suppose that $X$ is an AGI, and that
    $\alpha_\infty$ and $\mathcal F_\infty$ are as in
    Definition \ref{slowgrowinghierarchyofanagidefn}, and that
    $\{G_\beta\}_{\beta<\alpha_\infty}$ is the slow-growing hierarchy
    given by $\alpha_\infty$ and $\mathcal F_\infty$
    (Definition \ref{slowgrowinghierarchiesdefn}).
    The \emph{transfinite Hibbard measure given by $X$} is
    the function which assigns to each AGI $Y$ a computable ordinal (or $\infty$)
    $\|Y\|_X$
    defined as follows.
    We define $\|Y\|_X$ to be the smallest ordinal $\alpha<\alpha_\infty$ such that
    there is some evader $e\in E_{G_\alpha}$ such that $Y$'s predictor does not
    learn to predict $e$ (where $E_{G_\alpha}$ is as in Definition \ref{evadersetdefinition}),
    or we define $\|Y\|_X=\infty$ if there is no such $\alpha$.
\end{definition}

Definition \ref{transfinitehibbardmeasuredefn} avoids the order-dependency problem which
we saw in Subsection \ref{problemwithsimplehibbardsection}, because the functions
$G_{\alpha}$ which are used to define evader-sets come with their own intrinsic ordering
($G_{\alpha}$ comes before $G_{\beta}$ if and only if $\alpha<\beta$) rather than
depending on the order in which the AGI thinks of things.

If $X$ is an AGI, consider the set $S$ of all AGIs $Y$ such that $\|Y\|_X<\infty$.
The transfinite Hibbard measure given by $X$ is a computable-ordinal-valued intelligence
measure defined on $S$. This should be contrasted with intelligence measures that
are real-number-valued. In \cite{alexander2020archimedean} we point out that because
the real numbers are constrained by a certain generalized Archimedean property,
real numbers are inappropriate for measuring things which are non-Archimedean in a certain
technical sense. Arguably, if $X$ itself is sufficiently intelligent, then
the intelligences of the AGIs in $S$ are probably non-Archimedean, and so the usage of
computable ordinals to measure their intelligence is more appropriate than using real numbers.

If AGI $Y$ plays the adversarial sequence prediction game using $Y$'s brute-force
predictor, $Y$ enumerates all the Turing machines $M_1,M_2,\ldots$ such that $Y$ knows that
$M_i$ computes a total function from $B^*$ to $B$, and $Y$ systematically tries to
predict the evader $e$ by first assuming that $e$ computes the same function as
$M_1$, and if that fails, then assuming that $e$ computes the same function as
$M_2$, and so on. In particular, suppose $Y$ knows that a certain computable ordinal
$\alpha$ and function $\mathcal F$ give a slow-growing hierarchy
$\{G_\beta\}_{\beta<\alpha}$. For any $\beta<\alpha$,
since $Y$ is capable of mathematical reasoning, for every Turing machine $M$
which computes a total function from $B^*$ to $B$ and which has runtime bounded by
$G_\beta$, there should be a Turing machine $M'$ such that $M$ computes the same
function as $M'$ and such that $Y$ knows that $M'$ computes a total function from $B^*$
to $B$. Thus, $M_1,M_2,\ldots$ should include Turing machines that compute all the
functions from $B^*$ to $B$ that can be so computed with runtime bounded by any such
$G_\beta$. Thus, assuming that $Y$'s predictor is $Y$'s brute-force predictor, if
$\|Y\|_X<\infty$, then it seems that $\|Y\|_X$ should in some sense measure the size
of the supremum of the ordinals $\alpha$ such that $Y$ knows a fundamental sequence up
to $\alpha$. This suggests a close relation between the transfinite Hibbard measure and
our Intuitive Ordinal Intelligence measure (an AGI $Y$'s Intuitive Ordinal Intelligence is
defined as the supremum of the ordinals $\alpha$ such that $\alpha$ has any code
$c$ such that $Y$ knows that $c$ is the code of a computable ordinal)
\cite{ioi1} \cite{ioi2}.

\section{Summary and Conclusion}
\label{conclusionsection}

To summarize:
\begin{itemize}
    \item
    Hibbard proposed \cite{hibbard} an intelligence measure for predictors (or, implicitly,
    for AGIs capable of acting as predictors) in games of adversarial sequence prediction.
    \item
    Hibbard's measure depends on one specific sequence of computable functions from $\mathbb N$
    to $\mathbb N$.
    \item
    In Section \ref{agiperspectivesection}, we argued that all AGIs probably have
    intelligence $\infty$ according to Hibbard's definition. Essentially, this is because
    the specific functions that Hibbard's definition is based on should all be trivially
    well-known by any genuine AGI.
    \item
    In Section \ref{simplemeasuresection}, we introduced what we call \emph{simple Hibbard
    measures}. For each AGI $X$, there is a corresponding simple Hibbard measure which
    assigns an intelligence measurement $|Y|_X$ to every AGI $Y$. The simple Hibbard
    measure corresponding to $X$ might be thought of as a measure of ``intelligence as
    judged by $X$''. The key insight needed to define the simple Hibbard measure corresponding
    to $X$ is as follows: rather than depend on one fixed sequence of functions (as in
    Hibbard's original definition), we can delegate the task of choosing a function-sequence
    to $X$.
    \item
    We showed that simple Hibbard measures are less trivial than Hibbard's original measure.
    However, they still suffer a crucial flaw: the Hibbard measure corresponding to an
    AGI $X$ depends unnaturally on the \emph{order} in which $X$ can think of
    computable functions.
    \item
    To remedy the above-mentioned flaw in the simple Hibbard measures, we reviewed
    \emph{slow-growing hierarchies} from mathematical logic and used them to define
    (in Section \ref{transfinitehibbardsection}) what
    we call \emph{transfinite Hibbard measures}, which assign
    computable-ordinal-number-valued
    intelligence measures rather than real-number-valued intelligence measures.
\end{itemize}

This paper exemplifies a useful technique for theoretical AGI research.
By viewing an AGI as an employee who is capable of engaging in casual human
language communication with its employer, and which can be commanded (using said
casual human language) to perform mathematical tasks, the AGI becomes a useful
black box to which many arbitrary decisions can be delegated. For example, instead
of arbitrarily choosing one particular function-sequence (as Hibbard did in order
to define his original measure), we can short-circuit the task of
function-sequence-selection by delegating it to an AGI.


\bibliographystyle{plain}
\bibliography{hibbard}
\end{document}
